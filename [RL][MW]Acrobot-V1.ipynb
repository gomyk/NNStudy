{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL_NN_Impl.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gomyk/NNStudy/blob/moonwon/%5BRL%5D%5BMW%5DAcrobot-V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6QDytnJc1V5",
        "colab_type": "code",
        "outputId": "50572066-9a9c-4eaa-cfca-43031226d1df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!apt-get install x11-utils\n",
        "\n",
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40)\n",
        "\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "display = Display(visible=0, size=(1400,900),)\n",
        "display.start()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 65%\r\rReading package lists... 65%\r\rReading package lists... 66%\r\rReading package lists... 66%\r\rReading package lists... 73%\r\rReading package lists... 73%\r\rReading package lists... 73%\r\rReading package lists... 73%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 95%\r\rReading package lists... 95%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n",
            "\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n",
            "x11-utils is already the newest version (7.7+3build1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1037'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1037'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_uitgnKdJ8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "HIDDEN = 32\n",
        "BATCH_SIZE = 32\n",
        "PERCENTILE = 50\n",
        "LIMIT = 250\n",
        "EPISODE = 100\n",
        "class Net(nn.Module):\n",
        "  def __init__(self, obs_size, hidden, action_size):\n",
        "    super(Net, self).__init__()\n",
        "    self.net=nn.Sequential(\n",
        "        nn.Linear(obs_size, hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden, action_size)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS1SOTZceS7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "\n",
        "def get_batch(batch_size, env, net):\n",
        "  print('')\n",
        "  batch = []\n",
        "  reward = 0.0\n",
        "  obs = env.reset()\n",
        "  steps = []\n",
        "  sm = nn.Softmax(dim=1)\n",
        "  while True:\n",
        "    obs_v = torch.FloatTensor([obs])\n",
        "    obs_v = obs_v.to(device)\n",
        "    action_v = sm(net(obs_v)).cpu().data.numpy()[0]\n",
        "    action = np.random.choice(env.action_space.n, p=action_v)\n",
        "    next_obs, rew, done, _ = env.step(action)\n",
        "    reward += rew\n",
        "    steps.append((obs,action))\n",
        "    if done:\n",
        "      batch.append((reward, steps))\n",
        "      reward = 0.0\n",
        "      next_obs = env.reset()\n",
        "      steps = []\n",
        "      if len(batch) == batch_size:\n",
        "        yield batch\n",
        "        obs = env.reset()\n",
        "        batch=[]\n",
        "    obs = next_obs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nSYB-BTlk5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filter_batch(batch):\n",
        "  rews = list(map(lambda episode: episode[0],batch))\n",
        "  rews_threshold = np.percentile(rews, PERCENTILE)\n",
        "  rews_mean = np.mean(rews)\n",
        "\n",
        "  ret_action = []\n",
        "  ret_obs = []\n",
        "\n",
        "  for scene in batch:\n",
        "    if scene[0] < rews_threshold:\n",
        "      continue\n",
        "    ret_obs.extend(map(lambda step: step[0], scene[1]))\n",
        "    ret_action.extend(map(lambda step: step[1], scene[1]))\n",
        "\n",
        "  return torch.FloatTensor(ret_obs), torch.LongTensor(ret_action), rews_threshold, rews_mean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rm1piHQ87HI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evalNet(env, net):\n",
        "  #Best 100 episode rewards\n",
        "  sm = nn.Softmax(dim=1)\n",
        "  total_reward = 0\n",
        "  for i in range(EPISODE):\n",
        "    obs = env.reset()\n",
        "    reward = 0\n",
        "    while True:\n",
        "      obs_v = torch.FloatTensor([obs]).to(device)\n",
        "      action = sm(net(obs_v))\n",
        "      _, predicted = torch.max(action.data, 1)\n",
        "      next_obs, rew, done, _ = env.step(predicted)\n",
        "      reward += rew\n",
        "      obs = next_obs\n",
        "      if done:\n",
        "        total_reward += reward\n",
        "        break;\n",
        "  return total_reward/EPISODE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08L70DJvkWPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    for mp4 in mp4list:\n",
        "      video = io.open(mp4, 'r+b').read()\n",
        "      print(mp4)\n",
        "      encoded = base64.b64encode(video)\n",
        "      ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay loop controls style=\"height: 300px;\">\n",
        "                                  <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\"/>\n",
        "                                  </video>'''.format(encoded.decode('ascii'))))\n",
        "  else:\n",
        "    print(\"Could not find video\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5Bf4hpml22W",
        "colab_type": "code",
        "outputId": "dfe257f1-ce72-4640-cb49-727b4d3f62bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "env = gym.wrappers.Monitor(gym.make(\"Acrobot-v1\"), \"video\", force=True, video_callable=lambda c:c%100 ==0)\n",
        "net = Net(env.observation_space.shape[0], HIDDEN, env.action_space.n)\n",
        "CELoss = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(net.parameters(), 0.01)\n",
        "device = torch.device(\"cuda\")\n",
        "net = net.to(device)\n",
        "\n",
        "for i,batch in enumerate(get_batch(BATCH_SIZE, env, net)):\n",
        "  obs, action, threshold, mean = filter_batch(batch)\n",
        "  opt.zero_grad()\n",
        "  obs = obs.to(device)\n",
        "  action = action.to(device)\n",
        "  action_out = net(obs)\n",
        "  loss = CELoss(action_out, action)\n",
        "  loss.backward()\n",
        "  opt.step()\n",
        "  print(\"%d, loss = %.4f, th = %.2f, mean = %.2f \"%(i, loss, threshold, mean))\n",
        "  if(i == 10) :\n",
        "    print(\"%d EVAL : %.4f\"%(i, evalNet(env, net)))\n",
        "  if(i == EPISODE) :\n",
        "      show_video()\n",
        "  \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0, loss = 1.0885, th = -500.00, mean = -500.00 \n",
            "1, loss = 1.0768, th = -500.00, mean = -499.94 \n",
            "2, loss = 1.0635, th = -500.00, mean = -494.31 \n",
            "3, loss = 1.0430, th = -500.00, mean = -458.78 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ggM82_AHeCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}