{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPRFcHZIXGgZP/xp8Q5qseA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gomyk/NNStudy/blob/moonwon/%5BRL%5D%5BDQN%5D%5BMW%5D%20CartPole-v0%20(Not%20using%20CNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9duZfSLhJ8X",
        "colab_type": "code",
        "outputId": "c247ea0a-c4cc-4c41-85a8-509cf980a356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!apt-get install x11-utils"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "x11-utils is already the newest version (7.7+3build1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DE8ejMqcTWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import base64\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "from google.colab import output\n",
        "\n",
        "display = Display(visible=0, size=(400,600),)\n",
        "display.start()\n",
        "\n",
        "env = gym.wrappers.Monitor(gym.make(\"CartPole-v1\"), \"video\", force=True, video_callable=lambda c:c%100 ==0)\n",
        "\n",
        "# GPU를 사용할 경우\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmc6Jfr2d8_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"transition 저장\"\"\"\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = Transition(*args)\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gwNNaGeeyMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class DQN(nn.Module):\n",
        "\n",
        "    def __init__(self, h, w, outputs):\n",
        "        super(DQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        # Linear 입력의 연결 숫자는 conv2d 계층의 출력과 입력 이미지의 크기에\n",
        "        # 따라 결정되기 때문에 따로 계산을 해야합니다.\n",
        "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
        "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
        "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
        "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
        "        linear_input_size = convw * convh * 32\n",
        "        \n",
        "        self.head = nn.Linear(linear_input_size, outputs)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        return self.head(x.view(x.size(0), -1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1hagvrqKTpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HIDDEN_SIZE = 64\n",
        "class DQN_custom(nn.Module):\n",
        "\n",
        "    def __init__(self, obs_size, outputs):\n",
        "        super(DQN_custom, self).__init__()\n",
        "        self.linear = nn.Linear(obs_size, HIDDEN_SIZE)\n",
        "        self.head = nn.Linear(HIDDEN_SIZE, outputs)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.linear(x))\n",
        "        return self.head(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVgLn9rKgS79",
        "colab_type": "code",
        "outputId": "cd316dd5-dd8e-4f26-ecea-c0d169c1622b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "resize = T.Compose([T.ToPILImage(),\n",
        "                    T.Resize(40, interpolation=Image.CUBIC),\n",
        "                    T.ToTensor()])\n",
        "\n",
        "\n",
        "def get_cart_location(screen_width):\n",
        "    world_width = env.x_threshold * 2\n",
        "    scale = screen_width / world_width\n",
        "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
        "\n",
        "def get_screen():\n",
        "    # gym이 요청한 화면은 400x600x3 이지만, 가끔 800x1200x3 처럼 큰 경우가 있습니다.\n",
        "    # 이것을 Torch order (CHW)로 변환한다.\n",
        "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
        "    # 카트는 아래쪽에 있으므로 화면의 상단과 하단을 제거하십시오.\n",
        "    _, screen_height, screen_width = screen.shape\n",
        "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
        "    view_width = int(screen_width * 0.6)\n",
        "    cart_location = get_cart_location(screen_width)\n",
        "    if cart_location < view_width // 2:\n",
        "        slice_range = slice(view_width)\n",
        "    elif cart_location > (screen_width - view_width // 2):\n",
        "        slice_range = slice(-view_width, None)\n",
        "    else:\n",
        "        slice_range = slice(cart_location - view_width // 2,\n",
        "                            cart_location + view_width // 2)\n",
        "    # 카트를 중심으로 정사각형 이미지가 되도록 가장자리를 제거하십시오.\n",
        "    screen = screen[:, :, slice_range]\n",
        "    # float 으로 변환하고,  rescale 하고, torch tensor 로 변환하십시오.\n",
        "    # (이것은 복사를 필요로하지 않습니다)\n",
        "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
        "    screen = torch.from_numpy(screen)\n",
        "    # 크기를 수정하고 배치 차원(BCHW)을 추가하십시오.\n",
        "    return resize(screen).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "env.reset()\n",
        "plt.figure()\n",
        "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
        "           interpolation='none')\n",
        "plt.title('Example extracted screen')\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAADECAYAAACGNXroAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y5GkgVljenU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.999\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 2000\n",
        "TARGET_UPDATE = 10\n",
        "LR = 0.01\n",
        "MEMORY_SIZE = 10000\n",
        "EPISODE_SIZE = 1500\n",
        "\n",
        "# gym 행동 공간에서 행동의 숫자를 얻습니다.\n",
        "n_actions = env.action_space.n\n",
        "n_obvs = 4\n",
        "\n",
        "policy_net = DQN_custom(n_obvs, n_actions).to(device)\n",
        "policy_net.eval()\n",
        "target_net = DQN_custom(n_obvs, n_actions).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=LR)\n",
        "memory = ReplayMemory(MEMORY_SIZE)\n",
        "\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "def select_action(obs):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            obs = torch.FloatTensor(obs).to(device)\n",
        "            output = policy_net(obs).cpu()\n",
        "            predicted = np.argmax(output.data.numpy())\n",
        "            return torch.tensor([[predicted]],device=device, dtype=torch.long)\n",
        "    else:\n",
        "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
        "\n",
        "\n",
        "episode_durations = []\n",
        "\n",
        "\n",
        "def plot_durations():\n",
        "    plt.figure(2)\n",
        "    plt.clf()\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # 100개의 에피소드 평균을 가져 와서 도표 그리기\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1Vbb4tzjnjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return -1\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation). 이것은 batch-array의 Transitions을 Transition의 batch-arrays로\n",
        "    # 전환합니다.\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    state_batch = torch.cat(batch.state).to(device)\n",
        "    reward_batch = torch.cat(batch.reward).to(device)\n",
        "    action_batch = torch.cat(batch.action).to(device)\n",
        " \n",
        "    non_final_mask = map(lambda s: s is not None, batch.next_state)\n",
        "    non_final_mask = tuple(non_final_mask)\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    non_final_mask = torch.BoolTensor(non_final_mask)\n",
        "\n",
        "    # We don't want to backprop through the expected action values and volatile\n",
        "    # will save us on temporarily changing the model parameters'\n",
        "    # requires_grad to False!\n",
        "    non_final_next_states = [s.view(1, -1) for s in batch.next_state if s is not None]\n",
        "    non_final_next_states = torch.cat(non_final_next_states, 0).to(device)\n",
        "  \n",
        "\n",
        "    # Q(s_t, a) 계산 - 모델이 Q(s_t)를 계산하고, 취한 행동의 열을 선택합니다.\n",
        "    # 이들은 policy_net에 따라 각 배치 상태에 대해 선택된 행동입니다.\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # 모든 다음 상태를 위한 V(s_{t+1}) 계산\n",
        "    # non_final_next_states의 행동들에 대한 기대값은 \"이전\" target_net을 기반으로 계산됩니다.\n",
        "    # max(1)[0]으로 최고의 보상을 선택하십시오.\n",
        "    # 이것은 마스크를 기반으로 병합되어 기대 상태 값을 갖거나 상태가 최종인 경우 0을 갖습니다.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
        "    # 기대 Q 값 계산\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "    \n",
        "    # Huber 손실 계산\n",
        "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "    # 모델 최적화\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    for param in policy_net.parameters():\n",
        "        param.grad.data.clamp_(-1, 1)\n",
        "    optimizer.step()\n",
        "    return loss.cpu().data.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-2dnWNDjp7y",
        "colab_type": "code",
        "outputId": "f8ab565a-163d-4ca3-8a67-c8a8786613dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_episodes = EPISODE_SIZE\n",
        "for i_episode in range(num_episodes):\n",
        "    # 환경과 상태 초기화\n",
        "    obv = env.reset()\n",
        "    total_loss = 0\n",
        "    for t in count():\n",
        "        # 행동 선택과 수행\n",
        "        action = select_action(obv)\n",
        "        next_obv, reward, done, _ = env.step(action.item())\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "\n",
        "        if not done:\n",
        "          next_state = torch.FloatTensor([next_obv])\n",
        "        else:\n",
        "          next_state = None\n",
        "        # 메모리에 변이 저장\n",
        "        assert obv is not None\n",
        "        memory.push(torch.FloatTensor([obv]), action, next_state, reward)\n",
        "\n",
        "        # 다음 상태로 이동\n",
        "        obv = next_obv\n",
        "\n",
        "        # 최적화 한단계 수행(목표 네트워크에서)\n",
        "        total_loss += optimize_model()\n",
        "        if done:\n",
        "            E = eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "            math.exp(-1. * steps_done / EPS_DECAY)\n",
        "            episode_durations.append(t + 1)\n",
        "            print('%d episode , %d step , %.2f Loss, %.2f Threshold'%(i_episode,t+1,total_loss/(t+1),E))\n",
        "            plot_durations()\n",
        "            total_loss = 0\n",
        "            break\n",
        "    #목표 네트워크 업데이트, 모든 웨이트와 바이어스 복사\n",
        "    if i_episode % TARGET_UPDATE == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "print('Complete')\n",
        "env.render()\n",
        "env.close()\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 episode , 19 step , -1.00 Loss, 0.89 Threshold\n",
            "1 episode , 12 step , -1.00 Loss, 0.89 Threshold\n",
            "2 episode , 8 step , -1.00 Loss, 0.88 Threshold\n",
            "3 episode , 29 step , -1.00 Loss, 0.87 Threshold\n",
            "4 episode , 30 step , -1.00 Loss, 0.86 Threshold\n",
            "5 episode , 18 step , -1.00 Loss, 0.85 Threshold\n",
            "6 episode , 17 step , -0.53 Loss, 0.85 Threshold\n",
            "7 episode , 53 step , 0.02 Loss, 0.82 Threshold\n",
            "8 episode , 31 step , 0.00 Loss, 0.81 Threshold\n",
            "9 episode , 25 step , 0.00 Loss, 0.80 Threshold\n",
            "10 episode , 18 step , 0.00 Loss, 0.80 Threshold\n",
            "11 episode , 34 step , 0.10 Loss, 0.78 Threshold\n",
            "12 episode , 16 step , 0.03 Loss, 0.78 Threshold\n",
            "13 episode , 10 step , 0.02 Loss, 0.77 Threshold\n",
            "14 episode , 14 step , 0.01 Loss, 0.77 Threshold\n",
            "15 episode , 28 step , 0.02 Loss, 0.76 Threshold\n",
            "16 episode , 12 step , 0.02 Loss, 0.76 Threshold\n",
            "17 episode , 10 step , 0.02 Loss, 0.75 Threshold\n",
            "18 episode , 10 step , 0.02 Loss, 0.75 Threshold\n",
            "19 episode , 25 step , 0.02 Loss, 0.74 Threshold\n",
            "20 episode , 11 step , 0.02 Loss, 0.74 Threshold\n",
            "21 episode , 12 step , 0.21 Loss, 0.73 Threshold\n",
            "22 episode , 11 step , 0.09 Loss, 0.73 Threshold\n",
            "23 episode , 9 step , 0.06 Loss, 0.72 Threshold\n",
            "24 episode , 19 step , 0.04 Loss, 0.72 Threshold\n",
            "25 episode , 11 step , 0.05 Loss, 0.71 Threshold\n",
            "26 episode , 19 step , 0.04 Loss, 0.71 Threshold\n",
            "27 episode , 41 step , 0.04 Loss, 0.69 Threshold\n",
            "28 episode , 13 step , 0.04 Loss, 0.69 Threshold\n",
            "29 episode , 12 step , 0.03 Loss, 0.69 Threshold\n",
            "30 episode , 25 step , 0.03 Loss, 0.68 Threshold\n",
            "31 episode , 17 step , 0.16 Loss, 0.67 Threshold\n",
            "32 episode , 19 step , 0.07 Loss, 0.67 Threshold\n",
            "33 episode , 12 step , 0.05 Loss, 0.66 Threshold\n",
            "34 episode , 17 step , 0.05 Loss, 0.66 Threshold\n",
            "35 episode , 56 step , 0.04 Loss, 0.64 Threshold\n",
            "36 episode , 44 step , 0.04 Loss, 0.63 Threshold\n",
            "37 episode , 46 step , 0.03 Loss, 0.62 Threshold\n",
            "38 episode , 58 step , 0.03 Loss, 0.60 Threshold\n",
            "39 episode , 10 step , 0.03 Loss, 0.60 Threshold\n",
            "40 episode , 38 step , 0.03 Loss, 0.59 Threshold\n",
            "41 episode , 28 step , 0.11 Loss, 0.58 Threshold\n",
            "42 episode , 57 step , 0.04 Loss, 0.56 Threshold\n",
            "43 episode , 73 step , 0.04 Loss, 0.55 Threshold\n",
            "44 episode , 15 step , 0.03 Loss, 0.54 Threshold\n",
            "45 episode , 11 step , 0.03 Loss, 0.54 Threshold\n",
            "46 episode , 14 step , 0.04 Loss, 0.54 Threshold\n",
            "47 episode , 69 step , 0.03 Loss, 0.52 Threshold\n",
            "48 episode , 34 step , 0.04 Loss, 0.51 Threshold\n",
            "49 episode , 79 step , 0.03 Loss, 0.49 Threshold\n",
            "50 episode , 63 step , 0.03 Loss, 0.48 Threshold\n",
            "51 episode , 146 step , 0.06 Loss, 0.45 Threshold\n",
            "52 episode , 74 step , 0.04 Loss, 0.44 Threshold\n",
            "53 episode , 126 step , 0.04 Loss, 0.41 Threshold\n",
            "54 episode , 59 step , 0.04 Loss, 0.40 Threshold\n",
            "55 episode , 85 step , 0.04 Loss, 0.39 Threshold\n",
            "56 episode , 27 step , 0.04 Loss, 0.38 Threshold\n",
            "57 episode , 99 step , 0.05 Loss, 0.37 Threshold\n",
            "58 episode , 21 step , 0.03 Loss, 0.36 Threshold\n",
            "59 episode , 45 step , 0.04 Loss, 0.36 Threshold\n",
            "60 episode , 55 step , 0.04 Loss, 0.35 Threshold\n",
            "61 episode , 189 step , 0.06 Loss, 0.32 Threshold\n",
            "62 episode , 147 step , 0.05 Loss, 0.30 Threshold\n",
            "63 episode , 30 step , 0.04 Loss, 0.30 Threshold\n",
            "64 episode , 78 step , 0.05 Loss, 0.29 Threshold\n",
            "65 episode , 43 step , 0.05 Loss, 0.28 Threshold\n",
            "66 episode , 14 step , 0.05 Loss, 0.28 Threshold\n",
            "67 episode , 80 step , 0.04 Loss, 0.27 Threshold\n",
            "68 episode , 137 step , 0.04 Loss, 0.26 Threshold\n",
            "69 episode , 88 step , 0.04 Loss, 0.25 Threshold\n",
            "70 episode , 115 step , 0.04 Loss, 0.24 Threshold\n",
            "71 episode , 178 step , 0.06 Loss, 0.22 Threshold\n",
            "72 episode , 106 step , 0.05 Loss, 0.21 Threshold\n",
            "73 episode , 165 step , 0.04 Loss, 0.20 Threshold\n",
            "74 episode , 156 step , 0.04 Loss, 0.19 Threshold\n",
            "75 episode , 47 step , 0.04 Loss, 0.19 Threshold\n",
            "76 episode , 117 step , 0.05 Loss, 0.18 Threshold\n",
            "77 episode , 75 step , 0.05 Loss, 0.17 Threshold\n",
            "78 episode , 86 step , 0.04 Loss, 0.17 Threshold\n",
            "79 episode , 182 step , 0.05 Loss, 0.16 Threshold\n",
            "80 episode , 68 step , 0.04 Loss, 0.15 Threshold\n",
            "81 episode , 175 step , 0.07 Loss, 0.15 Threshold\n",
            "82 episode , 135 step , 0.05 Loss, 0.14 Threshold\n",
            "83 episode , 180 step , 0.05 Loss, 0.13 Threshold\n",
            "84 episode , 176 step , 0.05 Loss, 0.12 Threshold\n",
            "85 episode , 139 step , 0.04 Loss, 0.12 Threshold\n",
            "86 episode , 128 step , 0.04 Loss, 0.12 Threshold\n",
            "87 episode , 31 step , 0.05 Loss, 0.11 Threshold\n",
            "88 episode , 170 step , 0.05 Loss, 0.11 Threshold\n",
            "89 episode , 137 step , 0.04 Loss, 0.11 Threshold\n",
            "90 episode , 165 step , 0.05 Loss, 0.10 Threshold\n",
            "91 episode , 267 step , 0.06 Loss, 0.09 Threshold\n",
            "92 episode , 87 step , 0.05 Loss, 0.09 Threshold\n",
            "93 episode , 88 step , 0.05 Loss, 0.09 Threshold\n",
            "94 episode , 151 step , 0.05 Loss, 0.09 Threshold\n",
            "95 episode , 179 step , 0.05 Loss, 0.08 Threshold\n",
            "96 episode , 87 step , 0.05 Loss, 0.08 Threshold\n",
            "97 episode , 146 step , 0.05 Loss, 0.08 Threshold\n",
            "98 episode , 156 step , 0.06 Loss, 0.08 Threshold\n",
            "99 episode , 93 step , 0.05 Loss, 0.08 Threshold\n",
            "100 episode , 158 step , 0.05 Loss, 0.08 Threshold\n",
            "101 episode , 98 step , 0.10 Loss, 0.07 Threshold\n",
            "102 episode , 176 step , 0.07 Loss, 0.07 Threshold\n",
            "103 episode , 195 step , 0.06 Loss, 0.07 Threshold\n",
            "104 episode , 106 step , 0.06 Loss, 0.07 Threshold\n",
            "105 episode , 369 step , 0.06 Loss, 0.07 Threshold\n",
            "106 episode , 150 step , 0.07 Loss, 0.06 Threshold\n",
            "107 episode , 181 step , 0.07 Loss, 0.06 Threshold\n",
            "108 episode , 125 step , 0.06 Loss, 0.06 Threshold\n",
            "109 episode , 60 step , 0.07 Loss, 0.06 Threshold\n",
            "110 episode , 268 step , 0.07 Loss, 0.06 Threshold\n",
            "111 episode , 108 step , 0.12 Loss, 0.06 Threshold\n",
            "112 episode , 114 step , 0.07 Loss, 0.06 Threshold\n",
            "113 episode , 135 step , 0.07 Loss, 0.06 Threshold\n",
            "114 episode , 27 step , 0.08 Loss, 0.06 Threshold\n",
            "115 episode , 129 step , 0.08 Loss, 0.06 Threshold\n",
            "116 episode , 154 step , 0.09 Loss, 0.06 Threshold\n",
            "117 episode , 117 step , 0.08 Loss, 0.06 Threshold\n",
            "118 episode , 114 step , 0.08 Loss, 0.06 Threshold\n",
            "119 episode , 119 step , 0.07 Loss, 0.06 Threshold\n",
            "120 episode , 114 step , 0.08 Loss, 0.06 Threshold\n",
            "121 episode , 129 step , 0.12 Loss, 0.06 Threshold\n",
            "122 episode , 206 step , 0.09 Loss, 0.06 Threshold\n",
            "123 episode , 284 step , 0.09 Loss, 0.05 Threshold\n",
            "124 episode , 175 step , 0.09 Loss, 0.05 Threshold\n",
            "125 episode , 125 step , 0.08 Loss, 0.05 Threshold\n",
            "126 episode , 136 step , 0.08 Loss, 0.05 Threshold\n",
            "127 episode , 107 step , 0.07 Loss, 0.05 Threshold\n",
            "128 episode , 271 step , 0.08 Loss, 0.05 Threshold\n",
            "129 episode , 249 step , 0.07 Loss, 0.05 Threshold\n",
            "130 episode , 107 step , 0.07 Loss, 0.05 Threshold\n",
            "131 episode , 262 step , 0.09 Loss, 0.05 Threshold\n",
            "132 episode , 233 step , 0.07 Loss, 0.05 Threshold\n",
            "133 episode , 103 step , 0.09 Loss, 0.05 Threshold\n",
            "134 episode , 120 step , 0.07 Loss, 0.05 Threshold\n",
            "135 episode , 109 step , 0.07 Loss, 0.05 Threshold\n",
            "136 episode , 12 step , 0.08 Loss, 0.05 Threshold\n",
            "137 episode , 226 step , 0.07 Loss, 0.05 Threshold\n",
            "138 episode , 118 step , 0.08 Loss, 0.05 Threshold\n",
            "139 episode , 239 step , 0.06 Loss, 0.05 Threshold\n",
            "140 episode , 227 step , 0.07 Loss, 0.05 Threshold\n",
            "141 episode , 243 step , 0.08 Loss, 0.05 Threshold\n",
            "142 episode , 230 step , 0.07 Loss, 0.05 Threshold\n",
            "143 episode , 216 step , 0.07 Loss, 0.05 Threshold\n",
            "144 episode , 247 step , 0.07 Loss, 0.05 Threshold\n",
            "145 episode , 275 step , 0.07 Loss, 0.05 Threshold\n",
            "146 episode , 283 step , 0.07 Loss, 0.05 Threshold\n",
            "147 episode , 112 step , 0.07 Loss, 0.05 Threshold\n",
            "148 episode , 271 step , 0.07 Loss, 0.05 Threshold\n",
            "149 episode , 249 step , 0.06 Loss, 0.05 Threshold\n",
            "150 episode , 263 step , 0.05 Loss, 0.05 Threshold\n",
            "151 episode , 68 step , 0.11 Loss, 0.05 Threshold\n",
            "152 episode , 248 step , 0.06 Loss, 0.05 Threshold\n",
            "153 episode , 306 step , 0.06 Loss, 0.05 Threshold\n",
            "154 episode , 250 step , 0.06 Loss, 0.05 Threshold\n",
            "155 episode , 274 step , 0.06 Loss, 0.05 Threshold\n",
            "156 episode , 242 step , 0.06 Loss, 0.05 Threshold\n",
            "157 episode , 263 step , 0.05 Loss, 0.05 Threshold\n",
            "158 episode , 213 step , 0.06 Loss, 0.05 Threshold\n",
            "159 episode , 248 step , 0.05 Loss, 0.05 Threshold\n",
            "160 episode , 256 step , 0.04 Loss, 0.05 Threshold\n",
            "161 episode , 19 step , 0.18 Loss, 0.05 Threshold\n",
            "162 episode , 300 step , 0.04 Loss, 0.05 Threshold\n",
            "163 episode , 68 step , 0.05 Loss, 0.05 Threshold\n",
            "164 episode , 117 step , 0.04 Loss, 0.05 Threshold\n",
            "165 episode , 106 step , 0.05 Loss, 0.05 Threshold\n",
            "166 episode , 109 step , 0.06 Loss, 0.05 Threshold\n",
            "167 episode , 105 step , 0.04 Loss, 0.05 Threshold\n",
            "168 episode , 101 step , 0.05 Loss, 0.05 Threshold\n",
            "169 episode , 106 step , 0.05 Loss, 0.05 Threshold\n",
            "170 episode , 101 step , 0.05 Loss, 0.05 Threshold\n",
            "171 episode , 281 step , 0.07 Loss, 0.05 Threshold\n",
            "172 episode , 104 step , 0.05 Loss, 0.05 Threshold\n",
            "173 episode , 310 step , 0.05 Loss, 0.05 Threshold\n",
            "174 episode , 114 step , 0.05 Loss, 0.05 Threshold\n",
            "175 episode , 107 step , 0.05 Loss, 0.05 Threshold\n",
            "176 episode , 106 step , 0.06 Loss, 0.05 Threshold\n",
            "177 episode , 122 step , 0.06 Loss, 0.05 Threshold\n",
            "178 episode , 13 step , 0.06 Loss, 0.05 Threshold\n",
            "179 episode , 115 step , 0.06 Loss, 0.05 Threshold\n",
            "180 episode , 142 step , 0.07 Loss, 0.05 Threshold\n",
            "181 episode , 103 step , 0.09 Loss, 0.05 Threshold\n",
            "182 episode , 89 step , 0.07 Loss, 0.05 Threshold\n",
            "183 episode , 104 step , 0.08 Loss, 0.05 Threshold\n",
            "184 episode , 98 step , 0.08 Loss, 0.05 Threshold\n",
            "185 episode , 103 step , 0.07 Loss, 0.05 Threshold\n",
            "186 episode , 21 step , 0.07 Loss, 0.05 Threshold\n",
            "187 episode , 97 step , 0.08 Loss, 0.05 Threshold\n",
            "188 episode , 105 step , 0.08 Loss, 0.05 Threshold\n",
            "189 episode , 101 step , 0.08 Loss, 0.05 Threshold\n",
            "190 episode , 95 step , 0.11 Loss, 0.05 Threshold\n",
            "191 episode , 38 step , 0.16 Loss, 0.05 Threshold\n",
            "192 episode , 34 step , 0.06 Loss, 0.05 Threshold\n",
            "193 episode , 104 step , 0.08 Loss, 0.05 Threshold\n",
            "194 episode , 106 step , 0.10 Loss, 0.05 Threshold\n",
            "195 episode , 105 step , 0.10 Loss, 0.05 Threshold\n",
            "196 episode , 100 step , 0.12 Loss, 0.05 Threshold\n",
            "197 episode , 103 step , 0.11 Loss, 0.05 Threshold\n",
            "198 episode , 105 step , 0.10 Loss, 0.05 Threshold\n",
            "199 episode , 99 step , 0.10 Loss, 0.05 Threshold\n",
            "200 episode , 103 step , 0.13 Loss, 0.05 Threshold\n",
            "201 episode , 104 step , 0.13 Loss, 0.05 Threshold\n",
            "202 episode , 127 step , 0.11 Loss, 0.05 Threshold\n",
            "203 episode , 128 step , 0.09 Loss, 0.05 Threshold\n",
            "204 episode , 121 step , 0.11 Loss, 0.05 Threshold\n",
            "205 episode , 124 step , 0.12 Loss, 0.05 Threshold\n",
            "206 episode , 121 step , 0.12 Loss, 0.05 Threshold\n",
            "207 episode , 152 step , 0.11 Loss, 0.05 Threshold\n",
            "208 episode , 115 step , 0.13 Loss, 0.05 Threshold\n",
            "209 episode , 112 step , 0.14 Loss, 0.05 Threshold\n",
            "210 episode , 106 step , 0.12 Loss, 0.05 Threshold\n",
            "211 episode , 134 step , 0.17 Loss, 0.05 Threshold\n",
            "212 episode , 109 step , 0.12 Loss, 0.05 Threshold\n",
            "213 episode , 109 step , 0.11 Loss, 0.05 Threshold\n",
            "214 episode , 114 step , 0.15 Loss, 0.05 Threshold\n",
            "215 episode , 129 step , 0.12 Loss, 0.05 Threshold\n",
            "216 episode , 120 step , 0.14 Loss, 0.05 Threshold\n",
            "217 episode , 317 step , 0.13 Loss, 0.05 Threshold\n",
            "218 episode , 125 step , 0.15 Loss, 0.05 Threshold\n",
            "219 episode , 328 step , 0.15 Loss, 0.05 Threshold\n",
            "220 episode , 127 step , 0.15 Loss, 0.05 Threshold\n",
            "221 episode , 144 step , 0.20 Loss, 0.05 Threshold\n",
            "222 episode , 124 step , 0.17 Loss, 0.05 Threshold\n",
            "223 episode , 125 step , 0.15 Loss, 0.05 Threshold\n",
            "224 episode , 78 step , 0.17 Loss, 0.05 Threshold\n",
            "225 episode , 150 step , 0.15 Loss, 0.05 Threshold\n",
            "226 episode , 88 step , 0.16 Loss, 0.05 Threshold\n",
            "227 episode , 139 step , 0.17 Loss, 0.05 Threshold\n",
            "228 episode , 134 step , 0.16 Loss, 0.05 Threshold\n",
            "229 episode , 249 step , 0.15 Loss, 0.05 Threshold\n",
            "230 episode , 475 step , 0.18 Loss, 0.05 Threshold\n",
            "231 episode , 16 step , 0.39 Loss, 0.05 Threshold\n",
            "232 episode , 17 step , 0.25 Loss, 0.05 Threshold\n",
            "233 episode , 117 step , 0.17 Loss, 0.05 Threshold\n",
            "234 episode , 108 step , 0.19 Loss, 0.05 Threshold\n",
            "235 episode , 118 step , 0.19 Loss, 0.05 Threshold\n",
            "236 episode , 126 step , 0.19 Loss, 0.05 Threshold\n",
            "237 episode , 116 step , 0.20 Loss, 0.05 Threshold\n",
            "238 episode , 121 step , 0.18 Loss, 0.05 Threshold\n",
            "239 episode , 114 step , 0.18 Loss, 0.05 Threshold\n",
            "240 episode , 14 step , 0.24 Loss, 0.05 Threshold\n",
            "241 episode , 10 step , 0.47 Loss, 0.05 Threshold\n",
            "242 episode , 111 step , 0.22 Loss, 0.05 Threshold\n",
            "243 episode , 123 step , 0.21 Loss, 0.05 Threshold\n",
            "244 episode , 103 step , 0.20 Loss, 0.05 Threshold\n",
            "245 episode , 99 step , 0.21 Loss, 0.05 Threshold\n",
            "246 episode , 92 step , 0.23 Loss, 0.05 Threshold\n",
            "247 episode , 16 step , 0.21 Loss, 0.05 Threshold\n",
            "248 episode , 105 step , 0.21 Loss, 0.05 Threshold\n",
            "249 episode , 103 step , 0.18 Loss, 0.05 Threshold\n",
            "250 episode , 101 step , 0.22 Loss, 0.05 Threshold\n",
            "251 episode , 25 step , 0.34 Loss, 0.05 Threshold\n",
            "252 episode , 100 step , 0.23 Loss, 0.05 Threshold\n",
            "253 episode , 108 step , 0.21 Loss, 0.05 Threshold\n",
            "254 episode , 115 step , 0.22 Loss, 0.05 Threshold\n",
            "255 episode , 113 step , 0.25 Loss, 0.05 Threshold\n",
            "256 episode , 126 step , 0.22 Loss, 0.05 Threshold\n",
            "257 episode , 106 step , 0.23 Loss, 0.05 Threshold\n",
            "258 episode , 21 step , 0.26 Loss, 0.05 Threshold\n",
            "259 episode , 111 step , 0.21 Loss, 0.05 Threshold\n",
            "260 episode , 107 step , 0.18 Loss, 0.05 Threshold\n",
            "261 episode , 97 step , 0.24 Loss, 0.05 Threshold\n",
            "262 episode , 105 step , 0.20 Loss, 0.05 Threshold\n",
            "263 episode , 111 step , 0.20 Loss, 0.05 Threshold\n",
            "264 episode , 108 step , 0.22 Loss, 0.05 Threshold\n",
            "265 episode , 103 step , 0.19 Loss, 0.05 Threshold\n",
            "266 episode , 103 step , 0.24 Loss, 0.05 Threshold\n",
            "267 episode , 104 step , 0.19 Loss, 0.05 Threshold\n",
            "268 episode , 104 step , 0.21 Loss, 0.05 Threshold\n",
            "269 episode , 105 step , 0.19 Loss, 0.05 Threshold\n",
            "270 episode , 101 step , 0.22 Loss, 0.05 Threshold\n",
            "271 episode , 94 step , 0.24 Loss, 0.05 Threshold\n",
            "272 episode , 97 step , 0.19 Loss, 0.05 Threshold\n",
            "273 episode , 103 step , 0.24 Loss, 0.05 Threshold\n",
            "274 episode , 39 step , 0.17 Loss, 0.05 Threshold\n",
            "275 episode , 109 step , 0.21 Loss, 0.05 Threshold\n",
            "276 episode , 100 step , 0.24 Loss, 0.05 Threshold\n",
            "277 episode , 101 step , 0.23 Loss, 0.05 Threshold\n",
            "278 episode , 102 step , 0.18 Loss, 0.05 Threshold\n",
            "279 episode , 15 step , 0.23 Loss, 0.05 Threshold\n",
            "280 episode , 100 step , 0.23 Loss, 0.05 Threshold\n",
            "281 episode , 100 step , 0.24 Loss, 0.05 Threshold\n",
            "282 episode , 39 step , 0.18 Loss, 0.05 Threshold\n",
            "283 episode , 92 step , 0.22 Loss, 0.05 Threshold\n",
            "284 episode , 95 step , 0.20 Loss, 0.05 Threshold\n",
            "285 episode , 20 step , 0.18 Loss, 0.05 Threshold\n",
            "286 episode , 103 step , 0.23 Loss, 0.05 Threshold\n",
            "287 episode , 103 step , 0.23 Loss, 0.05 Threshold\n",
            "288 episode , 99 step , 0.22 Loss, 0.05 Threshold\n",
            "289 episode , 99 step , 0.21 Loss, 0.05 Threshold\n",
            "290 episode , 104 step , 0.21 Loss, 0.05 Threshold\n",
            "291 episode , 97 step , 0.27 Loss, 0.05 Threshold\n",
            "292 episode , 94 step , 0.20 Loss, 0.05 Threshold\n",
            "293 episode , 93 step , 0.23 Loss, 0.05 Threshold\n",
            "294 episode , 92 step , 0.22 Loss, 0.05 Threshold\n",
            "295 episode , 94 step , 0.23 Loss, 0.05 Threshold\n",
            "296 episode , 100 step , 0.22 Loss, 0.05 Threshold\n",
            "297 episode , 21 step , 0.25 Loss, 0.05 Threshold\n",
            "298 episode , 95 step , 0.24 Loss, 0.05 Threshold\n",
            "299 episode , 12 step , 0.23 Loss, 0.05 Threshold\n",
            "300 episode , 96 step , 0.24 Loss, 0.05 Threshold\n",
            "301 episode , 141 step , 0.25 Loss, 0.05 Threshold\n",
            "302 episode , 149 step , 0.22 Loss, 0.05 Threshold\n",
            "303 episode , 12 step , 0.29 Loss, 0.05 Threshold\n",
            "304 episode , 112 step , 0.23 Loss, 0.05 Threshold\n",
            "305 episode , 97 step , 0.24 Loss, 0.05 Threshold\n",
            "306 episode , 112 step , 0.23 Loss, 0.05 Threshold\n",
            "307 episode , 108 step , 0.24 Loss, 0.05 Threshold\n",
            "308 episode , 110 step , 0.22 Loss, 0.05 Threshold\n",
            "309 episode , 100 step , 0.25 Loss, 0.05 Threshold\n",
            "310 episode , 132 step , 0.21 Loss, 0.05 Threshold\n",
            "311 episode , 102 step , 0.24 Loss, 0.05 Threshold\n",
            "312 episode , 97 step , 0.23 Loss, 0.05 Threshold\n",
            "313 episode , 95 step , 0.21 Loss, 0.05 Threshold\n",
            "314 episode , 33 step , 0.32 Loss, 0.05 Threshold\n",
            "315 episode , 96 step , 0.24 Loss, 0.05 Threshold\n",
            "316 episode , 94 step , 0.28 Loss, 0.05 Threshold\n",
            "317 episode , 134 step , 0.25 Loss, 0.05 Threshold\n",
            "318 episode , 28 step , 0.19 Loss, 0.05 Threshold\n",
            "319 episode , 17 step , 0.23 Loss, 0.05 Threshold\n",
            "320 episode , 45 step , 0.27 Loss, 0.05 Threshold\n",
            "321 episode , 105 step , 0.29 Loss, 0.05 Threshold\n",
            "322 episode , 82 step , 0.25 Loss, 0.05 Threshold\n",
            "323 episode , 63 step , 0.20 Loss, 0.05 Threshold\n",
            "324 episode , 111 step , 0.29 Loss, 0.05 Threshold\n",
            "325 episode , 101 step , 0.22 Loss, 0.05 Threshold\n",
            "326 episode , 141 step , 0.24 Loss, 0.05 Threshold\n",
            "327 episode , 101 step , 0.21 Loss, 0.05 Threshold\n",
            "328 episode , 40 step , 0.29 Loss, 0.05 Threshold\n",
            "329 episode , 95 step , 0.23 Loss, 0.05 Threshold\n",
            "330 episode , 112 step , 0.23 Loss, 0.05 Threshold\n",
            "331 episode , 129 step , 0.30 Loss, 0.05 Threshold\n",
            "332 episode , 95 step , 0.27 Loss, 0.05 Threshold\n",
            "333 episode , 104 step , 0.24 Loss, 0.05 Threshold\n",
            "334 episode , 41 step , 0.22 Loss, 0.05 Threshold\n",
            "335 episode , 42 step , 0.22 Loss, 0.05 Threshold\n",
            "336 episode , 96 step , 0.27 Loss, 0.05 Threshold\n",
            "337 episode , 100 step , 0.27 Loss, 0.05 Threshold\n",
            "338 episode , 102 step , 0.27 Loss, 0.05 Threshold\n",
            "339 episode , 16 step , 0.18 Loss, 0.05 Threshold\n",
            "340 episode , 100 step , 0.25 Loss, 0.05 Threshold\n",
            "341 episode , 96 step , 0.29 Loss, 0.05 Threshold\n",
            "342 episode , 119 step , 0.26 Loss, 0.05 Threshold\n",
            "343 episode , 102 step , 0.25 Loss, 0.05 Threshold\n",
            "344 episode , 107 step , 0.26 Loss, 0.05 Threshold\n",
            "345 episode , 99 step , 0.28 Loss, 0.05 Threshold\n",
            "346 episode , 110 step , 0.26 Loss, 0.05 Threshold\n",
            "347 episode , 103 step , 0.28 Loss, 0.05 Threshold\n",
            "348 episode , 92 step , 0.26 Loss, 0.05 Threshold\n",
            "349 episode , 102 step , 0.28 Loss, 0.05 Threshold\n",
            "350 episode , 102 step , 0.28 Loss, 0.05 Threshold\n",
            "351 episode , 117 step , 0.29 Loss, 0.05 Threshold\n",
            "352 episode , 97 step , 0.27 Loss, 0.05 Threshold\n",
            "353 episode , 100 step , 0.28 Loss, 0.05 Threshold\n",
            "354 episode , 96 step , 0.24 Loss, 0.05 Threshold\n",
            "355 episode , 94 step , 0.24 Loss, 0.05 Threshold\n",
            "356 episode , 96 step , 0.27 Loss, 0.05 Threshold\n",
            "357 episode , 98 step , 0.30 Loss, 0.05 Threshold\n",
            "358 episode , 40 step , 0.26 Loss, 0.05 Threshold\n",
            "359 episode , 33 step , 0.25 Loss, 0.05 Threshold\n",
            "360 episode , 100 step , 0.29 Loss, 0.05 Threshold\n",
            "361 episode , 122 step , 0.28 Loss, 0.05 Threshold\n",
            "362 episode , 97 step , 0.24 Loss, 0.05 Threshold\n",
            "363 episode , 94 step , 0.28 Loss, 0.05 Threshold\n",
            "364 episode , 99 step , 0.28 Loss, 0.05 Threshold\n",
            "365 episode , 101 step , 0.29 Loss, 0.05 Threshold\n",
            "366 episode , 89 step , 0.27 Loss, 0.05 Threshold\n",
            "367 episode , 87 step , 0.29 Loss, 0.05 Threshold\n",
            "368 episode , 107 step , 0.25 Loss, 0.05 Threshold\n",
            "369 episode , 96 step , 0.30 Loss, 0.05 Threshold\n",
            "370 episode , 91 step , 0.29 Loss, 0.05 Threshold\n",
            "371 episode , 118 step , 0.31 Loss, 0.05 Threshold\n",
            "372 episode , 157 step , 0.26 Loss, 0.05 Threshold\n",
            "373 episode , 112 step , 0.23 Loss, 0.05 Threshold\n",
            "374 episode , 117 step , 0.26 Loss, 0.05 Threshold\n",
            "375 episode , 118 step , 0.30 Loss, 0.05 Threshold\n",
            "376 episode , 129 step , 0.26 Loss, 0.05 Threshold\n",
            "377 episode , 136 step , 0.25 Loss, 0.05 Threshold\n",
            "378 episode , 109 step , 0.29 Loss, 0.05 Threshold\n",
            "379 episode , 109 step , 0.29 Loss, 0.05 Threshold\n",
            "380 episode , 122 step , 0.32 Loss, 0.05 Threshold\n",
            "381 episode , 13 step , 0.38 Loss, 0.05 Threshold\n",
            "382 episode , 24 step , 0.25 Loss, 0.05 Threshold\n",
            "383 episode , 100 step , 0.26 Loss, 0.05 Threshold\n",
            "384 episode , 97 step , 0.27 Loss, 0.05 Threshold\n",
            "385 episode , 110 step , 0.25 Loss, 0.05 Threshold\n",
            "386 episode , 93 step , 0.27 Loss, 0.05 Threshold\n",
            "387 episode , 96 step , 0.32 Loss, 0.05 Threshold\n",
            "388 episode , 95 step , 0.28 Loss, 0.05 Threshold\n",
            "389 episode , 90 step , 0.23 Loss, 0.05 Threshold\n",
            "390 episode , 93 step , 0.27 Loss, 0.05 Threshold\n",
            "391 episode , 25 step , 0.29 Loss, 0.05 Threshold\n",
            "392 episode , 35 step , 0.27 Loss, 0.05 Threshold\n",
            "393 episode , 37 step , 0.26 Loss, 0.05 Threshold\n",
            "394 episode , 107 step , 0.28 Loss, 0.05 Threshold\n",
            "395 episode , 104 step , 0.25 Loss, 0.05 Threshold\n",
            "396 episode , 104 step , 0.28 Loss, 0.05 Threshold\n",
            "397 episode , 113 step , 0.27 Loss, 0.05 Threshold\n",
            "398 episode , 97 step , 0.28 Loss, 0.05 Threshold\n",
            "399 episode , 102 step , 0.26 Loss, 0.05 Threshold\n",
            "400 episode , 96 step , 0.26 Loss, 0.05 Threshold\n",
            "401 episode , 153 step , 0.27 Loss, 0.05 Threshold\n",
            "402 episode , 15 step , 0.35 Loss, 0.05 Threshold\n",
            "403 episode , 141 step , 0.27 Loss, 0.05 Threshold\n",
            "404 episode , 31 step , 0.32 Loss, 0.05 Threshold\n",
            "405 episode , 11 step , 0.29 Loss, 0.05 Threshold\n",
            "406 episode , 36 step , 0.32 Loss, 0.05 Threshold\n",
            "407 episode , 64 step , 0.31 Loss, 0.05 Threshold\n",
            "408 episode , 228 step , 0.27 Loss, 0.05 Threshold\n",
            "409 episode , 150 step , 0.32 Loss, 0.05 Threshold\n",
            "410 episode , 284 step , 0.29 Loss, 0.05 Threshold\n",
            "411 episode , 123 step , 0.30 Loss, 0.05 Threshold\n",
            "412 episode , 118 step , 0.27 Loss, 0.05 Threshold\n",
            "413 episode , 138 step , 0.27 Loss, 0.05 Threshold\n",
            "414 episode , 173 step , 0.27 Loss, 0.05 Threshold\n",
            "415 episode , 112 step , 0.28 Loss, 0.05 Threshold\n",
            "416 episode , 199 step , 0.26 Loss, 0.05 Threshold\n",
            "417 episode , 260 step , 0.28 Loss, 0.05 Threshold\n",
            "418 episode , 360 step , 0.28 Loss, 0.05 Threshold\n",
            "419 episode , 308 step , 0.24 Loss, 0.05 Threshold\n",
            "420 episode , 358 step , 0.26 Loss, 0.05 Threshold\n",
            "421 episode , 500 step , 0.24 Loss, 0.05 Threshold\n",
            "422 episode , 500 step , 0.24 Loss, 0.05 Threshold\n",
            "423 episode , 500 step , 0.22 Loss, 0.05 Threshold\n",
            "424 episode , 500 step , 0.23 Loss, 0.05 Threshold\n",
            "425 episode , 21 step , 0.22 Loss, 0.05 Threshold\n",
            "426 episode , 500 step , 0.22 Loss, 0.05 Threshold\n",
            "427 episode , 500 step , 0.21 Loss, 0.05 Threshold\n",
            "428 episode , 500 step , 0.21 Loss, 0.05 Threshold\n",
            "429 episode , 500 step , 0.20 Loss, 0.05 Threshold\n",
            "430 episode , 83 step , 0.22 Loss, 0.05 Threshold\n",
            "431 episode , 500 step , 0.18 Loss, 0.05 Threshold\n",
            "432 episode , 500 step , 0.17 Loss, 0.05 Threshold\n",
            "433 episode , 500 step , 0.17 Loss, 0.05 Threshold\n",
            "434 episode , 500 step , 0.15 Loss, 0.05 Threshold\n",
            "435 episode , 422 step , 0.14 Loss, 0.05 Threshold\n",
            "436 episode , 500 step , 0.14 Loss, 0.05 Threshold\n",
            "437 episode , 500 step , 0.12 Loss, 0.05 Threshold\n",
            "438 episode , 500 step , 0.11 Loss, 0.05 Threshold\n",
            "439 episode , 500 step , 0.10 Loss, 0.05 Threshold\n",
            "440 episode , 21 step , 0.10 Loss, 0.05 Threshold\n",
            "441 episode , 500 step , 0.10 Loss, 0.05 Threshold\n",
            "442 episode , 12 step , 0.18 Loss, 0.05 Threshold\n",
            "443 episode , 500 step , 0.09 Loss, 0.05 Threshold\n",
            "444 episode , 500 step , 0.09 Loss, 0.05 Threshold\n",
            "445 episode , 500 step , 0.10 Loss, 0.05 Threshold\n",
            "446 episode , 500 step , 0.10 Loss, 0.05 Threshold\n",
            "447 episode , 15 step , 0.13 Loss, 0.05 Threshold\n",
            "448 episode , 500 step , 0.10 Loss, 0.05 Threshold\n",
            "449 episode , 500 step , 0.11 Loss, 0.05 Threshold\n",
            "450 episode , 500 step , 0.10 Loss, 0.05 Threshold\n",
            "451 episode , 500 step , 0.11 Loss, 0.05 Threshold\n",
            "452 episode , 30 step , 0.09 Loss, 0.05 Threshold\n",
            "453 episode , 100 step , 0.08 Loss, 0.05 Threshold\n",
            "454 episode , 500 step , 0.10 Loss, 0.05 Threshold\n",
            "455 episode , 115 step , 0.14 Loss, 0.05 Threshold\n",
            "456 episode , 17 step , 0.13 Loss, 0.05 Threshold\n",
            "457 episode , 107 step , 0.12 Loss, 0.05 Threshold\n",
            "458 episode , 98 step , 0.11 Loss, 0.05 Threshold\n",
            "459 episode , 392 step , 0.10 Loss, 0.05 Threshold\n",
            "460 episode , 86 step , 0.13 Loss, 0.05 Threshold\n",
            "461 episode , 500 step , 0.13 Loss, 0.05 Threshold\n",
            "462 episode , 109 step , 0.11 Loss, 0.05 Threshold\n",
            "463 episode , 14 step , 0.23 Loss, 0.05 Threshold\n",
            "464 episode , 12 step , 0.10 Loss, 0.05 Threshold\n",
            "465 episode , 125 step , 0.11 Loss, 0.05 Threshold\n",
            "466 episode , 112 step , 0.09 Loss, 0.05 Threshold\n",
            "467 episode , 500 step , 0.12 Loss, 0.05 Threshold\n",
            "468 episode , 22 step , 0.07 Loss, 0.05 Threshold\n",
            "469 episode , 15 step , 0.12 Loss, 0.05 Threshold\n",
            "470 episode , 125 step , 0.15 Loss, 0.05 Threshold\n",
            "471 episode , 500 step , 0.16 Loss, 0.05 Threshold\n",
            "472 episode , 500 step , 0.16 Loss, 0.05 Threshold\n",
            "473 episode , 500 step , 0.16 Loss, 0.05 Threshold\n",
            "474 episode , 500 step , 0.16 Loss, 0.05 Threshold\n",
            "475 episode , 500 step , 0.16 Loss, 0.05 Threshold\n",
            "476 episode , 18 step , 0.16 Loss, 0.05 Threshold\n",
            "477 episode , 500 step , 0.14 Loss, 0.05 Threshold\n",
            "478 episode , 500 step , 0.15 Loss, 0.05 Threshold\n",
            "479 episode , 500 step , 0.13 Loss, 0.05 Threshold\n",
            "480 episode , 21 step , 0.18 Loss, 0.05 Threshold\n",
            "481 episode , 500 step , 0.17 Loss, 0.05 Threshold\n",
            "482 episode , 500 step , 0.15 Loss, 0.05 Threshold\n",
            "483 episode , 500 step , 0.14 Loss, 0.05 Threshold\n",
            "484 episode , 500 step , 0.16 Loss, 0.05 Threshold\n",
            "485 episode , 500 step , 0.14 Loss, 0.05 Threshold\n",
            "486 episode , 500 step , 0.17 Loss, 0.05 Threshold\n",
            "487 episode , 500 step , 0.14 Loss, 0.05 Threshold\n",
            "488 episode , 500 step , 0.14 Loss, 0.05 Threshold\n",
            "489 episode , 500 step , 0.15 Loss, 0.05 Threshold\n",
            "490 episode , 26 step , 0.17 Loss, 0.05 Threshold\n",
            "491 episode , 500 step , 0.14 Loss, 0.05 Threshold\n",
            "492 episode , 500 step , 0.13 Loss, 0.05 Threshold\n",
            "493 episode , 500 step , 0.12 Loss, 0.05 Threshold\n",
            "494 episode , 500 step , 0.12 Loss, 0.05 Threshold\n",
            "495 episode , 500 step , 0.09 Loss, 0.05 Threshold\n",
            "496 episode , 500 step , 0.11 Loss, 0.05 Threshold\n",
            "497 episode , 188 step , 0.12 Loss, 0.05 Threshold\n",
            "498 episode , 112 step , 0.11 Loss, 0.05 Threshold\n",
            "499 episode , 95 step , 0.08 Loss, 0.05 Threshold\n",
            "500 episode , 192 step , 0.10 Loss, 0.05 Threshold\n",
            "501 episode , 25 step , 0.19 Loss, 0.05 Threshold\n",
            "502 episode , 500 step , 0.13 Loss, 0.05 Threshold\n",
            "503 episode , 184 step , 0.14 Loss, 0.05 Threshold\n",
            "504 episode , 15 step , 0.11 Loss, 0.05 Threshold\n",
            "505 episode , 422 step , 0.14 Loss, 0.05 Threshold\n",
            "506 episode , 115 step , 0.14 Loss, 0.05 Threshold\n",
            "507 episode , 388 step , 0.11 Loss, 0.05 Threshold\n",
            "508 episode , 10 step , 0.04 Loss, 0.05 Threshold\n",
            "509 episode , 52 step , 0.22 Loss, 0.05 Threshold\n",
            "510 episode , 500 step , 0.15 Loss, 0.05 Threshold\n",
            "511 episode , 63 step , 0.23 Loss, 0.05 Threshold\n",
            "512 episode , 500 step , 0.15 Loss, 0.05 Threshold\n",
            "513 episode , 232 step , 0.14 Loss, 0.05 Threshold\n",
            "514 episode , 443 step , 0.15 Loss, 0.05 Threshold\n",
            "515 episode , 204 step , 0.15 Loss, 0.05 Threshold\n",
            "516 episode , 20 step , 0.24 Loss, 0.05 Threshold\n",
            "517 episode , 21 step , 0.17 Loss, 0.05 Threshold\n",
            "518 episode , 500 step , 0.15 Loss, 0.05 Threshold\n",
            "519 episode , 78 step , 0.21 Loss, 0.05 Threshold\n",
            "520 episode , 361 step , 0.16 Loss, 0.05 Threshold\n",
            "521 episode , 20 step , 0.35 Loss, 0.05 Threshold\n",
            "522 episode , 500 step , 0.18 Loss, 0.05 Threshold\n",
            "523 episode , 500 step , 0.17 Loss, 0.05 Threshold\n",
            "524 episode , 500 step , 0.16 Loss, 0.05 Threshold\n",
            "525 episode , 500 step , 0.17 Loss, 0.05 Threshold\n",
            "526 episode , 31 step , 0.14 Loss, 0.05 Threshold\n",
            "527 episode , 338 step , 0.17 Loss, 0.05 Threshold\n",
            "528 episode , 500 step , 0.16 Loss, 0.05 Threshold\n",
            "529 episode , 500 step , 0.16 Loss, 0.05 Threshold\n",
            "530 episode , 500 step , 0.16 Loss, 0.05 Threshold\n",
            "531 episode , 148 step , 0.21 Loss, 0.05 Threshold\n",
            "532 episode , 159 step , 0.21 Loss, 0.05 Threshold\n",
            "533 episode , 255 step , 0.18 Loss, 0.05 Threshold\n",
            "534 episode , 277 step , 0.22 Loss, 0.05 Threshold\n",
            "535 episode , 258 step , 0.20 Loss, 0.05 Threshold\n",
            "536 episode , 158 step , 0.18 Loss, 0.05 Threshold\n",
            "537 episode , 134 step , 0.22 Loss, 0.05 Threshold\n",
            "538 episode , 185 step , 0.20 Loss, 0.05 Threshold\n",
            "539 episode , 184 step , 0.20 Loss, 0.05 Threshold\n",
            "540 episode , 172 step , 0.21 Loss, 0.05 Threshold\n",
            "541 episode , 133 step , 0.23 Loss, 0.05 Threshold\n",
            "542 episode , 152 step , 0.19 Loss, 0.05 Threshold\n",
            "543 episode , 500 step , 0.19 Loss, 0.05 Threshold\n",
            "544 episode , 203 step , 0.16 Loss, 0.05 Threshold\n",
            "545 episode , 273 step , 0.17 Loss, 0.05 Threshold\n",
            "546 episode , 198 step , 0.17 Loss, 0.05 Threshold\n",
            "547 episode , 144 step , 0.16 Loss, 0.05 Threshold\n",
            "548 episode , 185 step , 0.20 Loss, 0.05 Threshold\n",
            "549 episode , 188 step , 0.19 Loss, 0.05 Threshold\n",
            "550 episode , 356 step , 0.18 Loss, 0.05 Threshold\n",
            "551 episode , 132 step , 0.23 Loss, 0.05 Threshold\n",
            "552 episode , 199 step , 0.17 Loss, 0.05 Threshold\n",
            "553 episode , 308 step , 0.19 Loss, 0.05 Threshold\n",
            "554 episode , 161 step , 0.18 Loss, 0.05 Threshold\n",
            "555 episode , 139 step , 0.18 Loss, 0.05 Threshold\n",
            "556 episode , 134 step , 0.17 Loss, 0.05 Threshold\n",
            "557 episode , 136 step , 0.16 Loss, 0.05 Threshold\n",
            "558 episode , 120 step , 0.19 Loss, 0.05 Threshold\n",
            "559 episode , 125 step , 0.19 Loss, 0.05 Threshold\n",
            "560 episode , 97 step , 0.14 Loss, 0.05 Threshold\n",
            "561 episode , 112 step , 0.25 Loss, 0.05 Threshold\n",
            "562 episode , 130 step , 0.18 Loss, 0.05 Threshold\n",
            "563 episode , 44 step , 0.18 Loss, 0.05 Threshold\n",
            "564 episode , 143 step , 0.16 Loss, 0.05 Threshold\n",
            "565 episode , 162 step , 0.17 Loss, 0.05 Threshold\n",
            "566 episode , 59 step , 0.19 Loss, 0.05 Threshold\n",
            "567 episode , 198 step , 0.19 Loss, 0.05 Threshold\n",
            "568 episode , 64 step , 0.22 Loss, 0.05 Threshold\n",
            "569 episode , 193 step , 0.19 Loss, 0.05 Threshold\n",
            "570 episode , 225 step , 0.20 Loss, 0.05 Threshold\n",
            "571 episode , 53 step , 0.21 Loss, 0.05 Threshold\n",
            "572 episode , 52 step , 0.19 Loss, 0.05 Threshold\n",
            "573 episode , 119 step , 0.22 Loss, 0.05 Threshold\n",
            "574 episode , 17 step , 0.17 Loss, 0.05 Threshold\n",
            "575 episode , 197 step , 0.21 Loss, 0.05 Threshold\n",
            "576 episode , 135 step , 0.20 Loss, 0.05 Threshold\n",
            "577 episode , 131 step , 0.20 Loss, 0.05 Threshold\n",
            "578 episode , 131 step , 0.23 Loss, 0.05 Threshold\n",
            "579 episode , 138 step , 0.22 Loss, 0.05 Threshold\n",
            "580 episode , 137 step , 0.19 Loss, 0.05 Threshold\n",
            "581 episode , 163 step , 0.22 Loss, 0.05 Threshold\n",
            "582 episode , 52 step , 0.22 Loss, 0.05 Threshold\n",
            "583 episode , 98 step , 0.23 Loss, 0.05 Threshold\n",
            "584 episode , 75 step , 0.25 Loss, 0.05 Threshold\n",
            "585 episode , 265 step , 0.22 Loss, 0.05 Threshold\n",
            "586 episode , 72 step , 0.25 Loss, 0.05 Threshold\n",
            "587 episode , 238 step , 0.25 Loss, 0.05 Threshold\n",
            "588 episode , 321 step , 0.22 Loss, 0.05 Threshold\n",
            "589 episode , 90 step , 0.24 Loss, 0.05 Threshold\n",
            "590 episode , 145 step , 0.26 Loss, 0.05 Threshold\n",
            "591 episode , 163 step , 0.28 Loss, 0.05 Threshold\n",
            "592 episode , 132 step , 0.23 Loss, 0.05 Threshold\n",
            "593 episode , 153 step , 0.26 Loss, 0.05 Threshold\n",
            "594 episode , 165 step , 0.27 Loss, 0.05 Threshold\n",
            "595 episode , 133 step , 0.24 Loss, 0.05 Threshold\n",
            "596 episode , 224 step , 0.24 Loss, 0.05 Threshold\n",
            "597 episode , 173 step , 0.22 Loss, 0.05 Threshold\n",
            "598 episode , 196 step , 0.19 Loss, 0.05 Threshold\n",
            "599 episode , 159 step , 0.21 Loss, 0.05 Threshold\n",
            "600 episode , 122 step , 0.20 Loss, 0.05 Threshold\n",
            "601 episode , 85 step , 0.20 Loss, 0.05 Threshold\n",
            "602 episode , 112 step , 0.21 Loss, 0.05 Threshold\n",
            "603 episode , 48 step , 0.20 Loss, 0.05 Threshold\n",
            "604 episode , 82 step , 0.21 Loss, 0.05 Threshold\n",
            "605 episode , 125 step , 0.22 Loss, 0.05 Threshold\n",
            "606 episode , 121 step , 0.31 Loss, 0.05 Threshold\n",
            "607 episode , 34 step , 0.25 Loss, 0.05 Threshold\n",
            "608 episode , 120 step , 0.26 Loss, 0.05 Threshold\n",
            "609 episode , 58 step , 0.27 Loss, 0.05 Threshold\n",
            "610 episode , 112 step , 0.24 Loss, 0.05 Threshold\n",
            "611 episode , 86 step , 0.31 Loss, 0.05 Threshold\n",
            "612 episode , 56 step , 0.31 Loss, 0.05 Threshold\n",
            "613 episode , 77 step , 0.32 Loss, 0.05 Threshold\n",
            "614 episode , 59 step , 0.28 Loss, 0.05 Threshold\n",
            "615 episode , 44 step , 0.26 Loss, 0.05 Threshold\n",
            "616 episode , 82 step , 0.26 Loss, 0.05 Threshold\n",
            "617 episode , 65 step , 0.27 Loss, 0.05 Threshold\n",
            "618 episode , 83 step , 0.27 Loss, 0.05 Threshold\n",
            "619 episode , 85 step , 0.30 Loss, 0.05 Threshold\n",
            "620 episode , 43 step , 0.39 Loss, 0.05 Threshold\n",
            "621 episode , 59 step , 0.32 Loss, 0.05 Threshold\n",
            "622 episode , 85 step , 0.32 Loss, 0.05 Threshold\n",
            "623 episode , 48 step , 0.31 Loss, 0.05 Threshold\n",
            "624 episode , 12 step , 0.23 Loss, 0.05 Threshold\n",
            "625 episode , 15 step , 0.22 Loss, 0.05 Threshold\n",
            "626 episode , 75 step , 0.28 Loss, 0.05 Threshold\n",
            "627 episode , 41 step , 0.34 Loss, 0.05 Threshold\n",
            "628 episode , 67 step , 0.36 Loss, 0.05 Threshold\n",
            "629 episode , 61 step , 0.33 Loss, 0.05 Threshold\n",
            "630 episode , 18 step , 0.35 Loss, 0.05 Threshold\n",
            "631 episode , 34 step , 0.47 Loss, 0.05 Threshold\n",
            "632 episode , 54 step , 0.34 Loss, 0.05 Threshold\n",
            "633 episode , 51 step , 0.34 Loss, 0.05 Threshold\n",
            "634 episode , 36 step , 0.34 Loss, 0.05 Threshold\n",
            "635 episode , 46 step , 0.31 Loss, 0.05 Threshold\n",
            "636 episode , 71 step , 0.32 Loss, 0.05 Threshold\n",
            "637 episode , 44 step , 0.35 Loss, 0.05 Threshold\n",
            "638 episode , 28 step , 0.35 Loss, 0.05 Threshold\n",
            "639 episode , 79 step , 0.35 Loss, 0.05 Threshold\n",
            "640 episode , 27 step , 0.31 Loss, 0.05 Threshold\n",
            "641 episode , 43 step , 0.35 Loss, 0.05 Threshold\n",
            "642 episode , 30 step , 0.44 Loss, 0.05 Threshold\n",
            "643 episode , 22 step , 0.43 Loss, 0.05 Threshold\n",
            "644 episode , 18 step , 0.36 Loss, 0.05 Threshold\n",
            "645 episode , 19 step , 0.49 Loss, 0.05 Threshold\n",
            "646 episode , 22 step , 0.46 Loss, 0.05 Threshold\n",
            "647 episode , 30 step , 0.44 Loss, 0.05 Threshold\n",
            "648 episode , 19 step , 0.34 Loss, 0.05 Threshold\n",
            "649 episode , 25 step , 0.52 Loss, 0.05 Threshold\n",
            "650 episode , 17 step , 0.45 Loss, 0.05 Threshold\n",
            "651 episode , 47 step , 0.45 Loss, 0.05 Threshold\n",
            "652 episode , 61 step , 0.50 Loss, 0.05 Threshold\n",
            "653 episode , 40 step , 0.41 Loss, 0.05 Threshold\n",
            "654 episode , 13 step , 0.56 Loss, 0.05 Threshold\n",
            "655 episode , 24 step , 0.47 Loss, 0.05 Threshold\n",
            "656 episode , 93 step , 0.48 Loss, 0.05 Threshold\n",
            "657 episode , 38 step , 0.63 Loss, 0.05 Threshold\n",
            "658 episode , 20 step , 0.37 Loss, 0.05 Threshold\n",
            "659 episode , 26 step , 0.54 Loss, 0.05 Threshold\n",
            "660 episode , 20 step , 0.52 Loss, 0.05 Threshold\n",
            "661 episode , 500 step , 0.50 Loss, 0.05 Threshold\n",
            "662 episode , 324 step , 0.54 Loss, 0.05 Threshold\n",
            "663 episode , 500 step , 0.49 Loss, 0.05 Threshold\n",
            "664 episode , 470 step , 0.48 Loss, 0.05 Threshold\n",
            "665 episode , 500 step , 0.48 Loss, 0.05 Threshold\n",
            "666 episode , 500 step , 0.48 Loss, 0.05 Threshold\n",
            "667 episode , 500 step , 0.45 Loss, 0.05 Threshold\n",
            "668 episode , 500 step , 0.41 Loss, 0.05 Threshold\n",
            "669 episode , 500 step , 0.46 Loss, 0.05 Threshold\n",
            "670 episode , 141 step , 0.48 Loss, 0.05 Threshold\n",
            "671 episode , 500 step , 0.47 Loss, 0.05 Threshold\n",
            "672 episode , 500 step , 0.47 Loss, 0.05 Threshold\n",
            "673 episode , 500 step , 0.44 Loss, 0.05 Threshold\n",
            "674 episode , 385 step , 0.45 Loss, 0.05 Threshold\n",
            "675 episode , 164 step , 0.42 Loss, 0.05 Threshold\n",
            "676 episode , 500 step , 0.45 Loss, 0.05 Threshold\n",
            "677 episode , 149 step , 0.43 Loss, 0.05 Threshold\n",
            "678 episode , 500 step , 0.41 Loss, 0.05 Threshold\n",
            "679 episode , 140 step , 0.39 Loss, 0.05 Threshold\n",
            "680 episode , 141 step , 0.37 Loss, 0.05 Threshold\n",
            "681 episode , 132 step , 0.41 Loss, 0.05 Threshold\n",
            "682 episode , 144 step , 0.37 Loss, 0.05 Threshold\n",
            "683 episode , 137 step , 0.36 Loss, 0.05 Threshold\n",
            "684 episode , 148 step , 0.33 Loss, 0.05 Threshold\n",
            "685 episode , 127 step , 0.35 Loss, 0.05 Threshold\n",
            "686 episode , 124 step , 0.33 Loss, 0.05 Threshold\n",
            "687 episode , 122 step , 0.30 Loss, 0.05 Threshold\n",
            "688 episode , 122 step , 0.38 Loss, 0.05 Threshold\n",
            "689 episode , 500 step , 0.28 Loss, 0.05 Threshold\n",
            "690 episode , 122 step , 0.19 Loss, 0.05 Threshold\n",
            "691 episode , 148 step , 0.26 Loss, 0.05 Threshold\n",
            "692 episode , 139 step , 0.24 Loss, 0.05 Threshold\n",
            "693 episode , 145 step , 0.23 Loss, 0.05 Threshold\n",
            "694 episode , 151 step , 0.19 Loss, 0.05 Threshold\n",
            "695 episode , 159 step , 0.25 Loss, 0.05 Threshold\n",
            "696 episode , 148 step , 0.22 Loss, 0.05 Threshold\n",
            "697 episode , 169 step , 0.22 Loss, 0.05 Threshold\n",
            "698 episode , 143 step , 0.26 Loss, 0.05 Threshold\n",
            "699 episode , 154 step , 0.29 Loss, 0.05 Threshold\n",
            "700 episode , 162 step , 0.24 Loss, 0.05 Threshold\n",
            "701 episode , 500 step , 0.26 Loss, 0.05 Threshold\n",
            "702 episode , 500 step , 0.25 Loss, 0.05 Threshold\n",
            "703 episode , 500 step , 0.25 Loss, 0.05 Threshold\n",
            "704 episode , 500 step , 0.23 Loss, 0.05 Threshold\n",
            "705 episode , 500 step , 0.24 Loss, 0.05 Threshold\n",
            "706 episode , 500 step , 0.24 Loss, 0.05 Threshold\n",
            "707 episode , 500 step , 0.24 Loss, 0.05 Threshold\n",
            "708 episode , 500 step , 0.23 Loss, 0.05 Threshold\n",
            "709 episode , 500 step , 0.24 Loss, 0.05 Threshold\n",
            "710 episode , 500 step , 0.23 Loss, 0.05 Threshold\n",
            "711 episode , 344 step , 0.24 Loss, 0.05 Threshold\n",
            "712 episode , 500 step , 0.26 Loss, 0.05 Threshold\n",
            "713 episode , 392 step , 0.23 Loss, 0.05 Threshold\n",
            "714 episode , 447 step , 0.21 Loss, 0.05 Threshold\n",
            "715 episode , 500 step , 0.22 Loss, 0.05 Threshold\n",
            "716 episode , 500 step , 0.22 Loss, 0.05 Threshold\n",
            "717 episode , 500 step , 0.20 Loss, 0.05 Threshold\n",
            "718 episode , 500 step , 0.18 Loss, 0.05 Threshold\n",
            "719 episode , 500 step , 0.15 Loss, 0.05 Threshold\n",
            "720 episode , 500 step , 0.16 Loss, 0.05 Threshold\n",
            "721 episode , 14 step , 0.19 Loss, 0.05 Threshold\n",
            "722 episode , 127 step , 0.15 Loss, 0.05 Threshold\n",
            "723 episode , 258 step , 0.15 Loss, 0.05 Threshold\n",
            "724 episode , 130 step , 0.21 Loss, 0.05 Threshold\n",
            "725 episode , 114 step , 0.17 Loss, 0.05 Threshold\n",
            "726 episode , 500 step , 0.19 Loss, 0.05 Threshold\n",
            "727 episode , 98 step , 0.19 Loss, 0.05 Threshold\n",
            "728 episode , 500 step , 0.20 Loss, 0.05 Threshold\n",
            "729 episode , 500 step , 0.18 Loss, 0.05 Threshold\n",
            "730 episode , 56 step , 0.21 Loss, 0.05 Threshold\n",
            "731 episode , 20 step , 0.22 Loss, 0.05 Threshold\n",
            "732 episode , 12 step , 0.17 Loss, 0.05 Threshold\n",
            "733 episode , 25 step , 0.05 Loss, 0.05 Threshold\n",
            "734 episode , 22 step , 0.29 Loss, 0.05 Threshold\n",
            "735 episode , 15 step , 0.27 Loss, 0.05 Threshold\n",
            "736 episode , 9 step , 0.26 Loss, 0.05 Threshold\n",
            "737 episode , 13 step , 0.39 Loss, 0.05 Threshold\n",
            "738 episode , 12 step , 0.33 Loss, 0.05 Threshold\n",
            "739 episode , 12 step , 0.29 Loss, 0.05 Threshold\n",
            "740 episode , 12 step , 0.39 Loss, 0.05 Threshold\n",
            "741 episode , 30 step , 0.35 Loss, 0.05 Threshold\n",
            "742 episode , 11 step , 0.37 Loss, 0.05 Threshold\n",
            "743 episode , 13 step , 0.43 Loss, 0.05 Threshold\n",
            "744 episode , 9 step , 0.13 Loss, 0.05 Threshold\n",
            "745 episode , 8 step , 0.37 Loss, 0.05 Threshold\n",
            "746 episode , 14 step , 0.36 Loss, 0.05 Threshold\n",
            "747 episode , 13 step , 0.22 Loss, 0.05 Threshold\n",
            "748 episode , 11 step , 0.50 Loss, 0.05 Threshold\n",
            "749 episode , 11 step , 0.26 Loss, 0.05 Threshold\n",
            "750 episode , 10 step , 0.33 Loss, 0.05 Threshold\n",
            "751 episode , 18 step , 0.48 Loss, 0.05 Threshold\n",
            "752 episode , 18 step , 0.41 Loss, 0.05 Threshold\n",
            "753 episode , 11 step , 0.47 Loss, 0.05 Threshold\n",
            "754 episode , 12 step , 0.32 Loss, 0.05 Threshold\n",
            "755 episode , 15 step , 0.33 Loss, 0.05 Threshold\n",
            "756 episode , 15 step , 0.48 Loss, 0.05 Threshold\n",
            "757 episode , 16 step , 0.37 Loss, 0.05 Threshold\n",
            "758 episode , 15 step , 0.32 Loss, 0.05 Threshold\n",
            "759 episode , 16 step , 0.36 Loss, 0.05 Threshold\n",
            "760 episode , 12 step , 0.41 Loss, 0.05 Threshold\n",
            "761 episode , 31 step , 0.64 Loss, 0.05 Threshold\n",
            "762 episode , 21 step , 0.41 Loss, 0.05 Threshold\n",
            "763 episode , 21 step , 0.40 Loss, 0.05 Threshold\n",
            "764 episode , 48 step , 0.39 Loss, 0.05 Threshold\n",
            "765 episode , 41 step , 0.34 Loss, 0.05 Threshold\n",
            "766 episode , 47 step , 0.47 Loss, 0.05 Threshold\n",
            "767 episode , 48 step , 0.40 Loss, 0.05 Threshold\n",
            "768 episode , 38 step , 0.36 Loss, 0.05 Threshold\n",
            "769 episode , 27 step , 0.48 Loss, 0.05 Threshold\n",
            "770 episode , 92 step , 0.44 Loss, 0.05 Threshold\n",
            "771 episode , 343 step , 0.52 Loss, 0.05 Threshold\n",
            "772 episode , 393 step , 0.50 Loss, 0.05 Threshold\n",
            "773 episode , 438 step , 0.50 Loss, 0.05 Threshold\n",
            "774 episode , 185 step , 0.52 Loss, 0.05 Threshold\n",
            "775 episode , 402 step , 0.50 Loss, 0.05 Threshold\n",
            "776 episode , 159 step , 0.49 Loss, 0.05 Threshold\n",
            "777 episode , 94 step , 0.60 Loss, 0.05 Threshold\n",
            "778 episode , 147 step , 0.51 Loss, 0.05 Threshold\n",
            "779 episode , 103 step , 0.49 Loss, 0.05 Threshold\n",
            "780 episode , 98 step , 0.60 Loss, 0.05 Threshold\n",
            "781 episode , 500 step , 0.54 Loss, 0.05 Threshold\n",
            "782 episode , 99 step , 0.52 Loss, 0.05 Threshold\n",
            "783 episode , 95 step , 0.57 Loss, 0.05 Threshold\n",
            "784 episode , 90 step , 0.54 Loss, 0.05 Threshold\n",
            "785 episode , 500 step , 0.52 Loss, 0.05 Threshold\n",
            "786 episode , 90 step , 0.54 Loss, 0.05 Threshold\n",
            "787 episode , 97 step , 0.58 Loss, 0.05 Threshold\n",
            "788 episode , 96 step , 0.63 Loss, 0.05 Threshold\n",
            "789 episode , 101 step , 0.53 Loss, 0.05 Threshold\n",
            "790 episode , 84 step , 0.61 Loss, 0.05 Threshold\n",
            "791 episode , 500 step , 0.58 Loss, 0.05 Threshold\n",
            "792 episode , 97 step , 0.59 Loss, 0.05 Threshold\n",
            "793 episode , 109 step , 0.54 Loss, 0.05 Threshold\n",
            "794 episode , 500 step , 0.57 Loss, 0.05 Threshold\n",
            "795 episode , 14 step , 0.76 Loss, 0.05 Threshold\n",
            "796 episode , 55 step , 0.46 Loss, 0.05 Threshold\n",
            "797 episode , 376 step , 0.51 Loss, 0.05 Threshold\n",
            "798 episode , 500 step , 0.52 Loss, 0.05 Threshold\n",
            "799 episode , 500 step , 0.58 Loss, 0.05 Threshold\n",
            "800 episode , 500 step , 0.56 Loss, 0.05 Threshold\n",
            "801 episode , 84 step , 0.55 Loss, 0.05 Threshold\n",
            "802 episode , 78 step , 0.50 Loss, 0.05 Threshold\n",
            "803 episode , 104 step , 0.64 Loss, 0.05 Threshold\n",
            "804 episode , 73 step , 0.54 Loss, 0.05 Threshold\n",
            "805 episode , 111 step , 0.61 Loss, 0.05 Threshold\n",
            "806 episode , 87 step , 0.56 Loss, 0.05 Threshold\n",
            "807 episode , 500 step , 0.54 Loss, 0.05 Threshold\n",
            "808 episode , 74 step , 0.62 Loss, 0.05 Threshold\n",
            "809 episode , 77 step , 0.62 Loss, 0.05 Threshold\n",
            "810 episode , 90 step , 0.56 Loss, 0.05 Threshold\n",
            "811 episode , 390 step , 0.58 Loss, 0.05 Threshold\n",
            "812 episode , 107 step , 0.64 Loss, 0.05 Threshold\n",
            "813 episode , 156 step , 0.51 Loss, 0.05 Threshold\n",
            "814 episode , 87 step , 0.61 Loss, 0.05 Threshold\n",
            "815 episode , 102 step , 0.59 Loss, 0.05 Threshold\n",
            "816 episode , 81 step , 0.43 Loss, 0.05 Threshold\n",
            "817 episode , 85 step , 0.39 Loss, 0.05 Threshold\n",
            "818 episode , 88 step , 0.36 Loss, 0.05 Threshold\n",
            "819 episode , 78 step , 0.43 Loss, 0.05 Threshold\n",
            "820 episode , 99 step , 0.43 Loss, 0.05 Threshold\n",
            "821 episode , 86 step , 0.40 Loss, 0.05 Threshold\n",
            "822 episode , 80 step , 0.39 Loss, 0.05 Threshold\n",
            "823 episode , 103 step , 0.39 Loss, 0.05 Threshold\n",
            "824 episode , 500 step , 0.36 Loss, 0.05 Threshold\n",
            "825 episode , 126 step , 0.33 Loss, 0.05 Threshold\n",
            "826 episode , 114 step , 0.38 Loss, 0.05 Threshold\n",
            "827 episode , 376 step , 0.36 Loss, 0.05 Threshold\n",
            "828 episode , 13 step , 0.39 Loss, 0.05 Threshold\n",
            "829 episode , 500 step , 0.38 Loss, 0.05 Threshold\n",
            "830 episode , 500 step , 0.35 Loss, 0.05 Threshold\n",
            "831 episode , 121 step , 0.45 Loss, 0.05 Threshold\n",
            "832 episode , 18 step , 0.39 Loss, 0.05 Threshold\n",
            "833 episode , 14 step , 0.33 Loss, 0.05 Threshold\n",
            "834 episode , 12 step , 0.36 Loss, 0.05 Threshold\n",
            "835 episode , 11 step , 0.36 Loss, 0.05 Threshold\n",
            "836 episode , 28 step , 0.33 Loss, 0.05 Threshold\n",
            "837 episode , 129 step , 0.40 Loss, 0.05 Threshold\n",
            "838 episode , 15 step , 0.43 Loss, 0.05 Threshold\n",
            "839 episode , 500 step , 0.40 Loss, 0.05 Threshold\n",
            "840 episode , 41 step , 0.57 Loss, 0.05 Threshold\n",
            "841 episode , 24 step , 0.79 Loss, 0.05 Threshold\n",
            "842 episode , 500 step , 0.46 Loss, 0.05 Threshold\n",
            "843 episode , 500 step , 0.46 Loss, 0.05 Threshold\n",
            "844 episode , 93 step , 0.44 Loss, 0.05 Threshold\n",
            "845 episode , 500 step , 0.46 Loss, 0.05 Threshold\n",
            "846 episode , 500 step , 0.42 Loss, 0.05 Threshold\n",
            "847 episode , 500 step , 0.38 Loss, 0.05 Threshold\n",
            "848 episode , 500 step , 0.41 Loss, 0.05 Threshold\n",
            "849 episode , 500 step , 0.42 Loss, 0.05 Threshold\n",
            "850 episode , 500 step , 0.42 Loss, 0.05 Threshold\n",
            "851 episode , 500 step , 0.39 Loss, 0.05 Threshold\n",
            "852 episode , 500 step , 0.38 Loss, 0.05 Threshold\n",
            "853 episode , 94 step , 0.41 Loss, 0.05 Threshold\n",
            "854 episode , 94 step , 0.34 Loss, 0.05 Threshold\n",
            "855 episode , 500 step , 0.35 Loss, 0.05 Threshold\n",
            "856 episode , 500 step , 0.36 Loss, 0.05 Threshold\n",
            "857 episode , 500 step , 0.32 Loss, 0.05 Threshold\n",
            "858 episode , 500 step , 0.33 Loss, 0.05 Threshold\n",
            "859 episode , 500 step , 0.31 Loss, 0.05 Threshold\n",
            "860 episode , 76 step , 0.27 Loss, 0.05 Threshold\n",
            "861 episode , 500 step , 0.29 Loss, 0.05 Threshold\n",
            "862 episode , 500 step , 0.26 Loss, 0.05 Threshold\n",
            "863 episode , 500 step , 0.28 Loss, 0.05 Threshold\n",
            "864 episode , 500 step , 0.23 Loss, 0.05 Threshold\n",
            "865 episode , 500 step , 0.18 Loss, 0.05 Threshold\n",
            "866 episode , 500 step , 0.21 Loss, 0.05 Threshold\n",
            "867 episode , 500 step , 0.23 Loss, 0.05 Threshold\n",
            "868 episode , 11 step , 0.13 Loss, 0.05 Threshold\n",
            "869 episode , 14 step , 0.05 Loss, 0.05 Threshold\n",
            "870 episode , 500 step , 0.23 Loss, 0.05 Threshold\n",
            "871 episode , 74 step , 0.23 Loss, 0.05 Threshold\n",
            "872 episode , 73 step , 0.24 Loss, 0.05 Threshold\n",
            "873 episode , 500 step , 0.25 Loss, 0.05 Threshold\n",
            "874 episode , 500 step , 0.22 Loss, 0.05 Threshold\n",
            "875 episode , 73 step , 0.24 Loss, 0.05 Threshold\n",
            "876 episode , 500 step , 0.24 Loss, 0.05 Threshold\n",
            "877 episode , 500 step , 0.22 Loss, 0.05 Threshold\n",
            "878 episode , 71 step , 0.26 Loss, 0.05 Threshold\n",
            "879 episode , 500 step , 0.26 Loss, 0.05 Threshold\n",
            "880 episode , 500 step , 0.27 Loss, 0.05 Threshold\n",
            "881 episode , 500 step , 0.25 Loss, 0.05 Threshold\n",
            "882 episode , 500 step , 0.22 Loss, 0.05 Threshold\n",
            "883 episode , 500 step , 0.21 Loss, 0.05 Threshold\n",
            "884 episode , 500 step , 0.22 Loss, 0.05 Threshold\n",
            "885 episode , 500 step , 0.23 Loss, 0.05 Threshold\n",
            "886 episode , 500 step , 0.24 Loss, 0.05 Threshold\n",
            "887 episode , 500 step , 0.21 Loss, 0.05 Threshold\n",
            "888 episode , 500 step , 0.23 Loss, 0.05 Threshold\n",
            "889 episode , 500 step , 0.26 Loss, 0.05 Threshold\n",
            "890 episode , 500 step , 0.21 Loss, 0.05 Threshold\n",
            "891 episode , 500 step , 0.24 Loss, 0.05 Threshold\n",
            "892 episode , 500 step , 0.22 Loss, 0.05 Threshold\n",
            "893 episode , 500 step , 0.24 Loss, 0.05 Threshold\n",
            "894 episode , 500 step , 0.21 Loss, 0.05 Threshold\n",
            "895 episode , 500 step , 0.18 Loss, 0.05 Threshold\n",
            "896 episode , 500 step , 0.19 Loss, 0.05 Threshold\n",
            "897 episode , 500 step , 0.19 Loss, 0.05 Threshold\n",
            "898 episode , 500 step , 0.19 Loss, 0.05 Threshold\n",
            "899 episode , 500 step , 0.19 Loss, 0.05 Threshold\n",
            "900 episode , 500 step , 0.16 Loss, 0.05 Threshold\n",
            "901 episode , 500 step , 0.16 Loss, 0.05 Threshold\n",
            "902 episode , 500 step , 0.19 Loss, 0.05 Threshold\n",
            "903 episode , 500 step , 0.16 Loss, 0.05 Threshold\n",
            "904 episode , 34 step , 0.15 Loss, 0.05 Threshold\n",
            "905 episode , 500 step , 0.19 Loss, 0.05 Threshold\n",
            "906 episode , 500 step , 0.17 Loss, 0.05 Threshold\n",
            "907 episode , 19 step , 0.23 Loss, 0.05 Threshold\n",
            "908 episode , 500 step , 0.20 Loss, 0.05 Threshold\n",
            "909 episode , 500 step , 0.22 Loss, 0.05 Threshold\n",
            "910 episode , 500 step , 0.19 Loss, 0.05 Threshold\n",
            "911 episode , 500 step , 0.19 Loss, 0.05 Threshold\n",
            "912 episode , 73 step , 0.27 Loss, 0.05 Threshold\n",
            "913 episode , 48 step , 0.23 Loss, 0.05 Threshold\n",
            "914 episode , 74 step , 0.24 Loss, 0.05 Threshold\n",
            "915 episode , 500 step , 0.20 Loss, 0.05 Threshold\n",
            "916 episode , 500 step , 0.24 Loss, 0.05 Threshold\n",
            "917 episode , 37 step , 0.18 Loss, 0.05 Threshold\n",
            "918 episode , 500 step , 0.25 Loss, 0.05 Threshold\n",
            "919 episode , 39 step , 0.24 Loss, 0.05 Threshold\n",
            "920 episode , 39 step , 0.31 Loss, 0.05 Threshold\n",
            "921 episode , 34 step , 0.42 Loss, 0.05 Threshold\n",
            "922 episode , 500 step , 0.28 Loss, 0.05 Threshold\n",
            "923 episode , 500 step , 0.26 Loss, 0.05 Threshold\n",
            "924 episode , 500 step , 0.23 Loss, 0.05 Threshold\n",
            "925 episode , 11 step , 0.58 Loss, 0.05 Threshold\n",
            "926 episode , 25 step , 0.18 Loss, 0.05 Threshold\n",
            "927 episode , 30 step , 0.43 Loss, 0.05 Threshold\n",
            "928 episode , 31 step , 0.41 Loss, 0.05 Threshold\n",
            "929 episode , 42 step , 0.23 Loss, 0.05 Threshold\n",
            "930 episode , 40 step , 0.27 Loss, 0.05 Threshold\n",
            "931 episode , 37 step , 0.42 Loss, 0.05 Threshold\n",
            "932 episode , 11 step , 0.29 Loss, 0.05 Threshold\n",
            "933 episode , 16 step , 0.48 Loss, 0.05 Threshold\n",
            "934 episode , 12 step , 0.15 Loss, 0.05 Threshold\n",
            "935 episode , 12 step , 0.61 Loss, 0.05 Threshold\n",
            "936 episode , 29 step , 0.25 Loss, 0.05 Threshold\n",
            "937 episode , 31 step , 0.46 Loss, 0.05 Threshold\n",
            "938 episode , 13 step , 0.40 Loss, 0.05 Threshold\n",
            "939 episode , 11 step , 0.20 Loss, 0.05 Threshold\n",
            "940 episode , 25 step , 0.51 Loss, 0.05 Threshold\n",
            "941 episode , 13 step , 0.98 Loss, 0.05 Threshold\n",
            "942 episode , 17 step , 0.50 Loss, 0.05 Threshold\n",
            "943 episode , 12 step , 0.42 Loss, 0.05 Threshold\n",
            "944 episode , 31 step , 0.43 Loss, 0.05 Threshold\n",
            "945 episode , 57 step , 0.46 Loss, 0.05 Threshold\n",
            "946 episode , 93 step , 0.50 Loss, 0.05 Threshold\n",
            "947 episode , 46 step , 0.36 Loss, 0.05 Threshold\n",
            "948 episode , 73 step , 0.33 Loss, 0.05 Threshold\n",
            "949 episode , 70 step , 0.47 Loss, 0.05 Threshold\n",
            "950 episode , 75 step , 0.50 Loss, 0.05 Threshold\n",
            "951 episode , 21 step , 0.44 Loss, 0.05 Threshold\n",
            "952 episode , 80 step , 0.59 Loss, 0.05 Threshold\n",
            "953 episode , 93 step , 0.60 Loss, 0.05 Threshold\n",
            "954 episode , 119 step , 0.47 Loss, 0.05 Threshold\n",
            "955 episode , 112 step , 0.47 Loss, 0.05 Threshold\n",
            "956 episode , 44 step , 0.55 Loss, 0.05 Threshold\n",
            "957 episode , 106 step , 0.45 Loss, 0.05 Threshold\n",
            "958 episode , 103 step , 0.68 Loss, 0.05 Threshold\n",
            "959 episode , 119 step , 0.55 Loss, 0.05 Threshold\n",
            "960 episode , 73 step , 0.51 Loss, 0.05 Threshold\n",
            "961 episode , 14 step , 0.74 Loss, 0.05 Threshold\n",
            "962 episode , 107 step , 0.61 Loss, 0.05 Threshold\n",
            "963 episode , 140 step , 0.55 Loss, 0.05 Threshold\n",
            "964 episode , 114 step , 0.69 Loss, 0.05 Threshold\n",
            "965 episode , 125 step , 0.67 Loss, 0.05 Threshold\n",
            "966 episode , 115 step , 0.70 Loss, 0.05 Threshold\n",
            "967 episode , 116 step , 0.47 Loss, 0.05 Threshold\n",
            "968 episode , 117 step , 0.70 Loss, 0.05 Threshold\n",
            "969 episode , 108 step , 0.67 Loss, 0.05 Threshold\n",
            "970 episode , 107 step , 0.80 Loss, 0.05 Threshold\n",
            "971 episode , 106 step , 0.69 Loss, 0.05 Threshold\n",
            "972 episode , 111 step , 0.64 Loss, 0.05 Threshold\n",
            "973 episode , 115 step , 0.59 Loss, 0.05 Threshold\n",
            "974 episode , 112 step , 0.65 Loss, 0.05 Threshold\n",
            "975 episode , 98 step , 0.70 Loss, 0.05 Threshold\n",
            "976 episode , 103 step , 0.49 Loss, 0.05 Threshold\n",
            "977 episode , 100 step , 0.66 Loss, 0.05 Threshold\n",
            "978 episode , 111 step , 0.71 Loss, 0.05 Threshold\n",
            "979 episode , 109 step , 0.77 Loss, 0.05 Threshold\n",
            "980 episode , 105 step , 0.60 Loss, 0.05 Threshold\n",
            "981 episode , 116 step , 0.78 Loss, 0.05 Threshold\n",
            "982 episode , 99 step , 0.69 Loss, 0.05 Threshold\n",
            "983 episode , 103 step , 0.69 Loss, 0.05 Threshold\n",
            "984 episode , 100 step , 0.76 Loss, 0.05 Threshold\n",
            "985 episode , 96 step , 0.70 Loss, 0.05 Threshold\n",
            "986 episode , 104 step , 0.76 Loss, 0.05 Threshold\n",
            "987 episode , 106 step , 0.75 Loss, 0.05 Threshold\n",
            "988 episode , 104 step , 0.79 Loss, 0.05 Threshold\n",
            "989 episode , 105 step , 0.72 Loss, 0.05 Threshold\n",
            "990 episode , 109 step , 0.75 Loss, 0.05 Threshold\n",
            "991 episode , 48 step , 0.67 Loss, 0.05 Threshold\n",
            "992 episode , 103 step , 0.73 Loss, 0.05 Threshold\n",
            "993 episode , 106 step , 0.79 Loss, 0.05 Threshold\n",
            "994 episode , 108 step , 0.79 Loss, 0.05 Threshold\n",
            "995 episode , 100 step , 0.85 Loss, 0.05 Threshold\n",
            "996 episode , 103 step , 0.83 Loss, 0.05 Threshold\n",
            "997 episode , 54 step , 0.83 Loss, 0.05 Threshold\n",
            "998 episode , 97 step , 0.95 Loss, 0.05 Threshold\n",
            "999 episode , 45 step , 0.92 Loss, 0.05 Threshold\n",
            "1000 episode , 109 step , 0.87 Loss, 0.05 Threshold\n",
            "1001 episode , 38 step , 0.98 Loss, 0.05 Threshold\n",
            "1002 episode , 42 step , 0.76 Loss, 0.05 Threshold\n",
            "1003 episode , 26 step , 1.08 Loss, 0.05 Threshold\n",
            "1004 episode , 59 step , 0.88 Loss, 0.05 Threshold\n",
            "1005 episode , 40 step , 0.64 Loss, 0.05 Threshold\n",
            "1006 episode , 27 step , 0.76 Loss, 0.05 Threshold\n",
            "1007 episode , 45 step , 0.89 Loss, 0.05 Threshold\n",
            "1008 episode , 58 step , 0.88 Loss, 0.05 Threshold\n",
            "1009 episode , 45 step , 1.09 Loss, 0.05 Threshold\n",
            "1010 episode , 65 step , 1.01 Loss, 0.05 Threshold\n",
            "1011 episode , 16 step , 0.96 Loss, 0.05 Threshold\n",
            "1012 episode , 46 step , 1.13 Loss, 0.05 Threshold\n",
            "1013 episode , 48 step , 1.31 Loss, 0.05 Threshold\n",
            "1014 episode , 37 step , 1.06 Loss, 0.05 Threshold\n",
            "1015 episode , 38 step , 0.87 Loss, 0.05 Threshold\n",
            "1016 episode , 38 step , 1.03 Loss, 0.05 Threshold\n",
            "1017 episode , 49 step , 0.91 Loss, 0.05 Threshold\n",
            "1018 episode , 34 step , 1.04 Loss, 0.05 Threshold\n",
            "1019 episode , 25 step , 1.03 Loss, 0.05 Threshold\n",
            "1020 episode , 40 step , 1.05 Loss, 0.05 Threshold\n",
            "1021 episode , 13 step , 0.92 Loss, 0.05 Threshold\n",
            "1022 episode , 16 step , 0.84 Loss, 0.05 Threshold\n",
            "1023 episode , 14 step , 1.46 Loss, 0.05 Threshold\n",
            "1024 episode , 25 step , 1.12 Loss, 0.05 Threshold\n",
            "1025 episode , 23 step , 1.10 Loss, 0.05 Threshold\n",
            "1026 episode , 22 step , 0.81 Loss, 0.05 Threshold\n",
            "1027 episode , 17 step , 0.58 Loss, 0.05 Threshold\n",
            "1028 episode , 22 step , 1.05 Loss, 0.05 Threshold\n",
            "1029 episode , 26 step , 0.94 Loss, 0.05 Threshold\n",
            "1030 episode , 22 step , 1.19 Loss, 0.05 Threshold\n",
            "1031 episode , 13 step , 1.58 Loss, 0.05 Threshold\n",
            "1032 episode , 28 step , 1.32 Loss, 0.05 Threshold\n",
            "1033 episode , 100 step , 1.00 Loss, 0.05 Threshold\n",
            "1034 episode , 31 step , 1.27 Loss, 0.05 Threshold\n",
            "1035 episode , 101 step , 1.13 Loss, 0.05 Threshold\n",
            "1036 episode , 95 step , 1.27 Loss, 0.05 Threshold\n",
            "1037 episode , 101 step , 1.18 Loss, 0.05 Threshold\n",
            "1038 episode , 104 step , 1.23 Loss, 0.05 Threshold\n",
            "1039 episode , 98 step , 1.11 Loss, 0.05 Threshold\n",
            "1040 episode , 99 step , 1.31 Loss, 0.05 Threshold\n",
            "1041 episode , 13 step , 1.59 Loss, 0.05 Threshold\n",
            "1042 episode , 100 step , 1.34 Loss, 0.05 Threshold\n",
            "1043 episode , 102 step , 1.18 Loss, 0.05 Threshold\n",
            "1044 episode , 101 step , 1.23 Loss, 0.05 Threshold\n",
            "1045 episode , 109 step , 1.32 Loss, 0.05 Threshold\n",
            "1046 episode , 105 step , 1.12 Loss, 0.05 Threshold\n",
            "1047 episode , 108 step , 1.28 Loss, 0.05 Threshold\n",
            "1048 episode , 111 step , 1.27 Loss, 0.05 Threshold\n",
            "1049 episode , 106 step , 1.29 Loss, 0.05 Threshold\n",
            "1050 episode , 102 step , 1.50 Loss, 0.05 Threshold\n",
            "1051 episode , 12 step , 0.98 Loss, 0.05 Threshold\n",
            "1052 episode , 31 step , 0.99 Loss, 0.05 Threshold\n",
            "1053 episode , 116 step , 1.37 Loss, 0.05 Threshold\n",
            "1054 episode , 110 step , 1.32 Loss, 0.05 Threshold\n",
            "1055 episode , 116 step , 1.24 Loss, 0.05 Threshold\n",
            "1056 episode , 117 step , 1.34 Loss, 0.05 Threshold\n",
            "1057 episode , 106 step , 1.35 Loss, 0.05 Threshold\n",
            "1058 episode , 110 step , 1.35 Loss, 0.05 Threshold\n",
            "1059 episode , 111 step , 1.39 Loss, 0.05 Threshold\n",
            "1060 episode , 129 step , 1.31 Loss, 0.05 Threshold\n",
            "1061 episode , 15 step , 1.78 Loss, 0.05 Threshold\n",
            "1062 episode , 11 step , 1.56 Loss, 0.05 Threshold\n",
            "1063 episode , 130 step , 1.44 Loss, 0.05 Threshold\n",
            "1064 episode , 13 step , 1.20 Loss, 0.05 Threshold\n",
            "1065 episode , 118 step , 1.43 Loss, 0.05 Threshold\n",
            "1066 episode , 137 step , 1.54 Loss, 0.05 Threshold\n",
            "1067 episode , 123 step , 1.49 Loss, 0.05 Threshold\n",
            "1068 episode , 121 step , 1.29 Loss, 0.05 Threshold\n",
            "1069 episode , 25 step , 1.15 Loss, 0.05 Threshold\n",
            "1070 episode , 111 step , 1.42 Loss, 0.05 Threshold\n",
            "1071 episode , 11 step , 1.13 Loss, 0.05 Threshold\n",
            "1072 episode , 14 step , 1.72 Loss, 0.05 Threshold\n",
            "1073 episode , 20 step , 1.74 Loss, 0.05 Threshold\n",
            "1074 episode , 22 step , 1.05 Loss, 0.05 Threshold\n",
            "1075 episode , 12 step , 1.39 Loss, 0.05 Threshold\n",
            "1076 episode , 110 step , 1.46 Loss, 0.05 Threshold\n",
            "1077 episode , 30 step , 1.28 Loss, 0.05 Threshold\n",
            "1078 episode , 111 step , 1.32 Loss, 0.05 Threshold\n",
            "1079 episode , 109 step , 1.45 Loss, 0.05 Threshold\n",
            "1080 episode , 17 step , 1.17 Loss, 0.05 Threshold\n",
            "1081 episode , 11 step , 1.49 Loss, 0.05 Threshold\n",
            "1082 episode , 12 step , 1.76 Loss, 0.05 Threshold\n",
            "1083 episode , 13 step , 0.88 Loss, 0.05 Threshold\n",
            "1084 episode , 16 step , 1.50 Loss, 0.05 Threshold\n",
            "1085 episode , 13 step , 1.34 Loss, 0.05 Threshold\n",
            "1086 episode , 13 step , 1.79 Loss, 0.05 Threshold\n",
            "1087 episode , 12 step , 2.33 Loss, 0.05 Threshold\n",
            "1088 episode , 18 step , 1.86 Loss, 0.05 Threshold\n",
            "1089 episode , 14 step , 1.39 Loss, 0.05 Threshold\n",
            "1090 episode , 14 step , 1.44 Loss, 0.05 Threshold\n",
            "1091 episode , 11 step , 1.57 Loss, 0.05 Threshold\n",
            "1092 episode , 13 step , 1.74 Loss, 0.05 Threshold\n",
            "1093 episode , 9 step , 1.73 Loss, 0.05 Threshold\n",
            "1094 episode , 10 step , 1.29 Loss, 0.05 Threshold\n",
            "1095 episode , 11 step , 1.72 Loss, 0.05 Threshold\n",
            "1096 episode , 11 step , 1.27 Loss, 0.05 Threshold\n",
            "1097 episode , 9 step , 1.38 Loss, 0.05 Threshold\n",
            "1098 episode , 10 step , 1.04 Loss, 0.05 Threshold\n",
            "1099 episode , 14 step , 1.60 Loss, 0.05 Threshold\n",
            "1100 episode , 13 step , 1.64 Loss, 0.05 Threshold\n",
            "1101 episode , 14 step , 1.83 Loss, 0.05 Threshold\n",
            "1102 episode , 158 step , 1.47 Loss, 0.05 Threshold\n",
            "1103 episode , 65 step , 1.62 Loss, 0.05 Threshold\n",
            "1104 episode , 129 step , 1.60 Loss, 0.05 Threshold\n",
            "1105 episode , 118 step , 1.59 Loss, 0.05 Threshold\n",
            "1106 episode , 81 step , 1.58 Loss, 0.05 Threshold\n",
            "1107 episode , 500 step , 1.62 Loss, 0.05 Threshold\n",
            "1108 episode , 131 step , 1.54 Loss, 0.05 Threshold\n",
            "1109 episode , 13 step , 1.26 Loss, 0.05 Threshold\n",
            "1110 episode , 126 step , 1.46 Loss, 0.05 Threshold\n",
            "1111 episode , 11 step , 1.72 Loss, 0.05 Threshold\n",
            "1112 episode , 12 step , 1.45 Loss, 0.05 Threshold\n",
            "1113 episode , 14 step , 1.44 Loss, 0.05 Threshold\n",
            "1114 episode , 16 step , 1.32 Loss, 0.05 Threshold\n",
            "1115 episode , 17 step , 1.15 Loss, 0.05 Threshold\n",
            "1116 episode , 141 step , 1.56 Loss, 0.05 Threshold\n",
            "1117 episode , 119 step , 1.41 Loss, 0.05 Threshold\n",
            "1118 episode , 127 step , 1.62 Loss, 0.05 Threshold\n",
            "1119 episode , 11 step , 1.10 Loss, 0.05 Threshold\n",
            "1120 episode , 123 step , 1.60 Loss, 0.05 Threshold\n",
            "1121 episode , 13 step , 1.74 Loss, 0.05 Threshold\n",
            "1122 episode , 492 step , 1.56 Loss, 0.05 Threshold\n",
            "1123 episode , 172 step , 1.68 Loss, 0.05 Threshold\n",
            "1124 episode , 171 step , 1.55 Loss, 0.05 Threshold\n",
            "1125 episode , 25 step , 1.46 Loss, 0.05 Threshold\n",
            "1126 episode , 171 step , 1.48 Loss, 0.05 Threshold\n",
            "1127 episode , 166 step , 1.64 Loss, 0.05 Threshold\n",
            "1128 episode , 156 step , 1.59 Loss, 0.05 Threshold\n",
            "1129 episode , 168 step , 1.52 Loss, 0.05 Threshold\n",
            "1130 episode , 156 step , 1.55 Loss, 0.05 Threshold\n",
            "1131 episode , 12 step , 1.70 Loss, 0.05 Threshold\n",
            "1132 episode , 500 step , 1.58 Loss, 0.05 Threshold\n",
            "1133 episode , 500 step , 1.55 Loss, 0.05 Threshold\n",
            "1134 episode , 500 step , 1.42 Loss, 0.05 Threshold\n",
            "1135 episode , 500 step , 1.33 Loss, 0.05 Threshold\n",
            "1136 episode , 500 step , 1.17 Loss, 0.05 Threshold\n",
            "1137 episode , 500 step , 1.07 Loss, 0.05 Threshold\n",
            "1138 episode , 500 step , 1.02 Loss, 0.05 Threshold\n",
            "1139 episode , 500 step , 0.99 Loss, 0.05 Threshold\n",
            "1140 episode , 500 step , 0.93 Loss, 0.05 Threshold\n",
            "1141 episode , 500 step , 0.84 Loss, 0.05 Threshold\n",
            "1142 episode , 500 step , 0.82 Loss, 0.05 Threshold\n",
            "1143 episode , 500 step , 0.75 Loss, 0.05 Threshold\n",
            "1144 episode , 500 step , 0.60 Loss, 0.05 Threshold\n",
            "1145 episode , 500 step , 0.43 Loss, 0.05 Threshold\n",
            "1146 episode , 500 step , 0.44 Loss, 0.05 Threshold\n",
            "1147 episode , 500 step , 0.34 Loss, 0.05 Threshold\n",
            "1148 episode , 500 step , 0.31 Loss, 0.05 Threshold\n",
            "1149 episode , 500 step , 0.28 Loss, 0.05 Threshold\n",
            "1150 episode , 500 step , 0.25 Loss, 0.05 Threshold\n",
            "1151 episode , 14 step , 0.40 Loss, 0.05 Threshold\n",
            "1152 episode , 500 step , 0.24 Loss, 0.05 Threshold\n",
            "1153 episode , 500 step , 0.25 Loss, 0.05 Threshold\n",
            "1154 episode , 12 step , 0.08 Loss, 0.05 Threshold\n",
            "1155 episode , 500 step , 0.24 Loss, 0.05 Threshold\n",
            "1156 episode , 500 step , 0.27 Loss, 0.05 Threshold\n",
            "1157 episode , 13 step , 0.21 Loss, 0.05 Threshold\n",
            "1158 episode , 500 step , 0.25 Loss, 0.05 Threshold\n",
            "1159 episode , 12 step , 0.38 Loss, 0.05 Threshold\n",
            "1160 episode , 14 step , 0.32 Loss, 0.05 Threshold\n",
            "1161 episode , 12 step , 0.60 Loss, 0.05 Threshold\n",
            "1162 episode , 500 step , 0.34 Loss, 0.05 Threshold\n",
            "1163 episode , 500 step , 0.31 Loss, 0.05 Threshold\n",
            "1164 episode , 500 step , 0.29 Loss, 0.05 Threshold\n",
            "1165 episode , 12 step , 0.32 Loss, 0.05 Threshold\n",
            "1166 episode , 500 step , 0.29 Loss, 0.05 Threshold\n",
            "1167 episode , 10 step , 0.43 Loss, 0.05 Threshold\n",
            "1168 episode , 500 step , 0.34 Loss, 0.05 Threshold\n",
            "1169 episode , 500 step , 0.33 Loss, 0.05 Threshold\n",
            "1170 episode , 500 step , 0.28 Loss, 0.05 Threshold\n",
            "1171 episode , 500 step , 0.29 Loss, 0.05 Threshold\n",
            "1172 episode , 500 step , 0.31 Loss, 0.05 Threshold\n",
            "1173 episode , 500 step , 0.36 Loss, 0.05 Threshold\n",
            "1174 episode , 500 step , 0.34 Loss, 0.05 Threshold\n",
            "1175 episode , 500 step , 0.31 Loss, 0.05 Threshold\n",
            "1176 episode , 500 step , 0.30 Loss, 0.05 Threshold\n",
            "1177 episode , 500 step , 0.32 Loss, 0.05 Threshold\n",
            "1178 episode , 500 step , 0.28 Loss, 0.05 Threshold\n",
            "1179 episode , 500 step , 0.30 Loss, 0.05 Threshold\n",
            "1180 episode , 500 step , 0.30 Loss, 0.05 Threshold\n",
            "1181 episode , 12 step , 0.87 Loss, 0.05 Threshold\n",
            "1182 episode , 500 step , 0.30 Loss, 0.05 Threshold\n",
            "1183 episode , 11 step , 0.50 Loss, 0.05 Threshold\n",
            "1184 episode , 500 step , 0.30 Loss, 0.05 Threshold\n",
            "1185 episode , 11 step , 0.25 Loss, 0.05 Threshold\n",
            "1186 episode , 500 step , 0.31 Loss, 0.05 Threshold\n",
            "1187 episode , 500 step , 0.28 Loss, 0.05 Threshold\n",
            "1188 episode , 500 step , 0.27 Loss, 0.05 Threshold\n",
            "1189 episode , 500 step , 0.26 Loss, 0.05 Threshold\n",
            "1190 episode , 14 step , 0.43 Loss, 0.05 Threshold\n",
            "1191 episode , 14 step , 0.34 Loss, 0.05 Threshold\n",
            "1192 episode , 15 step , 0.38 Loss, 0.05 Threshold\n",
            "1193 episode , 43 step , 0.26 Loss, 0.05 Threshold\n",
            "1194 episode , 500 step , 0.30 Loss, 0.05 Threshold\n",
            "1195 episode , 18 step , 0.21 Loss, 0.05 Threshold\n",
            "1196 episode , 500 step , 0.32 Loss, 0.05 Threshold\n",
            "1197 episode , 28 step , 0.39 Loss, 0.05 Threshold\n",
            "1198 episode , 17 step , 0.34 Loss, 0.05 Threshold\n",
            "1199 episode , 12 step , 0.22 Loss, 0.05 Threshold\n",
            "1200 episode , 500 step , 0.38 Loss, 0.05 Threshold\n",
            "1201 episode , 21 step , 0.44 Loss, 0.05 Threshold\n",
            "1202 episode , 17 step , 0.57 Loss, 0.05 Threshold\n",
            "1203 episode , 12 step , 0.13 Loss, 0.05 Threshold\n",
            "1204 episode , 11 step , 0.48 Loss, 0.05 Threshold\n",
            "1205 episode , 13 step , 0.22 Loss, 0.05 Threshold\n",
            "1206 episode , 13 step , 0.32 Loss, 0.05 Threshold\n",
            "1207 episode , 12 step , 0.39 Loss, 0.05 Threshold\n",
            "1208 episode , 14 step , 0.43 Loss, 0.05 Threshold\n",
            "1209 episode , 11 step , 0.32 Loss, 0.05 Threshold\n",
            "1210 episode , 500 step , 0.48 Loss, 0.05 Threshold\n",
            "1211 episode , 14 step , 0.57 Loss, 0.05 Threshold\n",
            "1212 episode , 16 step , 0.46 Loss, 0.05 Threshold\n",
            "1213 episode , 12 step , 0.62 Loss, 0.05 Threshold\n",
            "1214 episode , 30 step , 0.38 Loss, 0.05 Threshold\n",
            "1215 episode , 500 step , 0.49 Loss, 0.05 Threshold\n",
            "1216 episode , 500 step , 0.52 Loss, 0.05 Threshold\n",
            "1217 episode , 500 step , 0.58 Loss, 0.05 Threshold\n",
            "1218 episode , 500 step , 0.53 Loss, 0.05 Threshold\n",
            "1219 episode , 500 step , 0.54 Loss, 0.05 Threshold\n",
            "1220 episode , 500 step , 0.53 Loss, 0.05 Threshold\n",
            "1221 episode , 11 step , 0.60 Loss, 0.05 Threshold\n",
            "1222 episode , 500 step , 0.56 Loss, 0.05 Threshold\n",
            "1223 episode , 500 step , 0.58 Loss, 0.05 Threshold\n",
            "1224 episode , 500 step , 0.56 Loss, 0.05 Threshold\n",
            "1225 episode , 500 step , 0.53 Loss, 0.05 Threshold\n",
            "1226 episode , 500 step , 0.60 Loss, 0.05 Threshold\n",
            "1227 episode , 500 step , 0.50 Loss, 0.05 Threshold\n",
            "1228 episode , 12 step , 0.18 Loss, 0.05 Threshold\n",
            "1229 episode , 500 step , 0.53 Loss, 0.05 Threshold\n",
            "1230 episode , 500 step , 0.52 Loss, 0.05 Threshold\n",
            "1231 episode , 11 step , 0.36 Loss, 0.05 Threshold\n",
            "1232 episode , 13 step , 0.56 Loss, 0.05 Threshold\n",
            "1233 episode , 12 step , 0.91 Loss, 0.05 Threshold\n",
            "1234 episode , 14 step , 0.44 Loss, 0.05 Threshold\n",
            "1235 episode , 500 step , 0.59 Loss, 0.05 Threshold\n",
            "1236 episode , 500 step , 0.48 Loss, 0.05 Threshold\n",
            "1237 episode , 500 step , 0.55 Loss, 0.05 Threshold\n",
            "1238 episode , 500 step , 0.50 Loss, 0.05 Threshold\n",
            "1239 episode , 500 step , 0.44 Loss, 0.05 Threshold\n",
            "1240 episode , 500 step , 0.38 Loss, 0.05 Threshold\n",
            "1241 episode , 13 step , 0.35 Loss, 0.05 Threshold\n",
            "1242 episode , 18 step , 0.27 Loss, 0.05 Threshold\n",
            "1243 episode , 10 step , 0.25 Loss, 0.05 Threshold\n",
            "1244 episode , 26 step , 0.42 Loss, 0.05 Threshold\n",
            "1245 episode , 21 step , 0.31 Loss, 0.05 Threshold\n",
            "1246 episode , 500 step , 0.40 Loss, 0.05 Threshold\n",
            "1247 episode , 13 step , 0.22 Loss, 0.05 Threshold\n",
            "1248 episode , 12 step , 0.57 Loss, 0.05 Threshold\n",
            "1249 episode , 13 step , 0.43 Loss, 0.05 Threshold\n",
            "1250 episode , 500 step , 0.47 Loss, 0.05 Threshold\n",
            "1251 episode , 500 step , 0.44 Loss, 0.05 Threshold\n",
            "1252 episode , 500 step , 0.43 Loss, 0.05 Threshold\n",
            "1253 episode , 500 step , 0.46 Loss, 0.05 Threshold\n",
            "1254 episode , 83 step , 0.49 Loss, 0.05 Threshold\n",
            "1255 episode , 500 step , 0.43 Loss, 0.05 Threshold\n",
            "1256 episode , 500 step , 0.50 Loss, 0.05 Threshold\n",
            "1257 episode , 500 step , 0.44 Loss, 0.05 Threshold\n",
            "1258 episode , 500 step , 0.43 Loss, 0.05 Threshold\n",
            "1259 episode , 500 step , 0.42 Loss, 0.05 Threshold\n",
            "1260 episode , 33 step , 0.39 Loss, 0.05 Threshold\n",
            "1261 episode , 11 step , 0.77 Loss, 0.05 Threshold\n",
            "1262 episode , 18 step , 0.44 Loss, 0.05 Threshold\n",
            "1263 episode , 41 step , 0.53 Loss, 0.05 Threshold\n",
            "1264 episode , 500 step , 0.54 Loss, 0.05 Threshold\n",
            "1265 episode , 500 step , 0.49 Loss, 0.05 Threshold\n",
            "1266 episode , 500 step , 0.49 Loss, 0.05 Threshold\n",
            "1267 episode , 18 step , 0.61 Loss, 0.05 Threshold\n",
            "1268 episode , 12 step , 0.81 Loss, 0.05 Threshold\n",
            "1269 episode , 500 step , 0.47 Loss, 0.05 Threshold\n",
            "1270 episode , 100 step , 0.44 Loss, 0.05 Threshold\n",
            "1271 episode , 16 step , 0.51 Loss, 0.05 Threshold\n",
            "1272 episode , 79 step , 0.54 Loss, 0.05 Threshold\n",
            "1273 episode , 500 step , 0.44 Loss, 0.05 Threshold\n",
            "1274 episode , 500 step , 0.48 Loss, 0.05 Threshold\n",
            "1275 episode , 500 step , 0.45 Loss, 0.05 Threshold\n",
            "1276 episode , 500 step , 0.47 Loss, 0.05 Threshold\n",
            "1277 episode , 17 step , 0.88 Loss, 0.05 Threshold\n",
            "1278 episode , 13 step , 0.71 Loss, 0.05 Threshold\n",
            "1279 episode , 500 step , 0.57 Loss, 0.05 Threshold\n",
            "1280 episode , 500 step , 0.40 Loss, 0.05 Threshold\n",
            "1281 episode , 11 step , 0.59 Loss, 0.05 Threshold\n",
            "1282 episode , 13 step , 0.76 Loss, 0.05 Threshold\n",
            "1283 episode , 13 step , 0.44 Loss, 0.05 Threshold\n",
            "1284 episode , 12 step , 0.59 Loss, 0.05 Threshold\n",
            "1285 episode , 12 step , 0.50 Loss, 0.05 Threshold\n",
            "1286 episode , 12 step , 0.65 Loss, 0.05 Threshold\n",
            "1287 episode , 13 step , 0.61 Loss, 0.05 Threshold\n",
            "1288 episode , 11 step , 0.36 Loss, 0.05 Threshold\n",
            "1289 episode , 11 step , 0.48 Loss, 0.05 Threshold\n",
            "1290 episode , 14 step , 0.61 Loss, 0.05 Threshold\n",
            "1291 episode , 13 step , 0.61 Loss, 0.05 Threshold\n",
            "1292 episode , 11 step , 0.46 Loss, 0.05 Threshold\n",
            "1293 episode , 10 step , 0.59 Loss, 0.05 Threshold\n",
            "1294 episode , 15 step , 0.75 Loss, 0.05 Threshold\n",
            "1295 episode , 10 step , 0.41 Loss, 0.05 Threshold\n",
            "1296 episode , 10 step , 0.27 Loss, 0.05 Threshold\n",
            "1297 episode , 11 step , 0.66 Loss, 0.05 Threshold\n",
            "1298 episode , 11 step , 0.90 Loss, 0.05 Threshold\n",
            "1299 episode , 11 step , 0.81 Loss, 0.05 Threshold\n",
            "1300 episode , 12 step , 0.73 Loss, 0.05 Threshold\n",
            "1301 episode , 10 step , 0.94 Loss, 0.05 Threshold\n",
            "1302 episode , 11 step , 0.68 Loss, 0.05 Threshold\n",
            "1303 episode , 11 step , 0.83 Loss, 0.05 Threshold\n",
            "1304 episode , 12 step , 0.92 Loss, 0.05 Threshold\n",
            "1305 episode , 13 step , 0.91 Loss, 0.05 Threshold\n",
            "1306 episode , 11 step , 0.51 Loss, 0.05 Threshold\n",
            "1307 episode , 12 step , 0.60 Loss, 0.05 Threshold\n",
            "1308 episode , 9 step , 1.02 Loss, 0.05 Threshold\n",
            "1309 episode , 11 step , 1.00 Loss, 0.05 Threshold\n",
            "1310 episode , 11 step , 1.06 Loss, 0.05 Threshold\n",
            "1311 episode , 14 step , 0.71 Loss, 0.05 Threshold\n",
            "1312 episode , 14 step , 0.78 Loss, 0.05 Threshold\n",
            "1313 episode , 500 step , 0.77 Loss, 0.05 Threshold\n",
            "1314 episode , 500 step , 0.80 Loss, 0.05 Threshold\n",
            "1315 episode , 500 step , 0.85 Loss, 0.05 Threshold\n",
            "1316 episode , 65 step , 0.82 Loss, 0.05 Threshold\n",
            "1317 episode , 79 step , 0.84 Loss, 0.05 Threshold\n",
            "1318 episode , 47 step , 0.95 Loss, 0.05 Threshold\n",
            "1319 episode , 74 step , 0.88 Loss, 0.05 Threshold\n",
            "1320 episode , 81 step , 0.84 Loss, 0.05 Threshold\n",
            "1321 episode , 17 step , 1.42 Loss, 0.05 Threshold\n",
            "1322 episode , 96 step , 0.98 Loss, 0.05 Threshold\n",
            "1323 episode , 20 step , 0.83 Loss, 0.05 Threshold\n",
            "1324 episode , 18 step , 1.06 Loss, 0.05 Threshold\n",
            "1325 episode , 31 step , 0.84 Loss, 0.05 Threshold\n",
            "1326 episode , 19 step , 0.94 Loss, 0.05 Threshold\n",
            "1327 episode , 28 step , 0.88 Loss, 0.05 Threshold\n",
            "1328 episode , 15 step , 0.69 Loss, 0.05 Threshold\n",
            "1329 episode , 17 step , 1.08 Loss, 0.05 Threshold\n",
            "1330 episode , 16 step , 0.88 Loss, 0.05 Threshold\n",
            "1331 episode , 17 step , 0.96 Loss, 0.05 Threshold\n",
            "1332 episode , 500 step , 1.03 Loss, 0.05 Threshold\n",
            "1333 episode , 500 step , 0.95 Loss, 0.05 Threshold\n",
            "1334 episode , 92 step , 1.00 Loss, 0.05 Threshold\n",
            "1335 episode , 277 step , 0.99 Loss, 0.05 Threshold\n",
            "1336 episode , 500 step , 1.03 Loss, 0.05 Threshold\n",
            "1337 episode , 15 step , 0.84 Loss, 0.05 Threshold\n",
            "1338 episode , 67 step , 0.85 Loss, 0.05 Threshold\n",
            "1339 episode , 128 step , 1.04 Loss, 0.05 Threshold\n",
            "1340 episode , 500 step , 1.01 Loss, 0.05 Threshold\n",
            "1341 episode , 97 step , 0.99 Loss, 0.05 Threshold\n",
            "1342 episode , 122 step , 1.03 Loss, 0.05 Threshold\n",
            "1343 episode , 16 step , 1.07 Loss, 0.05 Threshold\n",
            "1344 episode , 118 step , 1.22 Loss, 0.05 Threshold\n",
            "1345 episode , 116 step , 1.14 Loss, 0.05 Threshold\n",
            "1346 episode , 40 step , 1.14 Loss, 0.05 Threshold\n",
            "1347 episode , 500 step , 1.09 Loss, 0.05 Threshold\n",
            "1348 episode , 31 step , 0.97 Loss, 0.05 Threshold\n",
            "1349 episode , 34 step , 0.92 Loss, 0.05 Threshold\n",
            "1350 episode , 27 step , 0.73 Loss, 0.05 Threshold\n",
            "1351 episode , 18 step , 1.31 Loss, 0.05 Threshold\n",
            "1352 episode , 33 step , 1.08 Loss, 0.05 Threshold\n",
            "1353 episode , 500 step , 1.18 Loss, 0.05 Threshold\n",
            "1354 episode , 500 step , 1.09 Loss, 0.05 Threshold\n",
            "1355 episode , 500 step , 1.05 Loss, 0.05 Threshold\n",
            "1356 episode , 21 step , 1.11 Loss, 0.05 Threshold\n",
            "1357 episode , 19 step , 0.52 Loss, 0.05 Threshold\n",
            "1358 episode , 26 step , 0.97 Loss, 0.05 Threshold\n",
            "1359 episode , 500 step , 1.14 Loss, 0.05 Threshold\n",
            "1360 episode , 22 step , 1.14 Loss, 0.05 Threshold\n",
            "1361 episode , 27 step , 1.14 Loss, 0.05 Threshold\n",
            "1362 episode , 213 step , 1.02 Loss, 0.05 Threshold\n",
            "1363 episode , 500 step , 1.14 Loss, 0.05 Threshold\n",
            "1364 episode , 500 step , 1.19 Loss, 0.05 Threshold\n",
            "1365 episode , 500 step , 1.13 Loss, 0.05 Threshold\n",
            "1366 episode , 500 step , 0.82 Loss, 0.05 Threshold\n",
            "1367 episode , 500 step , 0.67 Loss, 0.05 Threshold\n",
            "1368 episode , 149 step , 0.70 Loss, 0.05 Threshold\n",
            "1369 episode , 259 step , 0.76 Loss, 0.05 Threshold\n",
            "1370 episode , 382 step , 0.79 Loss, 0.05 Threshold\n",
            "1371 episode , 20 step , 1.01 Loss, 0.05 Threshold\n",
            "1372 episode , 250 step , 0.83 Loss, 0.05 Threshold\n",
            "1373 episode , 285 step , 0.76 Loss, 0.05 Threshold\n",
            "1374 episode , 70 step , 0.54 Loss, 0.05 Threshold\n",
            "1375 episode , 20 step , 0.61 Loss, 0.05 Threshold\n",
            "1376 episode , 73 step , 0.69 Loss, 0.05 Threshold\n",
            "1377 episode , 29 step , 0.89 Loss, 0.05 Threshold\n",
            "1378 episode , 18 step , 0.69 Loss, 0.05 Threshold\n",
            "1379 episode , 21 step , 0.32 Loss, 0.05 Threshold\n",
            "1380 episode , 24 step , 0.85 Loss, 0.05 Threshold\n",
            "1381 episode , 22 step , 0.83 Loss, 0.05 Threshold\n",
            "1382 episode , 20 step , 0.95 Loss, 0.05 Threshold\n",
            "1383 episode , 28 step , 0.63 Loss, 0.05 Threshold\n",
            "1384 episode , 17 step , 0.71 Loss, 0.05 Threshold\n",
            "1385 episode , 15 step , 0.93 Loss, 0.05 Threshold\n",
            "1386 episode , 19 step , 0.80 Loss, 0.05 Threshold\n",
            "1387 episode , 18 step , 0.36 Loss, 0.05 Threshold\n",
            "1388 episode , 14 step , 0.72 Loss, 0.05 Threshold\n",
            "1389 episode , 12 step , 0.95 Loss, 0.05 Threshold\n",
            "1390 episode , 21 step , 0.89 Loss, 0.05 Threshold\n",
            "1391 episode , 12 step , 0.91 Loss, 0.05 Threshold\n",
            "1392 episode , 18 step , 0.85 Loss, 0.05 Threshold\n",
            "1393 episode , 14 step , 1.12 Loss, 0.05 Threshold\n",
            "1394 episode , 14 step , 1.05 Loss, 0.05 Threshold\n",
            "1395 episode , 16 step , 0.71 Loss, 0.05 Threshold\n",
            "1396 episode , 12 step , 0.90 Loss, 0.05 Threshold\n",
            "1397 episode , 14 step , 0.74 Loss, 0.05 Threshold\n",
            "1398 episode , 14 step , 0.80 Loss, 0.05 Threshold\n",
            "1399 episode , 15 step , 1.58 Loss, 0.05 Threshold\n",
            "1400 episode , 13 step , 0.58 Loss, 0.05 Threshold\n",
            "1401 episode , 12 step , 0.99 Loss, 0.05 Threshold\n",
            "1402 episode , 13 step , 1.15 Loss, 0.05 Threshold\n",
            "1403 episode , 16 step , 0.76 Loss, 0.05 Threshold\n",
            "1404 episode , 15 step , 0.69 Loss, 0.05 Threshold\n",
            "1405 episode , 14 step , 1.35 Loss, 0.05 Threshold\n",
            "1406 episode , 16 step , 1.17 Loss, 0.05 Threshold\n",
            "1407 episode , 15 step , 0.70 Loss, 0.05 Threshold\n",
            "1408 episode , 12 step , 0.98 Loss, 0.05 Threshold\n",
            "1409 episode , 13 step , 1.55 Loss, 0.05 Threshold\n",
            "1410 episode , 12 step , 0.76 Loss, 0.05 Threshold\n",
            "1411 episode , 16 step , 1.24 Loss, 0.05 Threshold\n",
            "1412 episode , 15 step , 0.97 Loss, 0.05 Threshold\n",
            "1413 episode , 15 step , 0.61 Loss, 0.05 Threshold\n",
            "1414 episode , 17 step , 1.42 Loss, 0.05 Threshold\n",
            "1415 episode , 15 step , 0.71 Loss, 0.05 Threshold\n",
            "1416 episode , 12 step , 1.43 Loss, 0.05 Threshold\n",
            "1417 episode , 12 step , 1.63 Loss, 0.05 Threshold\n",
            "1418 episode , 13 step , 1.73 Loss, 0.05 Threshold\n",
            "1419 episode , 11 step , 1.48 Loss, 0.05 Threshold\n",
            "1420 episode , 16 step , 1.14 Loss, 0.05 Threshold\n",
            "1421 episode , 13 step , 1.93 Loss, 0.05 Threshold\n",
            "1422 episode , 12 step , 1.56 Loss, 0.05 Threshold\n",
            "1423 episode , 14 step , 1.46 Loss, 0.05 Threshold\n",
            "1424 episode , 14 step , 1.50 Loss, 0.05 Threshold\n",
            "1425 episode , 14 step , 1.07 Loss, 0.05 Threshold\n",
            "1426 episode , 17 step , 1.28 Loss, 0.05 Threshold\n",
            "1427 episode , 18 step , 1.56 Loss, 0.05 Threshold\n",
            "1428 episode , 18 step , 1.26 Loss, 0.05 Threshold\n",
            "1429 episode , 13 step , 0.77 Loss, 0.05 Threshold\n",
            "1430 episode , 14 step , 0.91 Loss, 0.05 Threshold\n",
            "1431 episode , 17 step , 1.63 Loss, 0.05 Threshold\n",
            "1432 episode , 14 step , 1.09 Loss, 0.05 Threshold\n",
            "1433 episode , 15 step , 1.61 Loss, 0.05 Threshold\n",
            "1434 episode , 15 step , 1.77 Loss, 0.05 Threshold\n",
            "1435 episode , 15 step , 1.68 Loss, 0.05 Threshold\n",
            "1436 episode , 15 step , 2.11 Loss, 0.05 Threshold\n",
            "1437 episode , 16 step , 1.44 Loss, 0.05 Threshold\n",
            "1438 episode , 15 step , 1.48 Loss, 0.05 Threshold\n",
            "1439 episode , 12 step , 1.44 Loss, 0.05 Threshold\n",
            "1440 episode , 17 step , 1.39 Loss, 0.05 Threshold\n",
            "1441 episode , 13 step , 1.90 Loss, 0.05 Threshold\n",
            "1442 episode , 19 step , 1.55 Loss, 0.05 Threshold\n",
            "1443 episode , 15 step , 1.08 Loss, 0.05 Threshold\n",
            "1444 episode , 17 step , 1.41 Loss, 0.05 Threshold\n",
            "1445 episode , 13 step , 1.77 Loss, 0.05 Threshold\n",
            "1446 episode , 17 step , 1.62 Loss, 0.05 Threshold\n",
            "1447 episode , 14 step , 1.76 Loss, 0.05 Threshold\n",
            "1448 episode , 16 step , 1.30 Loss, 0.05 Threshold\n",
            "1449 episode , 14 step , 1.92 Loss, 0.05 Threshold\n",
            "1450 episode , 15 step , 1.78 Loss, 0.05 Threshold\n",
            "1451 episode , 14 step , 2.15 Loss, 0.05 Threshold\n",
            "1452 episode , 16 step , 1.97 Loss, 0.05 Threshold\n",
            "1453 episode , 15 step , 1.70 Loss, 0.05 Threshold\n",
            "1454 episode , 24 step , 2.23 Loss, 0.05 Threshold\n",
            "1455 episode , 15 step , 1.35 Loss, 0.05 Threshold\n",
            "1456 episode , 13 step , 1.89 Loss, 0.05 Threshold\n",
            "1457 episode , 11 step , 1.46 Loss, 0.05 Threshold\n",
            "1458 episode , 17 step , 2.25 Loss, 0.05 Threshold\n",
            "1459 episode , 16 step , 2.00 Loss, 0.05 Threshold\n",
            "1460 episode , 20 step , 1.85 Loss, 0.05 Threshold\n",
            "1461 episode , 20 step , 2.01 Loss, 0.05 Threshold\n",
            "1462 episode , 19 step , 1.83 Loss, 0.05 Threshold\n",
            "1463 episode , 13 step , 2.20 Loss, 0.05 Threshold\n",
            "1464 episode , 15 step , 1.74 Loss, 0.05 Threshold\n",
            "1465 episode , 17 step , 2.04 Loss, 0.05 Threshold\n",
            "1466 episode , 16 step , 1.90 Loss, 0.05 Threshold\n",
            "1467 episode , 17 step , 2.16 Loss, 0.05 Threshold\n",
            "1468 episode , 12 step , 2.16 Loss, 0.05 Threshold\n",
            "1469 episode , 13 step , 1.87 Loss, 0.05 Threshold\n",
            "1470 episode , 21 step , 2.06 Loss, 0.05 Threshold\n",
            "1471 episode , 17 step , 1.45 Loss, 0.05 Threshold\n",
            "1472 episode , 19 step , 2.20 Loss, 0.05 Threshold\n",
            "1473 episode , 21 step , 1.57 Loss, 0.05 Threshold\n",
            "1474 episode , 14 step , 2.27 Loss, 0.05 Threshold\n",
            "1475 episode , 16 step , 2.80 Loss, 0.05 Threshold\n",
            "1476 episode , 171 step , 2.03 Loss, 0.05 Threshold\n",
            "1477 episode , 187 step , 1.88 Loss, 0.05 Threshold\n",
            "1478 episode , 13 step , 1.92 Loss, 0.05 Threshold\n",
            "1479 episode , 11 step , 1.67 Loss, 0.05 Threshold\n",
            "1480 episode , 16 step , 2.31 Loss, 0.05 Threshold\n",
            "1481 episode , 173 step , 1.90 Loss, 0.05 Threshold\n",
            "1482 episode , 10 step , 2.11 Loss, 0.05 Threshold\n",
            "1483 episode , 183 step , 1.99 Loss, 0.05 Threshold\n",
            "1484 episode , 168 step , 1.79 Loss, 0.05 Threshold\n",
            "1485 episode , 173 step , 1.82 Loss, 0.05 Threshold\n",
            "1486 episode , 203 step , 1.86 Loss, 0.05 Threshold\n",
            "1487 episode , 227 step , 1.84 Loss, 0.05 Threshold\n",
            "1488 episode , 245 step , 1.76 Loss, 0.05 Threshold\n",
            "1489 episode , 10 step , 1.96 Loss, 0.05 Threshold\n",
            "1490 episode , 233 step , 1.87 Loss, 0.05 Threshold\n",
            "1491 episode , 12 step , 1.26 Loss, 0.05 Threshold\n",
            "1492 episode , 329 step , 1.80 Loss, 0.05 Threshold\n",
            "1493 episode , 491 step , 1.64 Loss, 0.05 Threshold\n",
            "1494 episode , 500 step , 1.73 Loss, 0.05 Threshold\n",
            "1495 episode , 500 step , 1.66 Loss, 0.05 Threshold\n",
            "1496 episode , 500 step , 1.62 Loss, 0.05 Threshold\n",
            "1497 episode , 375 step , 1.51 Loss, 0.05 Threshold\n",
            "1498 episode , 137 step , 1.45 Loss, 0.05 Threshold\n",
            "1499 episode , 12 step , 1.22 Loss, 0.05 Threshold\n",
            "Complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njQutFDQajUbjQisFjUaj0bj4f7B27CdQ09n/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}