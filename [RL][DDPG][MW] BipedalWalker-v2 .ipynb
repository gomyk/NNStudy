{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOhughljmcrh4D+sH9xx9Zr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gomyk/NNStudy/blob/moonwon/%5BRL%5D%5BDDPG%5D%5BMW%5D%20BipedalWalker-v2%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO9p_LliP05R",
        "colab_type": "text"
      },
      "source": [
        "#Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9duZfSLhJ8X",
        "colab_type": "code",
        "outputId": "113eacc1-9281-47bb-ba2e-1783f436ad3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!apt-get install x11-utils\n",
        "!pip install box2d-py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 65%\r\rReading package lists... 65%\r\rReading package lists... 66%\r\rReading package lists... 66%\r\rReading package lists... 73%\r\rReading package lists... 73%\r\rReading package lists... 73%\r\rReading package lists... 73%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 88%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 95%\r\rReading package lists... 95%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libxxf86dga1\n",
            "Suggested packages:\n",
            "  mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  libxxf86dga1 x11-utils\n",
            "0 upgraded, 2 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 209 kB of archives.\n",
            "After this operation, 711 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Fetched 209 kB in 0s (2,175 kB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "(Reading database ... 148036 files and directories currently installed.)\n",
            "Preparing to unpack .../libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Collecting box2d-py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/bd/6cdc3fd994b0649dcf5d9bad85bd9e26172308bbe9a421bfc6fdbf5081a6/box2d_py-2.3.8-cp36-cp36m-manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 8.9MB/s \n",
            "\u001b[?25hInstalling collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DE8ejMqcTWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "import math\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "from PIL import Image\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import base64\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "from google.colab import output\n",
        "\n",
        "display = Display(visible=0, size=(400,600),)\n",
        "display.start()\n",
        "env = gym.make(\"BipedalWalker-v2\")\n",
        "env._max_episode_steps = 1600\n",
        "#env.seed(10)\n",
        "#env = gym.wrappers.Monitor(gym.make(\"CartPole-v1\"), \"video\", force=True, video_callable=lambda c:c%100 ==0)\n",
        "\n",
        "# GPU를 사용할 경우\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3exp-qAP7jv",
        "colab_type": "text"
      },
      "source": [
        "##Replay Memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmc6Jfr2d8_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReplayMemory:\n",
        "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
        "\n",
        "    def __init__(self, action_dim:int , obs_dim: int, size: int, batch_size: int):\n",
        "        \"\"\"Initializate.\"\"\"\n",
        "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.acts_buf = np.zeros([size, action_dim], dtype=np.float32)\n",
        "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.done_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.max_size, self.batch_size = size, batch_size\n",
        "        self.ptr, self.size, = 0, 0\n",
        "\n",
        "    def store(\n",
        "        self,\n",
        "        obs: np.ndarray,\n",
        "        act: np.ndarray, \n",
        "        rew: float, \n",
        "        next_obs: np.ndarray, \n",
        "        done: bool,\n",
        "    ):\n",
        "        \"\"\"Store the transition in buffer.\"\"\"\n",
        "        self.obs_buf[self.ptr] = obs\n",
        "        self.next_obs_buf[self.ptr] = next_obs\n",
        "        self.acts_buf[self.ptr] = act\n",
        "        self.rews_buf[self.ptr] = rew\n",
        "        self.done_buf[self.ptr] = done\n",
        "        self.ptr = (self.ptr + 1) % self.max_size\n",
        "        self.size = min(self.size + 1, self.max_size)\n",
        "\n",
        "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
        "        return dict(obs=self.obs_buf[idxs],\n",
        "                    next_obs=self.next_obs_buf[idxs],\n",
        "                    acts=self.acts_buf[idxs],\n",
        "                    rews=self.rews_buf[idxs],\n",
        "                    done=self.done_buf[idxs])\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwrDEGlnQAeH",
        "colab_type": "text"
      },
      "source": [
        "##Define Noise Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j021icUCet_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OUNoise:\n",
        "    \"\"\"Ornstein-Uhlenbeck process.\n",
        "    Taken from Udacity deep-reinforcement-learning github repository:\n",
        "    https://github.com/udacity/deep-reinforcement-learning/blob/master/\n",
        "    ddpg-pendulum/ddpg_agent.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        size: int, \n",
        "        mu: float = 0.0, \n",
        "        theta: float = 0.15, \n",
        "        sigma: float = 0.2,\n",
        "    ):\n",
        "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
        "        self.state = np.float64(0.0)\n",
        "        self.mu = mu * np.ones(size)\n",
        "        self.theta = theta\n",
        "        self.sigma = sigma\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
        "        self.state = copy.copy(self.mu)\n",
        "\n",
        "    def sample(self) -> np.ndarray:\n",
        "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
        "        x = self.state\n",
        "        dx = self.theta * (self.mu - x) + self.sigma * np.array(\n",
        "            [random.random() for _ in range(len(x))]\n",
        "        )\n",
        "        self.state = x + dx\n",
        "        return self.state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYAZSWC2QGDx",
        "colab_type": "text"
      },
      "source": [
        "##Actor Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1hagvrqKTpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HIDDEN_SIZE = 256\n",
        "HIDDEN_SIZE2 = 128\n",
        "class Actor(nn.Module):\n",
        "\n",
        "    def __init__(self, obs_size, outputs, init_w: float = 3e-3,):\n",
        "        super(Actor, self).__init__()\n",
        "        self.linear = nn.Linear(obs_size, HIDDEN_SIZE)\n",
        "        self.linear2 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE2)\n",
        "        self.linear3 = nn.Linear(HIDDEN_SIZE2, HIDDEN_SIZE)\n",
        "        self.head = nn.Linear(HIDDEN_SIZE, outputs)\n",
        "\n",
        "        self.head.weight.data.uniform_(-init_w, init_w)\n",
        "        self.head.bias.data.uniform_(-init_w, init_w)\n",
        "\n",
        "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
        "        x = F.relu(self.linear(state))\n",
        "        #x = F.relu(self.linear2(x))\n",
        "        #x = F.dropout(x, 0.5)\n",
        "        #x = F.relu(self.linear3(x))\n",
        "        return self.head(x).tanh()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy5GwnzbQJ4o",
        "colab_type": "text"
      },
      "source": [
        "##Critic Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_lqf372OXYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Critic(nn.Module):\n",
        "\n",
        "    def __init__(self, obs_size, action_size, init_w: float = 3e-3,):\n",
        "        super(Critic, self).__init__()\n",
        "        self.linear = nn.Linear(obs_size + action_size, HIDDEN_SIZE)\n",
        "        self.linear2 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE2)\n",
        "        self.linear3 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.head = nn.Linear(HIDDEN_SIZE2, 1)\n",
        "\n",
        "        self.head.weight.data.uniform_(-init_w, init_w)\n",
        "        self.head.bias.data.uniform_(-init_w, init_w)\n",
        "\n",
        "    def forward(self, state: torch.Tensor, action: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward method implementation.\"\"\"\n",
        "        x = torch.cat((state, action), dim=-1)\n",
        "        x = F.relu(self.linear(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        #x = F.dropout(x, 0.5)\n",
        "        #x = F.relu(self.linear3(x))\n",
        "        return self.head(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtxzbD_-QPWZ",
        "colab_type": "text"
      },
      "source": [
        "###Environment Snapshot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVgLn9rKgS79",
        "colab_type": "code",
        "outputId": "04628f2b-d1ab-4f6e-e0c1-8325d66d3362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "env.reset()\n",
        "plt.figure()\n",
        "plt.imshow(env.render(mode='rgb_array'))\n",
        "plt.title('Example extracted screen')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8/8B/XE15dEidRkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_0DaDLxQVkZ",
        "colab_type": "text"
      },
      "source": [
        "##Prepare to learning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y5GkgVljenU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.99\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.01\n",
        "EPS_DECAY = 2000\n",
        "TARGET_UPDATE = 9\n",
        "ACTOR_LR = 0.0001\n",
        "CRITIC_LR = 0.0003\n",
        "MEMORY_SIZE = 10000\n",
        "EPISODE_SIZE = 500\n",
        "TAU = 0.001\n",
        "ou_noise_theta = 0.15\n",
        "ou_noise_sigma = 0.2\n",
        "\n",
        "RECORD_INTERVAL = 99\n",
        "\n",
        "# gym 행동 공간에서 행동의 숫자를 얻습니다.\n",
        "#n_actions = env.action_space.n\n",
        "n_actions = env.action_space.shape[0]\n",
        "n_obvs = env.observation_space.shape[0]\n",
        "\n",
        "actor = Actor(n_obvs, n_actions).to(device)\n",
        "actor.eval()\n",
        "actor_target = Actor(n_obvs, n_actions).to(device)\n",
        "actor_target.load_state_dict(actor.state_dict())\n",
        "actor_target.eval()\n",
        "\n",
        "critic = Critic(n_obvs, n_actions).to(device)\n",
        "critic.eval()\n",
        "critic_target = Critic(n_obvs, n_actions).to(device)\n",
        "critic_target.load_state_dict(critic.state_dict())\n",
        "critic_target.eval()\n",
        "\n",
        "actor_optimizer = optim.Adam(actor.parameters(), lr=ACTOR_LR)\n",
        "critic_optimizer = optim.Adam(critic.parameters(), lr=CRITIC_LR, weight_decay=0.0001)\n",
        "memory = ReplayMemory(n_actions,n_obvs,MEMORY_SIZE,BATCH_SIZE)\n",
        "\n",
        "noise = OUNoise(\n",
        "            n_actions,\n",
        "            theta=ou_noise_theta,\n",
        "            sigma=ou_noise_sigma,\n",
        "        )\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    steps_done += 1\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    if sample < eps_threshold:\n",
        "            #selected_action = [np.random.uniform(0,1),np.random.uniform(0,1),np.random.uniform(0,1)]\n",
        "            selected_action = np.random.uniform(-1,1,n_actions)\n",
        "    else:\n",
        "        selected_action = actor(\n",
        "             torch.FloatTensor(state).to(device)\n",
        "         ).detach().cpu().numpy()\n",
        "    _noise = noise.sample()\n",
        "    for action in selected_action:\n",
        "      action = np.clip(action + _noise, -1.0, 1.0)\n",
        "    return selected_action\n",
        "episode_durations = []\n",
        "\n",
        "\n",
        "def plot_durations():\n",
        "    plt.figure(2)\n",
        "    plt.clf()\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Total Reward')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # 100개의 에피소드 평균을 가져 와서 도표 그리기\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB_xKtOnUR4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def target_soft_update():\n",
        "        #Soft-update: target = tau*local + (1-tau)*target\n",
        "        tau = TAU\n",
        "        \n",
        "        for t_param, l_param in zip(\n",
        "            actor_target.parameters(), actor.parameters()\n",
        "        ):\n",
        "            t_param.data.copy_(tau * l_param.data + (1.0 - tau) * t_param.data)\n",
        "            \n",
        "        for t_param, l_param in zip(\n",
        "            critic_target.parameters(), critic.parameters()\n",
        "        ):\n",
        "            t_param.data.copy_(tau * l_param.data + (1.0 - tau) * t_param.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpvU9RgzCYsW",
        "colab_type": "text"
      },
      "source": [
        "##Normalizer for obv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW7qP2ZuQf-s",
        "colab_type": "text"
      },
      "source": [
        "##Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1Vbb4tzjnjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return -1 , -1\n",
        "    samples = memory.sample_batch()\n",
        "    state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
        "    next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
        "    action = torch.FloatTensor(samples[\"acts\"]).to(device)\n",
        "    reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
        "    done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
        "    \n",
        "    masks = 1 - done\n",
        "    next_action = actor_target(next_state)\n",
        "    next_value = critic_target(next_state, next_action)\n",
        "    curr_return = reward + GAMMA * next_value * masks\n",
        "\n",
        "    # train critic\n",
        "    values = critic(state, action)\n",
        "    critic_loss = F.smooth_l1_loss(values, curr_return)\n",
        "    critic_optimizer.zero_grad()\n",
        "    critic_loss.backward()\n",
        "    critic_optimizer.step()     \n",
        "    # train actor\n",
        "    loss = critic(state, actor(state))\n",
        "    actor_loss = -loss.mean()\n",
        "        \n",
        "    actor_optimizer.zero_grad()\n",
        "    actor_loss.backward()\n",
        "    actor_optimizer.step()\n",
        "        \n",
        "    # target update\n",
        "    target_soft_update()\n",
        "\n",
        "    return actor_loss.data, critic_loss.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4UN3NpFQiLJ",
        "colab_type": "text"
      },
      "source": [
        "##Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-2dnWNDjp7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frames = []\n",
        "\n",
        "for i_episode in range(EPISODE_SIZE):\n",
        "    # 환경과 상태 초기화\n",
        "    obv = env.reset()\n",
        "    total_actor_loss = 0\n",
        "    total_critic_loss = 0\n",
        "    total_reward = 0\n",
        "    global steps_done\n",
        "    top_reward = -1\n",
        "    total_action_count = [0,0,0]\n",
        "    for t in count():\n",
        "        if i_episode % RECORD_INTERVAL == 0:\n",
        "          frames.append(env.render(mode=\"rgb_array\"))\n",
        "        # 행동 선택과 수행\n",
        "        action = select_action(obv)\n",
        "        next_obv, reward, done, _ = env.step(action)\n",
        "        reward = max(min(reward, 1), -1)\n",
        "        if reward > top_reward:\n",
        "          top_reward = reward\n",
        "        total_reward += reward\n",
        "\n",
        "        # 메모리에 변이 저장\n",
        "        assert obv is not None\n",
        "        memory.store(obv, action, reward, next_obv, done)\n",
        "\n",
        "        # 다음 상태로 이동\n",
        "        obv = next_obv\n",
        "\n",
        "        # 최적화 한단계 수행(목표 네트워크에서)\n",
        "        actor_loss, critic_loss = optimize_model()\n",
        "        total_actor_loss += actor_loss\n",
        "        total_critic_loss += critic_loss\n",
        "        if done:\n",
        "            E = eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "            math.exp(-1. * steps_done / EPS_DECAY)\n",
        "            episode_durations.append(total_reward)\n",
        "            print('%d episode , %d step , %.2f Actor Loss, %.2f Critic Loss,  %.2f Threshold , %.2f Top reward, %.2f Total reward'\\\n",
        "                  %(i_episode,t+1,total_actor_loss/(t+1), total_critic_loss/(t+1) ,E, top_reward, total_reward))\n",
        "            #print(total_action_count)\n",
        "            plot_durations()\n",
        "            total_actor_loss = 0\n",
        "            total_critic_loss = 0\n",
        "            top_reward = 0\n",
        "            total_reward = 0\n",
        "            total_action_count = [0,0,0]\n",
        "            break\n",
        "    #목표 네트워크 업데이트, 모든 웨이트와 바이어스 복사\n",
        "    if i_episode % TARGET_UPDATE == 0:\n",
        "        actor_target.load_state_dict(actor.state_dict())\n",
        "        critic_target.load_state_dict(critic.state_dict())\n",
        "print('Complete')\n",
        "env.render()\n",
        "env.close()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pWWG7HcMD3j",
        "colab_type": "text"
      },
      "source": [
        "## Rendering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lg-4834irdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHCq9xymdUgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install JSAnimation\n",
        "from matplotlib import animation, rc\n",
        "from JSAnimation.IPython_display import display_animation\n",
        "from IPython.display import display\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2NMRr68tmra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_video():\n",
        "  mp4list = glob.glob('./*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    print(mp4list)\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jaeim4ulL0y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports specifically so we can render outputs in Colab.\n",
        "fig = plt.figure()\n",
        "def display_frames_as_gif(frame):\n",
        "    \"\"\"Displays a list of frames as a gif, with controls.\"\"\"\n",
        "    patch = plt.imshow(frame[0].astype(int))\n",
        "    def animate(i):\n",
        "        patch.set_data(frame[i].astype(int))\n",
        "\n",
        "    anim = animation.FuncAnimation(\n",
        "        fig, animate, frames=len(frames), interval=30, blit=False\n",
        "    )\n",
        "    #display(display_animation(anim, default_mode='loop'))\n",
        "    # Set up formatting for the movie files\n",
        "    display(HTML(data=anim.to_html5_video()))\n",
        "    #FFwriter = animation.FFMpegWriter()\n",
        "    #anim.save('basic_animation.mp4', writer = FFwriter)\n",
        "    #show_video()\n",
        "# display \n",
        "display_frames_as_gif(frames)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}