{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMREq0UxPuW64WevatFXK3n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gomyk/NNStudy/blob/moonwon/%5BRL%5D%5BDDPG%5D%5BMW%5D%20BipedalWalker-v2%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO9p_LliP05R",
        "colab_type": "text"
      },
      "source": [
        "#Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9duZfSLhJ8X",
        "colab_type": "code",
        "outputId": "8f359c25-8dfa-4b53-a721-0404ed83bed7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!apt-get install x11-utils\n",
        "!pip install box2d-py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "x11-utils is already the newest version (7.7+3build1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n",
            "Requirement already satisfied: box2d-py in /usr/local/lib/python3.6/dist-packages (2.3.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DE8ejMqcTWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "import math\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "from PIL import Image\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import base64\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "from google.colab import output\n",
        "\n",
        "display = Display(visible=0, size=(400,600),)\n",
        "display.start()\n",
        "env = gym.make(\"BipedalWalker-v2\")\n",
        "env._max_episode_steps = 1600\n",
        "#env = gym.wrappers.Monitor(gym.make(\"CartPole-v1\"), \"video\", force=True, video_callable=lambda c:c%100 ==0)\n",
        "\n",
        "# GPU를 사용할 경우\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3exp-qAP7jv",
        "colab_type": "text"
      },
      "source": [
        "##Replay Memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmc6Jfr2d8_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReplayMemory:\n",
        "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
        "\n",
        "    def __init__(self, action_dim:int , obs_dim: int, size: int, batch_size: int):\n",
        "        \"\"\"Initializate.\"\"\"\n",
        "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.acts_buf = np.zeros([size, action_dim], dtype=np.float32)\n",
        "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.done_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.max_size, self.batch_size = size, batch_size\n",
        "        self.ptr, self.size, = 0, 0\n",
        "\n",
        "    def store(\n",
        "        self,\n",
        "        obs: np.ndarray,\n",
        "        act: np.ndarray, \n",
        "        rew: float, \n",
        "        next_obs: np.ndarray, \n",
        "        done: bool,\n",
        "    ):\n",
        "        \"\"\"Store the transition in buffer.\"\"\"\n",
        "        self.obs_buf[self.ptr] = obs\n",
        "        self.next_obs_buf[self.ptr] = next_obs\n",
        "        self.acts_buf[self.ptr] = act\n",
        "        self.rews_buf[self.ptr] = rew\n",
        "        self.done_buf[self.ptr] = done\n",
        "        self.ptr = (self.ptr + 1) % self.max_size\n",
        "        self.size = min(self.size + 1, self.max_size)\n",
        "\n",
        "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
        "        return dict(obs=self.obs_buf[idxs],\n",
        "                    next_obs=self.next_obs_buf[idxs],\n",
        "                    acts=self.acts_buf[idxs],\n",
        "                    rews=self.rews_buf[idxs],\n",
        "                    done=self.done_buf[idxs])\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwrDEGlnQAeH",
        "colab_type": "text"
      },
      "source": [
        "##Define Noise Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j021icUCet_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OUNoise:\n",
        "    \"\"\"Ornstein-Uhlenbeck process.\n",
        "    Taken from Udacity deep-reinforcement-learning github repository:\n",
        "    https://github.com/udacity/deep-reinforcement-learning/blob/master/\n",
        "    ddpg-pendulum/ddpg_agent.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        size: int, \n",
        "        mu: float = 0.0, \n",
        "        theta: float = 0.15, \n",
        "        sigma: float = 0.2,\n",
        "    ):\n",
        "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
        "        self.state = np.float64(0.0)\n",
        "        self.mu = mu * np.ones(size)\n",
        "        self.theta = theta\n",
        "        self.sigma = sigma\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
        "        self.state = copy.copy(self.mu)\n",
        "\n",
        "    def sample(self) -> np.ndarray:\n",
        "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
        "        x = self.state\n",
        "        dx = self.theta * (self.mu - x) + self.sigma * np.array(\n",
        "            [random.random() for _ in range(len(x))]\n",
        "        )\n",
        "        self.state = x + dx\n",
        "        return self.state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYAZSWC2QGDx",
        "colab_type": "text"
      },
      "source": [
        "##Actor Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1hagvrqKTpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HIDDEN_SIZE = 64\n",
        "class Actor(nn.Module):\n",
        "\n",
        "    def __init__(self, obs_size, outputs, init_w: float = 3e-3,):\n",
        "        super(Actor, self).__init__()\n",
        "        self.linear = nn.Linear(obs_size, HIDDEN_SIZE)\n",
        "        self.linear2 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.linear3 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.head = nn.Linear(HIDDEN_SIZE, outputs)\n",
        "\n",
        "        self.head.weight.data.uniform_(-init_w, init_w)\n",
        "        self.head.bias.data.uniform_(-init_w, init_w)\n",
        "\n",
        "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
        "        x = F.relu(self.linear(state))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = F.relu(self.linear3(x))\n",
        "        return self.head(x).tanh()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy5GwnzbQJ4o",
        "colab_type": "text"
      },
      "source": [
        "##Critic Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_lqf372OXYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Critic(nn.Module):\n",
        "\n",
        "    def __init__(self, obs_size, action_size, init_w: float = 3e-3,):\n",
        "        super(Critic, self).__init__()\n",
        "        self.linear = nn.Linear(obs_size + action_size, HIDDEN_SIZE)\n",
        "        self.linear2 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.linear3 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.head = nn.Linear(HIDDEN_SIZE, 1)\n",
        "\n",
        "        self.head.weight.data.uniform_(-init_w, init_w)\n",
        "        self.head.bias.data.uniform_(-init_w, init_w)\n",
        "\n",
        "    def forward(self, state: torch.Tensor, action: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward method implementation.\"\"\"\n",
        "        x = torch.cat((state, action), dim=-1)\n",
        "        x = F.relu(self.linear(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = F.relu(self.linear3(x))\n",
        "        return self.head(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtxzbD_-QPWZ",
        "colab_type": "text"
      },
      "source": [
        "###Environment Snapshot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVgLn9rKgS79",
        "colab_type": "code",
        "outputId": "ae873c0e-3ce2-47a9-c3b3-b15021dda9f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "env.reset()\n",
        "plt.figure()\n",
        "plt.imshow(env.render(mode='rgb_array'))\n",
        "plt.title('Example extracted screen')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGNcZc70AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_0DaDLxQVkZ",
        "colab_type": "text"
      },
      "source": [
        "##Prepare to learning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y5GkgVljenU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.99\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 2000\n",
        "TARGET_UPDATE = 4\n",
        "ACTOR_LR = 0.0001\n",
        "CRITIC_LR = 0.0001\n",
        "MEMORY_SIZE = 5000\n",
        "EPISODE_SIZE = 500\n",
        "TAU = 0.005\n",
        "ou_noise_theta = 1.0\n",
        "ou_noise_sigma = 0.1\n",
        "\n",
        "RECORD_INTERVAL = 49\n",
        "\n",
        "# gym 행동 공간에서 행동의 숫자를 얻습니다.\n",
        "#n_actions = env.action_space.n\n",
        "n_actions = 4\n",
        "n_obvs = 24\n",
        "\n",
        "actor = Actor(n_obvs, n_actions).to(device)\n",
        "actor.eval()\n",
        "actor_target = Actor(n_obvs, n_actions).to(device)\n",
        "actor_target.load_state_dict(actor.state_dict())\n",
        "actor_target.eval()\n",
        "\n",
        "critic = Critic(n_obvs, n_actions).to(device)\n",
        "critic.eval()\n",
        "critic_target = Critic(n_obvs, n_actions).to(device)\n",
        "critic_target.load_state_dict(critic.state_dict())\n",
        "critic_target.eval()\n",
        "\n",
        "actor_optimizer = optim.Adam(actor.parameters(), lr=ACTOR_LR)\n",
        "critic_optimizer = optim.Adam(critic.parameters(), lr=CRITIC_LR)\n",
        "memory = ReplayMemory(n_actions,n_obvs,MEMORY_SIZE,BATCH_SIZE)\n",
        "\n",
        "noise = OUNoise(\n",
        "            n_actions,\n",
        "            theta=ou_noise_theta,\n",
        "            sigma=ou_noise_sigma,\n",
        "        )\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    steps_done += 1\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    if sample < eps_threshold:\n",
        "            #selected_action = [np.random.uniform(0,1),np.random.uniform(0,1),np.random.uniform(0,1)]\n",
        "            selected_action = np.random.uniform(-1,1,n_actions)\n",
        "    else:\n",
        "        selected_action = actor(\n",
        "             torch.FloatTensor(state).to(device)\n",
        "         ).detach().cpu().numpy()\n",
        "    _noise = noise.sample()\n",
        "    for action in selected_action:\n",
        "      action = np.clip(action + _noise, -1.0, 1.0)\n",
        "    return selected_action\n",
        "episode_durations = []\n",
        "\n",
        "\n",
        "def plot_durations():\n",
        "    plt.figure(2)\n",
        "    plt.clf()\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # 100개의 에피소드 평균을 가져 와서 도표 그리기\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB_xKtOnUR4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def target_soft_update():\n",
        "        #Soft-update: target = tau*local + (1-tau)*target\n",
        "        tau = TAU\n",
        "        \n",
        "        for t_param, l_param in zip(\n",
        "            actor_target.parameters(), actor.parameters()\n",
        "        ):\n",
        "            t_param.data.copy_(tau * l_param.data + (1.0 - tau) * t_param.data)\n",
        "            \n",
        "        for t_param, l_param in zip(\n",
        "            critic_target.parameters(), critic.parameters()\n",
        "        ):\n",
        "            t_param.data.copy_(tau * l_param.data + (1.0 - tau) * t_param.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW7qP2ZuQf-s",
        "colab_type": "text"
      },
      "source": [
        "##Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1Vbb4tzjnjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return -1 , -1\n",
        "    samples = memory.sample_batch()\n",
        "    state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
        "    next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
        "    action = torch.FloatTensor(samples[\"acts\"]).to(device)\n",
        "    reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
        "    done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
        "    \n",
        "    masks = 1 - done\n",
        "    next_action = actor_target(next_state)\n",
        "    next_value = critic_target(next_state, next_action)\n",
        "    curr_return = reward + GAMMA * next_value * masks\n",
        "\n",
        "    # train critic\n",
        "    values = critic(state, action)\n",
        "    critic_loss = F.smooth_l1_loss(values, curr_return)\n",
        "    critic_optimizer.zero_grad()\n",
        "    critic_loss.backward()\n",
        "    critic_optimizer.step()     \n",
        "    # train actor\n",
        "    loss = critic(state, actor(state))\n",
        "    actor_loss = -loss.mean()\n",
        "        \n",
        "    actor_optimizer.zero_grad()\n",
        "    actor_loss.backward()\n",
        "    actor_optimizer.step()\n",
        "        \n",
        "    # target update\n",
        "    target_soft_update()\n",
        "\n",
        "    return actor_loss.data, critic_loss.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4UN3NpFQiLJ",
        "colab_type": "text"
      },
      "source": [
        "##Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-2dnWNDjp7y",
        "colab_type": "code",
        "outputId": "9c3cdd04-e44a-498b-db90-b9aaa74e9a5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "frames = []\n",
        "for i_episode in range(EPISODE_SIZE):\n",
        "    # 환경과 상태 초기화\n",
        "    obv = env.reset()\n",
        "    total_actor_loss = 0\n",
        "    total_critic_loss = 0\n",
        "    total_reward = 0\n",
        "    global steps_done\n",
        "    top_reward = -1\n",
        "    total_action_count = [0,0,0]\n",
        "    for t in count():\n",
        "        if i_episode % RECORD_INTERVAL == 0:\n",
        "          frames.append(env.render(mode=\"rgb_array\"))\n",
        "        # 행동 선택과 수행\n",
        "        action = select_action(obv)\n",
        "        next_obv, reward, done, _ = env.step(action)\n",
        "        if reward > top_reward:\n",
        "          top_reward = reward\n",
        "        total_reward += reward\n",
        "        if reward > 0 :\n",
        "          reward *= 2\n",
        "        # 메모리에 변이 저장\n",
        "        assert obv is not None\n",
        "        memory.store(obv, action, reward, next_obv, done)\n",
        "\n",
        "        # 다음 상태로 이동\n",
        "        obv = next_obv\n",
        "\n",
        "        # 최적화 한단계 수행(목표 네트워크에서)\n",
        "        actor_loss, critic_loss = optimize_model()\n",
        "        total_actor_loss += actor_loss\n",
        "        total_critic_loss += critic_loss\n",
        "        if done:\n",
        "            E = eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "            math.exp(-1. * steps_done / EPS_DECAY)\n",
        "            episode_durations.append(t + 1)\n",
        "            print('%d episode , %d step , %.2f Actor Loss, %.2f Critic Loss,  %.2f Threshold , %.2f Top reward, %.2f Avg reward'\\\n",
        "                  %(i_episode,t+1,total_actor_loss/(t+1), total_critic_loss/(t+1) ,E, top_reward, total_reward/(t+1)))\n",
        "            print(total_action_count)\n",
        "            plot_durations()\n",
        "            total_actor_loss = 0\n",
        "            total_critic_loss = 0\n",
        "            top_reward = 0\n",
        "            total_reward = 0\n",
        "            total_action_count = [0,0,0]\n",
        "            break\n",
        "    #목표 네트워크 업데이트, 모든 웨이트와 바이어스 복사\n",
        "    if i_episode % TARGET_UPDATE == 0:\n",
        "        actor_target.load_state_dict(actor.state_dict())\n",
        "        critic_target.load_state_dict(critic.state_dict())\n",
        "print('Complete')\n",
        "env.render()\n",
        "env.close()\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 episode , 65 step , -1.00 Actor Loss, -1.00 Critic Loss,  0.87 Threshold , 0.37 Top reward, -1.60 Avg reward\n",
            "[0, 0, 0]\n",
            "1 episode , 1366 step , -0.24 Actor Loss, 0.13 Critic Loss,  0.47 Threshold , 0.31 Top reward, -0.12 Avg reward\n",
            "[0, 0, 0]\n",
            "2 episode , 60 step , -0.22 Actor Loss, 0.16 Critic Loss,  0.45 Threshold , 0.24 Top reward, -1.81 Avg reward\n",
            "[0, 0, 0]\n",
            "3 episode , 58 step , -0.20 Actor Loss, 0.28 Critic Loss,  0.44 Threshold , 0.19 Top reward, -1.94 Avg reward\n",
            "[0, 0, 0]\n",
            "4 episode , 93 step , -0.21 Actor Loss, 0.31 Critic Loss,  0.42 Threshold , 0.16 Top reward, -1.14 Avg reward\n",
            "[0, 0, 0]\n",
            "5 episode , 1600 step , -0.62 Actor Loss, 0.21 Critic Loss,  0.22 Threshold , 0.35 Top reward, -0.05 Avg reward\n",
            "[0, 0, 0]\n",
            "6 episode , 40 step , -0.94 Actor Loss, 0.21 Critic Loss,  0.21 Threshold , -0.05 Top reward, -2.70 Avg reward\n",
            "[0, 0, 0]\n",
            "7 episode , 135 step , -1.02 Actor Loss, 0.20 Critic Loss,  0.20 Threshold , 0.34 Top reward, -0.72 Avg reward\n",
            "[0, 0, 0]\n",
            "8 episode , 53 step , -1.08 Actor Loss, 0.21 Critic Loss,  0.20 Threshold , -0.09 Top reward, -2.11 Avg reward\n",
            "[0, 0, 0]\n",
            "9 episode , 56 step , -1.19 Actor Loss, 0.25 Critic Loss,  0.20 Threshold , 0.01 Top reward, -1.98 Avg reward\n",
            "[0, 0, 0]\n",
            "10 episode , 56 step , -1.22 Actor Loss, 0.35 Critic Loss,  0.19 Threshold , 0.04 Top reward, -1.97 Avg reward\n",
            "[0, 0, 0]\n",
            "11 episode , 1600 step , -1.34 Actor Loss, 0.25 Critic Loss,  0.11 Threshold , 0.36 Top reward, -0.06 Avg reward\n",
            "[0, 0, 0]\n",
            "12 episode , 400 step , -1.40 Actor Loss, 0.19 Critic Loss,  0.10 Threshold , 0.56 Top reward, -0.27 Avg reward\n",
            "[0, 0, 0]\n",
            "13 episode , 74 step , -1.52 Actor Loss, 0.17 Critic Loss,  0.10 Threshold , 0.30 Top reward, -1.39 Avg reward\n",
            "[0, 0, 0]\n",
            "14 episode , 134 step , -1.57 Actor Loss, 0.21 Critic Loss,  0.10 Threshold , 0.33 Top reward, -0.73 Avg reward\n",
            "[0, 0, 0]\n",
            "15 episode , 1467 step , -1.92 Actor Loss, 0.22 Critic Loss,  0.07 Threshold , 0.31 Top reward, -0.12 Avg reward\n",
            "[0, 0, 0]\n",
            "16 episode , 768 step , -2.45 Actor Loss, 0.18 Critic Loss,  0.07 Threshold , 0.20 Top reward, -0.20 Avg reward\n",
            "[0, 0, 0]\n",
            "17 episode , 97 step , -2.68 Actor Loss, 0.19 Critic Loss,  0.06 Threshold , 0.26 Top reward, -1.01 Avg reward\n",
            "[0, 0, 0]\n",
            "18 episode , 129 step , -2.76 Actor Loss, 0.22 Critic Loss,  0.06 Threshold , 0.28 Top reward, -0.79 Avg reward\n",
            "[0, 0, 0]\n",
            "19 episode , 107 step , -2.80 Actor Loss, 0.26 Critic Loss,  0.06 Threshold , 0.29 Top reward, -0.92 Avg reward\n",
            "[0, 0, 0]\n",
            "20 episode , 91 step , -2.79 Actor Loss, 0.24 Critic Loss,  0.06 Threshold , 0.26 Top reward, -1.09 Avg reward\n",
            "[0, 0, 0]\n",
            "21 episode , 106 step , -3.01 Actor Loss, 0.19 Critic Loss,  0.06 Threshold , 0.27 Top reward, -0.94 Avg reward\n",
            "[0, 0, 0]\n",
            "22 episode , 102 step , -3.16 Actor Loss, 0.22 Critic Loss,  0.06 Threshold , 0.27 Top reward, -0.99 Avg reward\n",
            "[0, 0, 0]\n",
            "23 episode , 90 step , -3.19 Actor Loss, 0.12 Critic Loss,  0.06 Threshold , 0.32 Top reward, -1.14 Avg reward\n",
            "[0, 0, 0]\n",
            "24 episode , 134 step , -3.22 Actor Loss, 0.28 Critic Loss,  0.06 Threshold , 0.14 Top reward, -0.96 Avg reward\n",
            "[0, 0, 0]\n",
            "25 episode , 152 step , -3.26 Actor Loss, 0.34 Critic Loss,  0.06 Threshold , 0.41 Top reward, -0.67 Avg reward\n",
            "[0, 0, 0]\n",
            "26 episode , 88 step , -3.32 Actor Loss, 0.27 Critic Loss,  0.06 Threshold , -0.02 Top reward, -1.45 Avg reward\n",
            "[0, 0, 0]\n",
            "27 episode , 59 step , -3.30 Actor Loss, 0.29 Critic Loss,  0.06 Threshold , 0.09 Top reward, -1.74 Avg reward\n",
            "[0, 0, 0]\n",
            "28 episode , 77 step , -3.20 Actor Loss, 0.36 Critic Loss,  0.06 Threshold , 0.15 Top reward, -1.34 Avg reward\n",
            "[0, 0, 0]\n",
            "29 episode , 138 step , -3.20 Actor Loss, 0.35 Critic Loss,  0.06 Threshold , -0.01 Top reward, -0.96 Avg reward\n",
            "[0, 0, 0]\n",
            "30 episode , 129 step , -3.16 Actor Loss, 0.36 Critic Loss,  0.06 Threshold , -0.05 Top reward, -1.02 Avg reward\n",
            "[0, 0, 0]\n",
            "31 episode , 99 step , -3.07 Actor Loss, 0.34 Critic Loss,  0.06 Threshold , 0.26 Top reward, -1.01 Avg reward\n",
            "[0, 0, 0]\n",
            "32 episode , 154 step , -3.09 Actor Loss, 0.40 Critic Loss,  0.06 Threshold , 0.47 Top reward, -0.64 Avg reward\n",
            "[0, 0, 0]\n",
            "33 episode , 109 step , -3.05 Actor Loss, 0.47 Critic Loss,  0.06 Threshold , 0.28 Top reward, -0.92 Avg reward\n",
            "[0, 0, 0]\n",
            "34 episode , 165 step , -3.12 Actor Loss, 0.41 Critic Loss,  0.06 Threshold , 0.24 Top reward, -0.65 Avg reward\n",
            "[0, 0, 0]\n",
            "35 episode , 74 step , -3.02 Actor Loss, 0.40 Critic Loss,  0.06 Threshold , 0.20 Top reward, -1.45 Avg reward\n",
            "[0, 0, 0]\n",
            "36 episode , 136 step , -2.90 Actor Loss, 0.42 Critic Loss,  0.06 Threshold , 0.28 Top reward, -0.78 Avg reward\n",
            "[0, 0, 0]\n",
            "37 episode , 98 step , -2.71 Actor Loss, 0.52 Critic Loss,  0.05 Threshold , 0.32 Top reward, -1.06 Avg reward\n",
            "[0, 0, 0]\n",
            "38 episode , 141 step , -2.68 Actor Loss, 0.50 Critic Loss,  0.05 Threshold , 0.08 Top reward, -0.95 Avg reward\n",
            "[0, 0, 0]\n",
            "39 episode , 122 step , -2.53 Actor Loss, 0.55 Critic Loss,  0.05 Threshold , 0.32 Top reward, -0.84 Avg reward\n",
            "[0, 0, 0]\n",
            "40 episode , 67 step , -2.57 Actor Loss, 0.63 Critic Loss,  0.05 Threshold , 0.28 Top reward, -1.56 Avg reward\n",
            "[0, 0, 0]\n",
            "41 episode , 121 step , -2.60 Actor Loss, 0.47 Critic Loss,  0.05 Threshold , 0.28 Top reward, -0.82 Avg reward\n",
            "[0, 0, 0]\n",
            "42 episode , 1549 step , -3.98 Actor Loss, 0.50 Critic Loss,  0.05 Threshold , 0.37 Top reward, -0.09 Avg reward\n",
            "[0, 0, 0]\n",
            "43 episode , 45 step , -5.27 Actor Loss, 0.42 Critic Loss,  0.05 Threshold , -0.04 Top reward, -2.40 Avg reward\n",
            "[0, 0, 0]\n",
            "44 episode , 77 step , -4.68 Actor Loss, 0.48 Critic Loss,  0.05 Threshold , 0.01 Top reward, -1.39 Avg reward\n",
            "[0, 0, 0]\n",
            "45 episode , 204 step , -4.80 Actor Loss, 0.48 Critic Loss,  0.05 Threshold , 0.35 Top reward, -0.54 Avg reward\n",
            "[0, 0, 0]\n",
            "46 episode , 72 step , -4.72 Actor Loss, 0.47 Critic Loss,  0.05 Threshold , 0.15 Top reward, -1.55 Avg reward\n",
            "[0, 0, 0]\n",
            "47 episode , 102 step , -4.47 Actor Loss, 0.55 Critic Loss,  0.05 Threshold , 0.01 Top reward, -1.29 Avg reward\n",
            "[0, 0, 0]\n",
            "48 episode , 68 step , -3.84 Actor Loss, 0.54 Critic Loss,  0.05 Threshold , 0.02 Top reward, -1.72 Avg reward\n",
            "[0, 0, 0]\n",
            "49 episode , 183 step , -3.92 Actor Loss, 0.56 Critic Loss,  0.05 Threshold , 0.26 Top reward, -0.67 Avg reward\n",
            "[0, 0, 0]\n",
            "50 episode , 91 step , -3.62 Actor Loss, 0.54 Critic Loss,  0.05 Threshold , -0.00 Top reward, -1.36 Avg reward\n",
            "[0, 0, 0]\n",
            "51 episode , 79 step , -3.23 Actor Loss, 0.53 Critic Loss,  0.05 Threshold , 0.02 Top reward, -1.61 Avg reward\n",
            "[0, 0, 0]\n",
            "52 episode , 53 step , -2.91 Actor Loss, 0.52 Critic Loss,  0.05 Threshold , 0.02 Top reward, -2.16 Avg reward\n",
            "[0, 0, 0]\n",
            "53 episode , 54 step , -3.20 Actor Loss, 0.56 Critic Loss,  0.05 Threshold , 0.02 Top reward, -2.14 Avg reward\n",
            "[0, 0, 0]\n",
            "54 episode , 79 step , -2.83 Actor Loss, 0.54 Critic Loss,  0.05 Threshold , -0.02 Top reward, -1.54 Avg reward\n",
            "[0, 0, 0]\n",
            "55 episode , 841 step , -2.07 Actor Loss, 0.53 Critic Loss,  0.05 Threshold , 0.42 Top reward, -0.22 Avg reward\n",
            "[0, 0, 0]\n",
            "56 episode , 73 step , -1.50 Actor Loss, 0.59 Critic Loss,  0.05 Threshold , 0.01 Top reward, -1.65 Avg reward\n",
            "[0, 0, 0]\n",
            "57 episode , 132 step , -1.20 Actor Loss, 0.61 Critic Loss,  0.05 Threshold , 0.12 Top reward, -0.98 Avg reward\n",
            "[0, 0, 0]\n",
            "58 episode , 98 step , -1.27 Actor Loss, 0.62 Critic Loss,  0.05 Threshold , 0.27 Top reward, -1.00 Avg reward\n",
            "[0, 0, 0]\n",
            "59 episode , 813 step , -1.78 Actor Loss, 0.57 Critic Loss,  0.05 Threshold , 0.37 Top reward, -0.11 Avg reward\n",
            "[0, 0, 0]\n",
            "60 episode , 126 step , -2.64 Actor Loss, 0.58 Critic Loss,  0.05 Threshold , 0.42 Top reward, -0.72 Avg reward\n",
            "[0, 0, 0]\n",
            "61 episode , 63 step , -2.13 Actor Loss, 0.66 Critic Loss,  0.05 Threshold , -0.00 Top reward, -1.91 Avg reward\n",
            "[0, 0, 0]\n",
            "62 episode , 124 step , -2.29 Actor Loss, 0.59 Critic Loss,  0.05 Threshold , 0.15 Top reward, -1.04 Avg reward\n",
            "[0, 0, 0]\n",
            "63 episode , 136 step , -2.39 Actor Loss, 0.56 Critic Loss,  0.05 Threshold , 0.28 Top reward, -0.77 Avg reward\n",
            "[0, 0, 0]\n",
            "64 episode , 39 step , -2.21 Actor Loss, 0.61 Critic Loss,  0.05 Threshold , 0.11 Top reward, -2.88 Avg reward\n",
            "[0, 0, 0]\n",
            "65 episode , 40 step , -1.09 Actor Loss, 0.76 Critic Loss,  0.05 Threshold , -0.03 Top reward, -2.72 Avg reward\n",
            "[0, 0, 0]\n",
            "66 episode , 58 step , -1.59 Actor Loss, 0.66 Critic Loss,  0.05 Threshold , 0.10 Top reward, -1.90 Avg reward\n",
            "[0, 0, 0]\n",
            "67 episode , 137 step , -1.64 Actor Loss, 0.67 Critic Loss,  0.05 Threshold , 0.55 Top reward, -0.72 Avg reward\n",
            "[0, 0, 0]\n",
            "68 episode , 96 step , -1.73 Actor Loss, 0.66 Critic Loss,  0.05 Threshold , 0.46 Top reward, -1.03 Avg reward\n",
            "[0, 0, 0]\n",
            "69 episode , 63 step , -1.46 Actor Loss, 0.76 Critic Loss,  0.05 Threshold , 0.52 Top reward, -1.60 Avg reward\n",
            "[0, 0, 0]\n",
            "70 episode , 137 step , -0.99 Actor Loss, 0.66 Critic Loss,  0.05 Threshold , 0.41 Top reward, -0.68 Avg reward\n",
            "[0, 0, 0]\n",
            "71 episode , 94 step , -1.10 Actor Loss, 0.63 Critic Loss,  0.05 Threshold , 0.55 Top reward, -1.03 Avg reward\n",
            "[0, 0, 0]\n",
            "72 episode , 122 step , -0.30 Actor Loss, 0.70 Critic Loss,  0.05 Threshold , 0.45 Top reward, -0.75 Avg reward\n",
            "[0, 0, 0]\n",
            "73 episode , 127 step , -0.09 Actor Loss, 0.74 Critic Loss,  0.05 Threshold , 0.03 Top reward, -1.08 Avg reward\n",
            "[0, 0, 0]\n",
            "74 episode , 155 step , 0.73 Actor Loss, 0.75 Critic Loss,  0.05 Threshold , 0.17 Top reward, -0.84 Avg reward\n",
            "[0, 0, 0]\n",
            "75 episode , 116 step , 0.90 Actor Loss, 0.78 Critic Loss,  0.05 Threshold , 0.31 Top reward, -0.84 Avg reward\n",
            "[0, 0, 0]\n",
            "76 episode , 179 step , 1.49 Actor Loss, 0.83 Critic Loss,  0.05 Threshold , 0.41 Top reward, -0.53 Avg reward\n",
            "[0, 0, 0]\n",
            "77 episode , 105 step , 3.11 Actor Loss, 0.91 Critic Loss,  0.05 Threshold , 0.25 Top reward, -0.97 Avg reward\n",
            "[0, 0, 0]\n",
            "78 episode , 86 step , 2.13 Actor Loss, 0.87 Critic Loss,  0.05 Threshold , -0.02 Top reward, -1.46 Avg reward\n",
            "[0, 0, 0]\n",
            "79 episode , 134 step , 2.11 Actor Loss, 0.95 Critic Loss,  0.05 Threshold , 0.49 Top reward, -0.70 Avg reward\n",
            "[0, 0, 0]\n",
            "80 episode , 117 step , 1.85 Actor Loss, 0.97 Critic Loss,  0.05 Threshold , 0.31 Top reward, -0.80 Avg reward\n",
            "[0, 0, 0]\n",
            "81 episode , 58 step , 2.95 Actor Loss, 1.19 Critic Loss,  0.05 Threshold , 0.06 Top reward, -1.99 Avg reward\n",
            "[0, 0, 0]\n",
            "82 episode , 194 step , 1.45 Actor Loss, 1.04 Critic Loss,  0.05 Threshold , 0.46 Top reward, -0.51 Avg reward\n",
            "[0, 0, 0]\n",
            "83 episode , 132 step , 0.57 Actor Loss, 1.02 Critic Loss,  0.05 Threshold , 0.27 Top reward, -0.77 Avg reward\n",
            "[0, 0, 0]\n",
            "84 episode , 125 step , 0.28 Actor Loss, 1.02 Critic Loss,  0.05 Threshold , 0.49 Top reward, -0.80 Avg reward\n",
            "[0, 0, 0]\n",
            "85 episode , 192 step , -1.15 Actor Loss, 1.05 Critic Loss,  0.05 Threshold , 0.27 Top reward, -0.55 Avg reward\n",
            "[0, 0, 0]\n",
            "86 episode , 125 step , -1.99 Actor Loss, 1.04 Critic Loss,  0.05 Threshold , 0.30 Top reward, -0.83 Avg reward\n",
            "[0, 0, 0]\n",
            "87 episode , 263 step , -1.69 Actor Loss, 1.00 Critic Loss,  0.05 Threshold , 0.34 Top reward, -0.44 Avg reward\n",
            "[0, 0, 0]\n",
            "88 episode , 536 step , -0.96 Actor Loss, 0.87 Critic Loss,  0.05 Threshold , 0.26 Top reward, -0.24 Avg reward\n",
            "[0, 0, 0]\n",
            "89 episode , 123 step , -0.58 Actor Loss, 0.82 Critic Loss,  0.05 Threshold , 0.56 Top reward, -0.80 Avg reward\n",
            "[0, 0, 0]\n",
            "90 episode , 127 step , -0.96 Actor Loss, 0.77 Critic Loss,  0.05 Threshold , 0.56 Top reward, -0.77 Avg reward\n",
            "[0, 0, 0]\n",
            "91 episode , 1600 step , -1.68 Actor Loss, 0.73 Critic Loss,  0.05 Threshold , 0.43 Top reward, -0.04 Avg reward\n",
            "[0, 0, 0]\n",
            "92 episode , 1600 step , -8.74 Actor Loss, 0.39 Critic Loss,  0.05 Threshold , 0.39 Top reward, -0.02 Avg reward\n",
            "[0, 0, 0]\n",
            "93 episode , 125 step , -12.77 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 0.05 Top reward, -1.05 Avg reward\n",
            "[0, 0, 0]\n",
            "94 episode , 1600 step , -14.71 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 0.42 Top reward, -0.01 Avg reward\n",
            "[0, 0, 0]\n",
            "95 episode , 76 step , -17.18 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 0.03 Top reward, -1.60 Avg reward\n",
            "[0, 0, 0]\n",
            "96 episode , 79 step , -16.87 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.03 Top reward, -1.57 Avg reward\n",
            "[0, 0, 0]\n",
            "97 episode , 65 step , -16.22 Actor Loss, 0.26 Critic Loss,  0.05 Threshold , 0.03 Top reward, -1.85 Avg reward\n",
            "[0, 0, 0]\n",
            "98 episode , 59 step , -15.54 Actor Loss, 0.32 Critic Loss,  0.05 Threshold , 0.01 Top reward, -1.95 Avg reward\n",
            "[0, 0, 0]\n",
            "99 episode , 52 step , -14.77 Actor Loss, 0.33 Critic Loss,  0.05 Threshold , -0.00 Top reward, -2.15 Avg reward\n",
            "[0, 0, 0]\n",
            "100 episode , 62 step , -14.45 Actor Loss, 0.35 Critic Loss,  0.05 Threshold , 0.01 Top reward, -1.83 Avg reward\n",
            "[0, 0, 0]\n",
            "101 episode , 54 step , -13.95 Actor Loss, 0.37 Critic Loss,  0.05 Threshold , 0.02 Top reward, -2.07 Avg reward\n",
            "[0, 0, 0]\n",
            "102 episode , 61 step , -13.45 Actor Loss, 0.50 Critic Loss,  0.05 Threshold , 0.08 Top reward, -1.84 Avg reward\n",
            "[0, 0, 0]\n",
            "103 episode , 59 step , -13.22 Actor Loss, 0.37 Critic Loss,  0.05 Threshold , 0.14 Top reward, -1.88 Avg reward\n",
            "[0, 0, 0]\n",
            "104 episode , 67 step , -13.14 Actor Loss, 0.42 Critic Loss,  0.05 Threshold , -0.02 Top reward, -1.71 Avg reward\n",
            "[0, 0, 0]\n",
            "105 episode , 66 step , -11.75 Actor Loss, 0.48 Critic Loss,  0.05 Threshold , 0.00 Top reward, -1.70 Avg reward\n",
            "[0, 0, 0]\n",
            "106 episode , 113 step , -11.65 Actor Loss, 0.45 Critic Loss,  0.05 Threshold , 0.12 Top reward, -1.12 Avg reward\n",
            "[0, 0, 0]\n",
            "107 episode , 64 step , -10.58 Actor Loss, 0.54 Critic Loss,  0.05 Threshold , 0.02 Top reward, -1.77 Avg reward\n",
            "[0, 0, 0]\n",
            "108 episode , 77 step , -9.65 Actor Loss, 0.54 Critic Loss,  0.05 Threshold , 0.07 Top reward, -1.54 Avg reward\n",
            "[0, 0, 0]\n",
            "109 episode , 86 step , -8.08 Actor Loss, 0.61 Critic Loss,  0.05 Threshold , 0.13 Top reward, -1.44 Avg reward\n",
            "[0, 0, 0]\n",
            "110 episode , 1600 step , -4.86 Actor Loss, 0.87 Critic Loss,  0.05 Threshold , 0.46 Top reward, -0.01 Avg reward\n",
            "[0, 0, 0]\n",
            "111 episode , 58 step , -2.67 Actor Loss, 1.06 Critic Loss,  0.05 Threshold , -0.11 Top reward, -2.04 Avg reward\n",
            "[0, 0, 0]\n",
            "112 episode , 159 step , -2.09 Actor Loss, 1.00 Critic Loss,  0.05 Threshold , 0.11 Top reward, -0.73 Avg reward\n",
            "[0, 0, 0]\n",
            "113 episode , 55 step , -1.19 Actor Loss, 1.11 Critic Loss,  0.05 Threshold , -0.15 Top reward, -2.14 Avg reward\n",
            "[0, 0, 0]\n",
            "114 episode , 1600 step , -0.75 Actor Loss, 1.11 Critic Loss,  0.05 Threshold , 0.26 Top reward, -0.05 Avg reward\n",
            "[0, 0, 0]\n",
            "115 episode , 1600 step , -6.58 Actor Loss, 0.75 Critic Loss,  0.05 Threshold , 0.19 Top reward, -0.05 Avg reward\n",
            "[0, 0, 0]\n",
            "116 episode , 1600 step , -16.95 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 0.51 Top reward, -0.05 Avg reward\n",
            "[0, 0, 0]\n",
            "117 episode , 1600 step , -17.32 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.49 Top reward, -0.00 Avg reward\n",
            "[0, 0, 0]\n",
            "118 episode , 581 step , -18.09 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.52 Top reward, -0.14 Avg reward\n",
            "[0, 0, 0]\n",
            "119 episode , 854 step , -17.99 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 0.51 Top reward, -0.09 Avg reward\n",
            "[0, 0, 0]\n",
            "120 episode , 401 step , -18.70 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.58 Top reward, -0.29 Avg reward\n",
            "[0, 0, 0]\n",
            "121 episode , 321 step , -17.99 Actor Loss, 0.21 Critic Loss,  0.05 Threshold , 0.51 Top reward, -0.36 Avg reward\n",
            "[0, 0, 0]\n",
            "122 episode , 417 step , -17.21 Actor Loss, 0.31 Critic Loss,  0.05 Threshold , 0.62 Top reward, -0.17 Avg reward\n",
            "[0, 0, 0]\n",
            "123 episode , 123 step , -16.59 Actor Loss, 0.38 Critic Loss,  0.05 Threshold , 0.41 Top reward, -0.84 Avg reward\n",
            "[0, 0, 0]\n",
            "124 episode , 80 step , -16.26 Actor Loss, 0.35 Critic Loss,  0.05 Threshold , 0.35 Top reward, -1.33 Avg reward\n",
            "[0, 0, 0]\n",
            "125 episode , 312 step , -16.11 Actor Loss, 0.42 Critic Loss,  0.05 Threshold , 0.55 Top reward, -0.22 Avg reward\n",
            "[0, 0, 0]\n",
            "126 episode , 477 step , -16.56 Actor Loss, 0.47 Critic Loss,  0.05 Threshold , 0.54 Top reward, -0.20 Avg reward\n",
            "[0, 0, 0]\n",
            "127 episode , 474 step , -17.15 Actor Loss, 0.48 Critic Loss,  0.05 Threshold , 0.55 Top reward, -0.15 Avg reward\n",
            "[0, 0, 0]\n",
            "128 episode , 503 step , -17.07 Actor Loss, 0.53 Critic Loss,  0.05 Threshold , 0.70 Top reward, -0.17 Avg reward\n",
            "[0, 0, 0]\n",
            "129 episode , 227 step , -16.50 Actor Loss, 0.60 Critic Loss,  0.05 Threshold , 0.52 Top reward, -0.51 Avg reward\n",
            "[0, 0, 0]\n",
            "130 episode , 179 step , -15.31 Actor Loss, 0.77 Critic Loss,  0.05 Threshold , 0.52 Top reward, -0.62 Avg reward\n",
            "[0, 0, 0]\n",
            "131 episode , 264 step , -14.55 Actor Loss, 0.77 Critic Loss,  0.05 Threshold , 0.76 Top reward, -0.38 Avg reward\n",
            "[0, 0, 0]\n",
            "132 episode , 88 step , -12.44 Actor Loss, 0.85 Critic Loss,  0.05 Threshold , 0.14 Top reward, -1.47 Avg reward\n",
            "[0, 0, 0]\n",
            "133 episode , 145 step , -11.14 Actor Loss, 1.09 Critic Loss,  0.05 Threshold , 0.43 Top reward, -0.74 Avg reward\n",
            "[0, 0, 0]\n",
            "134 episode , 84 step , -9.84 Actor Loss, 1.05 Critic Loss,  0.05 Threshold , 0.12 Top reward, -1.52 Avg reward\n",
            "[0, 0, 0]\n",
            "135 episode , 84 step , -9.11 Actor Loss, 1.23 Critic Loss,  0.05 Threshold , 0.11 Top reward, -1.46 Avg reward\n",
            "[0, 0, 0]\n",
            "136 episode , 121 step , -8.86 Actor Loss, 1.13 Critic Loss,  0.05 Threshold , 0.08 Top reward, -0.96 Avg reward\n",
            "[0, 0, 0]\n",
            "137 episode , 99 step , -6.90 Actor Loss, 1.38 Critic Loss,  0.05 Threshold , 0.04 Top reward, -1.34 Avg reward\n",
            "[0, 0, 0]\n",
            "138 episode , 81 step , -5.25 Actor Loss, 1.41 Critic Loss,  0.05 Threshold , 0.17 Top reward, -1.56 Avg reward\n",
            "[0, 0, 0]\n",
            "139 episode , 96 step , -3.64 Actor Loss, 1.57 Critic Loss,  0.05 Threshold , 0.14 Top reward, -1.38 Avg reward\n",
            "[0, 0, 0]\n",
            "140 episode , 64 step , -1.14 Actor Loss, 1.52 Critic Loss,  0.05 Threshold , 0.04 Top reward, -1.88 Avg reward\n",
            "[0, 0, 0]\n",
            "141 episode , 80 step , 1.16 Actor Loss, 1.93 Critic Loss,  0.05 Threshold , 0.02 Top reward, -1.53 Avg reward\n",
            "[0, 0, 0]\n",
            "142 episode , 81 step , 2.65 Actor Loss, 1.98 Critic Loss,  0.05 Threshold , 0.03 Top reward, -1.51 Avg reward\n",
            "[0, 0, 0]\n",
            "143 episode , 98 step , 4.95 Actor Loss, 2.06 Critic Loss,  0.05 Threshold , 0.02 Top reward, -1.29 Avg reward\n",
            "[0, 0, 0]\n",
            "144 episode , 69 step , 6.35 Actor Loss, 2.22 Critic Loss,  0.05 Threshold , 0.21 Top reward, -1.74 Avg reward\n",
            "[0, 0, 0]\n",
            "145 episode , 57 step , 9.44 Actor Loss, 2.78 Critic Loss,  0.05 Threshold , 0.11 Top reward, -2.05 Avg reward\n",
            "[0, 0, 0]\n",
            "146 episode , 117 step , 10.73 Actor Loss, 2.45 Critic Loss,  0.05 Threshold , 0.28 Top reward, -1.10 Avg reward\n",
            "[0, 0, 0]\n",
            "147 episode , 111 step , 14.14 Actor Loss, 2.36 Critic Loss,  0.05 Threshold , 0.34 Top reward, -1.16 Avg reward\n",
            "[0, 0, 0]\n",
            "148 episode , 98 step , 16.72 Actor Loss, 2.89 Critic Loss,  0.05 Threshold , 0.21 Top reward, -1.12 Avg reward\n",
            "[0, 0, 0]\n",
            "149 episode , 111 step , 17.74 Actor Loss, 3.20 Critic Loss,  0.05 Threshold , 0.31 Top reward, -1.08 Avg reward\n",
            "[0, 0, 0]\n",
            "150 episode , 82 step , 18.60 Actor Loss, 3.00 Critic Loss,  0.05 Threshold , 0.03 Top reward, -1.36 Avg reward\n",
            "[0, 0, 0]\n",
            "151 episode , 79 step , 20.63 Actor Loss, 2.86 Critic Loss,  0.05 Threshold , 0.01 Top reward, -1.61 Avg reward\n",
            "[0, 0, 0]\n",
            "152 episode , 80 step , 23.69 Actor Loss, 3.41 Critic Loss,  0.05 Threshold , 0.05 Top reward, -1.57 Avg reward\n",
            "[0, 0, 0]\n",
            "153 episode , 111 step , 24.59 Actor Loss, 3.44 Critic Loss,  0.05 Threshold , 0.21 Top reward, -0.97 Avg reward\n",
            "[0, 0, 0]\n",
            "154 episode , 132 step , 25.97 Actor Loss, 3.52 Critic Loss,  0.05 Threshold , 0.02 Top reward, -0.98 Avg reward\n",
            "[0, 0, 0]\n",
            "155 episode , 120 step , 31.49 Actor Loss, 4.05 Critic Loss,  0.05 Threshold , 0.04 Top reward, -1.11 Avg reward\n",
            "[0, 0, 0]\n",
            "156 episode , 76 step , 34.32 Actor Loss, 4.30 Critic Loss,  0.05 Threshold , -0.00 Top reward, -1.53 Avg reward\n",
            "[0, 0, 0]\n",
            "157 episode , 106 step , 35.88 Actor Loss, 4.38 Critic Loss,  0.05 Threshold , 0.31 Top reward, -1.09 Avg reward\n",
            "[0, 0, 0]\n",
            "158 episode , 240 step , 36.83 Actor Loss, 4.20 Critic Loss,  0.05 Threshold , 0.39 Top reward, -0.42 Avg reward\n",
            "[0, 0, 0]\n",
            "159 episode , 188 step , 38.73 Actor Loss, 4.26 Critic Loss,  0.05 Threshold , 0.68 Top reward, -0.49 Avg reward\n",
            "[0, 0, 0]\n",
            "160 episode , 161 step , 41.18 Actor Loss, 4.35 Critic Loss,  0.05 Threshold , 0.63 Top reward, -0.50 Avg reward\n",
            "[0, 0, 0]\n",
            "161 episode , 117 step , 44.09 Actor Loss, 4.56 Critic Loss,  0.05 Threshold , 0.43 Top reward, -0.81 Avg reward\n",
            "[0, 0, 0]\n",
            "162 episode , 86 step , 47.67 Actor Loss, 4.76 Critic Loss,  0.05 Threshold , -0.00 Top reward, -1.41 Avg reward\n",
            "[0, 0, 0]\n",
            "163 episode , 110 step , 47.61 Actor Loss, 5.16 Critic Loss,  0.05 Threshold , 0.33 Top reward, -0.90 Avg reward\n",
            "[0, 0, 0]\n",
            "164 episode , 116 step , 49.22 Actor Loss, 4.92 Critic Loss,  0.05 Threshold , 0.30 Top reward, -0.88 Avg reward\n",
            "[0, 0, 0]\n",
            "165 episode , 81 step , 53.58 Actor Loss, 5.23 Critic Loss,  0.05 Threshold , 0.00 Top reward, -1.47 Avg reward\n",
            "[0, 0, 0]\n",
            "166 episode , 64 step , 51.92 Actor Loss, 5.31 Critic Loss,  0.05 Threshold , -0.00 Top reward, -1.85 Avg reward\n",
            "[0, 0, 0]\n",
            "167 episode , 60 step , 54.46 Actor Loss, 5.85 Critic Loss,  0.05 Threshold , 0.03 Top reward, -1.94 Avg reward\n",
            "[0, 0, 0]\n",
            "168 episode , 124 step , 58.71 Actor Loss, 5.78 Critic Loss,  0.05 Threshold , 0.42 Top reward, -0.79 Avg reward\n",
            "[0, 0, 0]\n",
            "169 episode , 72 step , 53.48 Actor Loss, 5.97 Critic Loss,  0.05 Threshold , -0.02 Top reward, -1.63 Avg reward\n",
            "[0, 0, 0]\n",
            "170 episode , 157 step , 57.46 Actor Loss, 6.09 Critic Loss,  0.05 Threshold , -0.01 Top reward, -0.87 Avg reward\n",
            "[0, 0, 0]\n",
            "171 episode , 90 step , 58.02 Actor Loss, 6.33 Critic Loss,  0.05 Threshold , 0.44 Top reward, -1.14 Avg reward\n",
            "[0, 0, 0]\n",
            "172 episode , 75 step , 58.23 Actor Loss, 6.01 Critic Loss,  0.05 Threshold , 0.56 Top reward, -1.41 Avg reward\n",
            "[0, 0, 0]\n",
            "173 episode , 95 step , 60.48 Actor Loss, 6.39 Critic Loss,  0.05 Threshold , -0.00 Top reward, -1.33 Avg reward\n",
            "[0, 0, 0]\n",
            "174 episode , 122 step , 60.72 Actor Loss, 5.88 Critic Loss,  0.05 Threshold , 0.57 Top reward, -0.78 Avg reward\n",
            "[0, 0, 0]\n",
            "175 episode , 136 step , 59.23 Actor Loss, 5.85 Critic Loss,  0.05 Threshold , 0.35 Top reward, -0.79 Avg reward\n",
            "[0, 0, 0]\n",
            "176 episode , 123 step , 58.60 Actor Loss, 5.90 Critic Loss,  0.05 Threshold , 0.40 Top reward, -0.82 Avg reward\n",
            "[0, 0, 0]\n",
            "177 episode , 129 step , 61.44 Actor Loss, 6.27 Critic Loss,  0.05 Threshold , 0.34 Top reward, -0.81 Avg reward\n",
            "[0, 0, 0]\n",
            "178 episode , 144 step , 62.02 Actor Loss, 6.03 Critic Loss,  0.05 Threshold , 0.74 Top reward, -0.71 Avg reward\n",
            "[0, 0, 0]\n",
            "179 episode , 112 step , 59.13 Actor Loss, 6.53 Critic Loss,  0.05 Threshold , 0.47 Top reward, -0.92 Avg reward\n",
            "[0, 0, 0]\n",
            "180 episode , 85 step , 58.12 Actor Loss, 5.90 Critic Loss,  0.05 Threshold , 0.47 Top reward, -1.20 Avg reward\n",
            "[0, 0, 0]\n",
            "181 episode , 97 step , 59.08 Actor Loss, 6.64 Critic Loss,  0.05 Threshold , 0.54 Top reward, -1.03 Avg reward\n",
            "[0, 0, 0]\n",
            "182 episode , 102 step , 57.51 Actor Loss, 5.73 Critic Loss,  0.05 Threshold , 0.53 Top reward, -0.96 Avg reward\n",
            "[0, 0, 0]\n",
            "183 episode , 86 step , 56.92 Actor Loss, 6.08 Critic Loss,  0.05 Threshold , 0.56 Top reward, -1.17 Avg reward\n",
            "[0, 0, 0]\n",
            "184 episode , 115 step , 55.11 Actor Loss, 5.45 Critic Loss,  0.05 Threshold , 0.45 Top reward, -0.86 Avg reward\n",
            "[0, 0, 0]\n",
            "185 episode , 226 step , 52.58 Actor Loss, 6.07 Critic Loss,  0.05 Threshold , 0.65 Top reward, -0.39 Avg reward\n",
            "[0, 0, 0]\n",
            "186 episode , 1010 step , 36.88 Actor Loss, 5.12 Critic Loss,  0.05 Threshold , 0.41 Top reward, -0.13 Avg reward\n",
            "[0, 0, 0]\n",
            "187 episode , 1600 step , 13.21 Actor Loss, 4.34 Critic Loss,  0.05 Threshold , 0.54 Top reward, 0.01 Avg reward\n",
            "[0, 0, 0]\n",
            "188 episode , 1600 step , -9.66 Actor Loss, 2.40 Critic Loss,  0.05 Threshold , 0.50 Top reward, 0.02 Avg reward\n",
            "[0, 0, 0]\n",
            "189 episode , 451 step , -23.58 Actor Loss, 1.28 Critic Loss,  0.05 Threshold , 0.29 Top reward, -0.27 Avg reward\n",
            "[0, 0, 0]\n",
            "190 episode , 460 step , -27.48 Actor Loss, 0.99 Critic Loss,  0.05 Threshold , 0.48 Top reward, -0.24 Avg reward\n",
            "[0, 0, 0]\n",
            "191 episode , 124 step , -25.99 Actor Loss, 1.02 Critic Loss,  0.05 Threshold , 0.15 Top reward, -0.85 Avg reward\n",
            "[0, 0, 0]\n",
            "192 episode , 132 step , -23.47 Actor Loss, 1.16 Critic Loss,  0.05 Threshold , 0.09 Top reward, -1.01 Avg reward\n",
            "[0, 0, 0]\n",
            "193 episode , 93 step , -19.26 Actor Loss, 1.54 Critic Loss,  0.05 Threshold , -0.00 Top reward, -1.43 Avg reward\n",
            "[0, 0, 0]\n",
            "194 episode , 175 step , -14.03 Actor Loss, 1.66 Critic Loss,  0.05 Threshold , 0.27 Top reward, -0.79 Avg reward\n",
            "[0, 0, 0]\n",
            "195 episode , 167 step , -9.34 Actor Loss, 2.25 Critic Loss,  0.05 Threshold , 0.11 Top reward, -0.81 Avg reward\n",
            "[0, 0, 0]\n",
            "196 episode , 1075 step , -5.81 Actor Loss, 1.98 Critic Loss,  0.05 Threshold , 0.30 Top reward, -0.17 Avg reward\n",
            "[0, 0, 0]\n",
            "197 episode , 178 step , -1.33 Actor Loss, 2.30 Critic Loss,  0.05 Threshold , 0.19 Top reward, -0.74 Avg reward\n",
            "[0, 0, 0]\n",
            "198 episode , 170 step , 2.16 Actor Loss, 2.30 Critic Loss,  0.05 Threshold , 0.26 Top reward, -0.60 Avg reward\n",
            "[0, 0, 0]\n",
            "199 episode , 308 step , 4.46 Actor Loss, 2.28 Critic Loss,  0.05 Threshold , 0.16 Top reward, -0.46 Avg reward\n",
            "[0, 0, 0]\n",
            "200 episode , 324 step , 5.75 Actor Loss, 2.43 Critic Loss,  0.05 Threshold , 0.17 Top reward, -0.41 Avg reward\n",
            "[0, 0, 0]\n",
            "201 episode , 301 step , 7.89 Actor Loss, 2.57 Critic Loss,  0.05 Threshold , 0.33 Top reward, -0.42 Avg reward\n",
            "[0, 0, 0]\n",
            "202 episode , 80 step , 11.65 Actor Loss, 3.24 Critic Loss,  0.05 Threshold , 0.32 Top reward, -1.21 Avg reward\n",
            "[0, 0, 0]\n",
            "203 episode , 52 step , 10.07 Actor Loss, 2.72 Critic Loss,  0.05 Threshold , 0.11 Top reward, -2.02 Avg reward\n",
            "[0, 0, 0]\n",
            "204 episode , 79 step , 13.80 Actor Loss, 3.20 Critic Loss,  0.05 Threshold , 0.24 Top reward, -1.40 Avg reward\n",
            "[0, 0, 0]\n",
            "205 episode , 50 step , 15.95 Actor Loss, 3.07 Critic Loss,  0.05 Threshold , 0.01 Top reward, -2.19 Avg reward\n",
            "[0, 0, 0]\n",
            "206 episode , 156 step , 19.53 Actor Loss, 3.59 Critic Loss,  0.05 Threshold , 0.20 Top reward, -0.77 Avg reward\n",
            "[0, 0, 0]\n",
            "207 episode , 69 step , 21.47 Actor Loss, 3.30 Critic Loss,  0.05 Threshold , -0.00 Top reward, -1.60 Avg reward\n",
            "[0, 0, 0]\n",
            "208 episode , 93 step , 23.48 Actor Loss, 3.23 Critic Loss,  0.05 Threshold , 0.02 Top reward, -1.18 Avg reward\n",
            "[0, 0, 0]\n",
            "209 episode , 56 step , 27.07 Actor Loss, 4.01 Critic Loss,  0.05 Threshold , -0.13 Top reward, -2.11 Avg reward\n",
            "[0, 0, 0]\n",
            "210 episode , 98 step , 30.26 Actor Loss, 3.91 Critic Loss,  0.05 Threshold , 0.10 Top reward, -1.15 Avg reward\n",
            "[0, 0, 0]\n",
            "211 episode , 146 step , 35.25 Actor Loss, 4.47 Critic Loss,  0.05 Threshold , 0.20 Top reward, -0.81 Avg reward\n",
            "[0, 0, 0]\n",
            "212 episode , 103 step , 39.23 Actor Loss, 4.06 Critic Loss,  0.05 Threshold , 0.36 Top reward, -1.13 Avg reward\n",
            "[0, 0, 0]\n",
            "213 episode , 109 step , 39.77 Actor Loss, 4.60 Critic Loss,  0.05 Threshold , 0.40 Top reward, -0.94 Avg reward\n",
            "[0, 0, 0]\n",
            "214 episode , 116 step , 44.60 Actor Loss, 4.57 Critic Loss,  0.05 Threshold , 0.16 Top reward, -0.90 Avg reward\n",
            "[0, 0, 0]\n",
            "215 episode , 98 step , 47.78 Actor Loss, 4.93 Critic Loss,  0.05 Threshold , 0.25 Top reward, -1.09 Avg reward\n",
            "[0, 0, 0]\n",
            "216 episode , 80 step , 50.72 Actor Loss, 5.19 Critic Loss,  0.05 Threshold , 0.13 Top reward, -1.34 Avg reward\n",
            "[0, 0, 0]\n",
            "217 episode , 163 step , 52.44 Actor Loss, 4.96 Critic Loss,  0.05 Threshold , 0.27 Top reward, -0.63 Avg reward\n",
            "[0, 0, 0]\n",
            "218 episode , 187 step , 50.66 Actor Loss, 5.06 Critic Loss,  0.05 Threshold , 0.86 Top reward, -0.43 Avg reward\n",
            "[0, 0, 0]\n",
            "219 episode , 146 step , 58.25 Actor Loss, 5.95 Critic Loss,  0.05 Threshold , 0.19 Top reward, -0.74 Avg reward\n",
            "[0, 0, 0]\n",
            "220 episode , 104 step , 60.82 Actor Loss, 5.37 Critic Loss,  0.05 Threshold , 0.03 Top reward, -1.19 Avg reward\n",
            "[0, 0, 0]\n",
            "221 episode , 103 step , 61.67 Actor Loss, 6.16 Critic Loss,  0.05 Threshold , -0.01 Top reward, -1.19 Avg reward\n",
            "[0, 0, 0]\n",
            "222 episode , 165 step , 65.02 Actor Loss, 7.25 Critic Loss,  0.05 Threshold , 0.46 Top reward, -0.60 Avg reward\n",
            "[0, 0, 0]\n",
            "223 episode , 47 step , 60.89 Actor Loss, 7.17 Critic Loss,  0.05 Threshold , -0.01 Top reward, -2.29 Avg reward\n",
            "[0, 0, 0]\n",
            "224 episode , 84 step , 62.88 Actor Loss, 6.42 Critic Loss,  0.05 Threshold , 0.01 Top reward, -1.40 Avg reward\n",
            "[0, 0, 0]\n",
            "225 episode , 64 step , 65.21 Actor Loss, 7.19 Critic Loss,  0.05 Threshold , 0.10 Top reward, -1.79 Avg reward\n",
            "[0, 0, 0]\n",
            "226 episode , 378 step , 63.96 Actor Loss, 6.89 Critic Loss,  0.05 Threshold , 0.38 Top reward, -0.38 Avg reward\n",
            "[0, 0, 0]\n",
            "227 episode , 111 step , 67.81 Actor Loss, 7.18 Critic Loss,  0.05 Threshold , 0.10 Top reward, -1.13 Avg reward\n",
            "[0, 0, 0]\n",
            "228 episode , 77 step , 71.47 Actor Loss, 7.61 Critic Loss,  0.05 Threshold , -0.03 Top reward, -1.63 Avg reward\n",
            "[0, 0, 0]\n",
            "229 episode , 140 step , 77.98 Actor Loss, 8.16 Critic Loss,  0.05 Threshold , 0.17 Top reward, -0.92 Avg reward\n",
            "[0, 0, 0]\n",
            "230 episode , 209 step , 83.25 Actor Loss, 8.47 Critic Loss,  0.05 Threshold , 0.17 Top reward, -0.65 Avg reward\n",
            "[0, 0, 0]\n",
            "231 episode , 87 step , 90.10 Actor Loss, 10.24 Critic Loss,  0.05 Threshold , 0.01 Top reward, -1.46 Avg reward\n",
            "[0, 0, 0]\n",
            "232 episode , 186 step , 94.56 Actor Loss, 9.11 Critic Loss,  0.05 Threshold , 0.25 Top reward, -0.59 Avg reward\n",
            "[0, 0, 0]\n",
            "233 episode , 71 step , 99.71 Actor Loss, 10.01 Critic Loss,  0.05 Threshold , 0.04 Top reward, -1.72 Avg reward\n",
            "[0, 0, 0]\n",
            "234 episode , 100 step , 99.62 Actor Loss, 10.31 Critic Loss,  0.05 Threshold , -0.00 Top reward, -1.29 Avg reward\n",
            "[0, 0, 0]\n",
            "235 episode , 65 step , 101.75 Actor Loss, 9.63 Critic Loss,  0.05 Threshold , -0.01 Top reward, -1.86 Avg reward\n",
            "[0, 0, 0]\n",
            "236 episode , 83 step , 102.75 Actor Loss, 9.84 Critic Loss,  0.05 Threshold , 0.01 Top reward, -1.54 Avg reward\n",
            "[0, 0, 0]\n",
            "237 episode , 101 step , 113.32 Actor Loss, 11.33 Critic Loss,  0.05 Threshold , 0.03 Top reward, -1.26 Avg reward\n",
            "[0, 0, 0]\n",
            "238 episode , 190 step , 113.40 Actor Loss, 11.10 Critic Loss,  0.05 Threshold , 0.07 Top reward, -0.71 Avg reward\n",
            "[0, 0, 0]\n",
            "239 episode , 117 step , 118.08 Actor Loss, 11.38 Critic Loss,  0.05 Threshold , 0.50 Top reward, -0.82 Avg reward\n",
            "[0, 0, 0]\n",
            "240 episode , 83 step , 117.52 Actor Loss, 11.97 Critic Loss,  0.05 Threshold , 0.53 Top reward, -1.20 Avg reward\n",
            "[0, 0, 0]\n",
            "241 episode , 124 step , 125.29 Actor Loss, 12.97 Critic Loss,  0.05 Threshold , 0.48 Top reward, -0.82 Avg reward\n",
            "[0, 0, 0]\n",
            "242 episode , 119 step , 123.50 Actor Loss, 13.49 Critic Loss,  0.05 Threshold , 0.49 Top reward, -0.87 Avg reward\n",
            "[0, 0, 0]\n",
            "243 episode , 107 step , 122.51 Actor Loss, 13.62 Critic Loss,  0.05 Threshold , 0.41 Top reward, -0.97 Avg reward\n",
            "[0, 0, 0]\n",
            "244 episode , 181 step , 122.16 Actor Loss, 12.96 Critic Loss,  0.05 Threshold , 0.50 Top reward, -0.50 Avg reward\n",
            "[0, 0, 0]\n",
            "245 episode , 239 step , 121.59 Actor Loss, 13.33 Critic Loss,  0.05 Threshold , 0.91 Top reward, -0.40 Avg reward\n",
            "[0, 0, 0]\n",
            "246 episode , 108 step , 116.48 Actor Loss, 13.68 Critic Loss,  0.05 Threshold , 0.56 Top reward, -0.85 Avg reward\n",
            "[0, 0, 0]\n",
            "247 episode , 69 step , 116.64 Actor Loss, 13.74 Critic Loss,  0.05 Threshold , 0.23 Top reward, -1.48 Avg reward\n",
            "[0, 0, 0]\n",
            "248 episode , 149 step , 118.49 Actor Loss, 14.42 Critic Loss,  0.05 Threshold , 0.37 Top reward, -0.59 Avg reward\n",
            "[0, 0, 0]\n",
            "249 episode , 173 step , 110.39 Actor Loss, 13.80 Critic Loss,  0.05 Threshold , 0.38 Top reward, -0.47 Avg reward\n",
            "[0, 0, 0]\n",
            "250 episode , 210 step , 108.82 Actor Loss, 13.89 Critic Loss,  0.05 Threshold , 0.43 Top reward, -0.53 Avg reward\n",
            "[0, 0, 0]\n",
            "251 episode , 121 step , 105.12 Actor Loss, 13.11 Critic Loss,  0.05 Threshold , 0.41 Top reward, -0.71 Avg reward\n",
            "[0, 0, 0]\n",
            "252 episode , 315 step , 96.54 Actor Loss, 12.90 Critic Loss,  0.05 Threshold , 0.31 Top reward, -0.40 Avg reward\n",
            "[0, 0, 0]\n",
            "253 episode , 190 step , 88.03 Actor Loss, 12.59 Critic Loss,  0.05 Threshold , 0.10 Top reward, -0.76 Avg reward\n",
            "[0, 0, 0]\n",
            "254 episode , 67 step , 88.32 Actor Loss, 12.87 Critic Loss,  0.05 Threshold , -0.01 Top reward, -1.82 Avg reward\n",
            "[0, 0, 0]\n",
            "255 episode , 65 step , 93.53 Actor Loss, 12.70 Critic Loss,  0.05 Threshold , 0.03 Top reward, -1.87 Avg reward\n",
            "[0, 0, 0]\n",
            "256 episode , 69 step , 94.61 Actor Loss, 12.71 Critic Loss,  0.05 Threshold , 0.02 Top reward, -1.78 Avg reward\n",
            "[0, 0, 0]\n",
            "257 episode , 66 step , 95.45 Actor Loss, 13.09 Critic Loss,  0.05 Threshold , -0.02 Top reward, -1.85 Avg reward\n",
            "[0, 0, 0]\n",
            "258 episode , 870 step , 83.20 Actor Loss, 11.32 Critic Loss,  0.05 Threshold , 0.37 Top reward, -0.18 Avg reward\n",
            "[0, 0, 0]\n",
            "259 episode , 600 step , 68.42 Actor Loss, 9.65 Critic Loss,  0.05 Threshold , 0.76 Top reward, -0.22 Avg reward\n",
            "[0, 0, 0]\n",
            "260 episode , 142 step , 64.41 Actor Loss, 9.12 Critic Loss,  0.05 Threshold , 0.13 Top reward, -0.94 Avg reward\n",
            "[0, 0, 0]\n",
            "261 episode , 269 step , 56.30 Actor Loss, 9.12 Critic Loss,  0.05 Threshold , 0.18 Top reward, -0.48 Avg reward\n",
            "[0, 0, 0]\n",
            "262 episode , 109 step , 54.61 Actor Loss, 7.92 Critic Loss,  0.05 Threshold , 0.06 Top reward, -1.06 Avg reward\n",
            "[0, 0, 0]\n",
            "263 episode , 354 step , 46.52 Actor Loss, 7.73 Critic Loss,  0.05 Threshold , 0.28 Top reward, -0.44 Avg reward\n",
            "[0, 0, 0]\n",
            "264 episode , 417 step , 42.35 Actor Loss, 7.50 Critic Loss,  0.05 Threshold , 0.37 Top reward, -0.34 Avg reward\n",
            "[0, 0, 0]\n",
            "265 episode , 93 step , 39.53 Actor Loss, 8.03 Critic Loss,  0.05 Threshold , 0.11 Top reward, -1.17 Avg reward\n",
            "[0, 0, 0]\n",
            "266 episode , 156 step , 37.17 Actor Loss, 7.17 Critic Loss,  0.05 Threshold , 0.19 Top reward, -0.81 Avg reward\n",
            "[0, 0, 0]\n",
            "267 episode , 234 step , 36.69 Actor Loss, 7.09 Critic Loss,  0.05 Threshold , 0.16 Top reward, -0.60 Avg reward\n",
            "[0, 0, 0]\n",
            "268 episode , 97 step , 43.06 Actor Loss, 7.46 Critic Loss,  0.05 Threshold , 0.08 Top reward, -1.14 Avg reward\n",
            "[0, 0, 0]\n",
            "269 episode , 256 step , 39.02 Actor Loss, 7.18 Critic Loss,  0.05 Threshold , 0.07 Top reward, -0.56 Avg reward\n",
            "[0, 0, 0]\n",
            "270 episode , 125 step , 35.52 Actor Loss, 6.77 Critic Loss,  0.05 Threshold , 0.16 Top reward, -0.96 Avg reward\n",
            "[0, 0, 0]\n",
            "271 episode , 52 step , 33.59 Actor Loss, 5.76 Critic Loss,  0.05 Threshold , 0.02 Top reward, -2.11 Avg reward\n",
            "[0, 0, 0]\n",
            "272 episode , 54 step , 39.67 Actor Loss, 7.36 Critic Loss,  0.05 Threshold , 0.02 Top reward, -2.05 Avg reward\n",
            "[0, 0, 0]\n",
            "273 episode , 288 step , 38.96 Actor Loss, 7.00 Critic Loss,  0.05 Threshold , 0.11 Top reward, -0.50 Avg reward\n",
            "[0, 0, 0]\n",
            "274 episode , 56 step , 34.56 Actor Loss, 6.89 Critic Loss,  0.05 Threshold , -0.00 Top reward, -2.00 Avg reward\n",
            "[0, 0, 0]\n",
            "275 episode , 253 step , 35.78 Actor Loss, 6.14 Critic Loss,  0.05 Threshold , 0.22 Top reward, -0.52 Avg reward\n",
            "[0, 0, 0]\n",
            "276 episode , 54 step , 40.41 Actor Loss, 7.23 Critic Loss,  0.05 Threshold , -0.00 Top reward, -2.02 Avg reward\n",
            "[0, 0, 0]\n",
            "277 episode , 47 step , 41.18 Actor Loss, 7.04 Critic Loss,  0.05 Threshold , -0.03 Top reward, -2.26 Avg reward\n",
            "[0, 0, 0]\n",
            "278 episode , 57 step , 39.32 Actor Loss, 7.09 Critic Loss,  0.05 Threshold , 0.02 Top reward, -1.90 Avg reward\n",
            "[0, 0, 0]\n",
            "279 episode , 68 step , 44.10 Actor Loss, 7.81 Critic Loss,  0.05 Threshold , 0.04 Top reward, -1.67 Avg reward\n",
            "[0, 0, 0]\n",
            "280 episode , 52 step , 44.87 Actor Loss, 6.33 Critic Loss,  0.05 Threshold , -0.01 Top reward, -2.06 Avg reward\n",
            "[0, 0, 0]\n",
            "281 episode , 163 step , 44.47 Actor Loss, 7.00 Critic Loss,  0.05 Threshold , 0.13 Top reward, -0.82 Avg reward\n",
            "[0, 0, 0]\n",
            "282 episode , 385 step , 38.86 Actor Loss, 6.79 Critic Loss,  0.05 Threshold , 0.17 Top reward, -0.41 Avg reward\n",
            "[0, 0, 0]\n",
            "283 episode , 83 step , 39.92 Actor Loss, 7.30 Critic Loss,  0.05 Threshold , 0.04 Top reward, -1.41 Avg reward\n",
            "[0, 0, 0]\n",
            "284 episode , 128 step , 44.22 Actor Loss, 7.58 Critic Loss,  0.05 Threshold , 0.04 Top reward, -0.94 Avg reward\n",
            "[0, 0, 0]\n",
            "285 episode , 230 step , 43.85 Actor Loss, 7.76 Critic Loss,  0.05 Threshold , 0.17 Top reward, -0.60 Avg reward\n",
            "[0, 0, 0]\n",
            "286 episode , 104 step , 47.44 Actor Loss, 8.12 Critic Loss,  0.05 Threshold , 0.13 Top reward, -1.08 Avg reward\n",
            "[0, 0, 0]\n",
            "287 episode , 103 step , 48.73 Actor Loss, 8.99 Critic Loss,  0.05 Threshold , 0.18 Top reward, -1.17 Avg reward\n",
            "[0, 0, 0]\n",
            "288 episode , 219 step , 51.55 Actor Loss, 7.72 Critic Loss,  0.05 Threshold , 0.19 Top reward, -0.65 Avg reward\n",
            "[0, 0, 0]\n",
            "289 episode , 85 step , 50.53 Actor Loss, 8.17 Critic Loss,  0.05 Threshold , 0.02 Top reward, -1.38 Avg reward\n",
            "[0, 0, 0]\n",
            "290 episode , 112 step , 49.92 Actor Loss, 8.13 Critic Loss,  0.05 Threshold , -0.02 Top reward, -1.13 Avg reward\n",
            "[0, 0, 0]\n",
            "291 episode , 122 step , 55.40 Actor Loss, 8.76 Critic Loss,  0.05 Threshold , -0.01 Top reward, -1.04 Avg reward\n",
            "[0, 0, 0]\n",
            "292 episode , 104 step , 57.07 Actor Loss, 9.49 Critic Loss,  0.05 Threshold , 0.03 Top reward, -1.15 Avg reward\n",
            "[0, 0, 0]\n",
            "293 episode , 125 step , 55.49 Actor Loss, 8.67 Critic Loss,  0.05 Threshold , 0.04 Top reward, -0.98 Avg reward\n",
            "[0, 0, 0]\n",
            "294 episode , 166 step , 59.14 Actor Loss, 9.02 Critic Loss,  0.05 Threshold , 0.09 Top reward, -0.84 Avg reward\n",
            "[0, 0, 0]\n",
            "295 episode , 258 step , 60.36 Actor Loss, 9.11 Critic Loss,  0.05 Threshold , 0.22 Top reward, -0.53 Avg reward\n",
            "[0, 0, 0]\n",
            "296 episode , 374 step , 61.60 Actor Loss, 8.98 Critic Loss,  0.05 Threshold , 0.16 Top reward, -0.40 Avg reward\n",
            "[0, 0, 0]\n",
            "297 episode , 532 step , 57.65 Actor Loss, 8.78 Critic Loss,  0.05 Threshold , 0.22 Top reward, -0.31 Avg reward\n",
            "[0, 0, 0]\n",
            "298 episode , 880 step , 46.46 Actor Loss, 7.76 Critic Loss,  0.05 Threshold , 0.40 Top reward, -0.20 Avg reward\n",
            "[0, 0, 0]\n",
            "299 episode , 104 step , 37.84 Actor Loss, 7.24 Critic Loss,  0.05 Threshold , 0.07 Top reward, -1.23 Avg reward\n",
            "[0, 0, 0]\n",
            "300 episode , 67 step , 44.57 Actor Loss, 7.66 Critic Loss,  0.05 Threshold , 0.06 Top reward, -1.73 Avg reward\n",
            "[0, 0, 0]\n",
            "301 episode , 110 step , 47.16 Actor Loss, 7.66 Critic Loss,  0.05 Threshold , 0.37 Top reward, -1.09 Avg reward\n",
            "[0, 0, 0]\n",
            "302 episode , 114 step , 46.46 Actor Loss, 7.51 Critic Loss,  0.05 Threshold , 0.11 Top reward, -1.01 Avg reward\n",
            "[0, 0, 0]\n",
            "303 episode , 92 step , 50.85 Actor Loss, 8.02 Critic Loss,  0.05 Threshold , 0.05 Top reward, -1.25 Avg reward\n",
            "[0, 0, 0]\n",
            "304 episode , 70 step , 53.07 Actor Loss, 8.02 Critic Loss,  0.05 Threshold , 0.04 Top reward, -1.65 Avg reward\n",
            "[0, 0, 0]\n",
            "305 episode , 67 step , 53.55 Actor Loss, 9.05 Critic Loss,  0.05 Threshold , 0.00 Top reward, -1.74 Avg reward\n",
            "[0, 0, 0]\n",
            "306 episode , 61 step , 55.15 Actor Loss, 8.47 Critic Loss,  0.05 Threshold , 0.05 Top reward, -1.88 Avg reward\n",
            "[0, 0, 0]\n",
            "307 episode , 120 step , 50.67 Actor Loss, 8.20 Critic Loss,  0.05 Threshold , 0.34 Top reward, -0.88 Avg reward\n",
            "[0, 0, 0]\n",
            "308 episode , 398 step , 48.90 Actor Loss, 8.28 Critic Loss,  0.05 Threshold , 0.42 Top reward, -0.33 Avg reward\n",
            "[0, 0, 0]\n",
            "309 episode , 159 step , 49.33 Actor Loss, 8.37 Critic Loss,  0.05 Threshold , 0.27 Top reward, -0.73 Avg reward\n",
            "[0, 0, 0]\n",
            "310 episode , 87 step , 51.89 Actor Loss, 8.49 Critic Loss,  0.05 Threshold , 0.03 Top reward, -1.36 Avg reward\n",
            "[0, 0, 0]\n",
            "311 episode , 1600 step , 32.45 Actor Loss, 7.21 Critic Loss,  0.05 Threshold , 0.39 Top reward, -0.08 Avg reward\n",
            "[0, 0, 0]\n",
            "312 episode , 1600 step , 0.86 Actor Loss, 4.04 Critic Loss,  0.05 Threshold , 0.33 Top reward, -0.08 Avg reward\n",
            "[0, 0, 0]\n",
            "313 episode , 1600 step , -21.06 Actor Loss, 2.05 Critic Loss,  0.05 Threshold , 0.28 Top reward, -0.07 Avg reward\n",
            "[0, 0, 0]\n",
            "314 episode , 1600 step , -45.87 Actor Loss, 0.43 Critic Loss,  0.05 Threshold , 0.27 Top reward, -0.08 Avg reward\n",
            "[0, 0, 0]\n",
            "315 episode , 1600 step , -45.41 Actor Loss, 0.31 Critic Loss,  0.05 Threshold , 0.22 Top reward, -0.08 Avg reward\n",
            "[0, 0, 0]\n",
            "316 episode , 916 step , -43.81 Actor Loss, 0.28 Critic Loss,  0.05 Threshold , 0.23 Top reward, -0.21 Avg reward\n",
            "[0, 0, 0]\n",
            "317 episode , 78 step , -42.71 Actor Loss, 0.31 Critic Loss,  0.05 Threshold , 0.25 Top reward, -1.47 Avg reward\n",
            "[0, 0, 0]\n",
            "318 episode , 1600 step , -41.18 Actor Loss, 0.32 Critic Loss,  0.05 Threshold , 0.29 Top reward, -0.05 Avg reward\n",
            "[0, 0, 0]\n",
            "319 episode , 103 step , -39.60 Actor Loss, 0.39 Critic Loss,  0.05 Threshold , 0.01 Top reward, -1.15 Avg reward\n",
            "[0, 0, 0]\n",
            "320 episode , 1600 step , -37.24 Actor Loss, 0.46 Critic Loss,  0.05 Threshold , 0.31 Top reward, -0.06 Avg reward\n",
            "[0, 0, 0]\n",
            "321 episode , 1600 step , -36.50 Actor Loss, 0.31 Critic Loss,  0.05 Threshold , 0.45 Top reward, 0.00 Avg reward\n",
            "[0, 0, 0]\n",
            "322 episode , 1600 step , -37.02 Actor Loss, 0.21 Critic Loss,  0.05 Threshold , 0.30 Top reward, -0.08 Avg reward\n",
            "[0, 0, 0]\n",
            "323 episode , 95 step , -36.85 Actor Loss, 0.24 Critic Loss,  0.05 Threshold , 0.15 Top reward, -1.20 Avg reward\n",
            "[0, 0, 0]\n",
            "324 episode , 97 step , -35.04 Actor Loss, 0.39 Critic Loss,  0.05 Threshold , 0.14 Top reward, -1.23 Avg reward\n",
            "[0, 0, 0]\n",
            "325 episode , 76 step , -32.41 Actor Loss, 0.55 Critic Loss,  0.05 Threshold , 0.03 Top reward, -1.59 Avg reward\n",
            "[0, 0, 0]\n",
            "326 episode , 87 step , -30.44 Actor Loss, 0.58 Critic Loss,  0.05 Threshold , 0.05 Top reward, -1.37 Avg reward\n",
            "[0, 0, 0]\n",
            "327 episode , 63 step , -28.02 Actor Loss, 0.65 Critic Loss,  0.05 Threshold , -0.05 Top reward, -1.91 Avg reward\n",
            "[0, 0, 0]\n",
            "328 episode , 62 step , -25.57 Actor Loss, 0.86 Critic Loss,  0.05 Threshold , -0.01 Top reward, -1.96 Avg reward\n",
            "[0, 0, 0]\n",
            "329 episode , 1231 step , -21.05 Actor Loss, 0.92 Critic Loss,  0.05 Threshold , 0.25 Top reward, -0.16 Avg reward\n",
            "[0, 0, 0]\n",
            "330 episode , 119 step , -16.58 Actor Loss, 0.90 Critic Loss,  0.05 Threshold , 0.10 Top reward, -0.93 Avg reward\n",
            "[0, 0, 0]\n",
            "331 episode , 141 step , -14.57 Actor Loss, 1.15 Critic Loss,  0.05 Threshold , 0.15 Top reward, -0.79 Avg reward\n",
            "[0, 0, 0]\n",
            "332 episode , 46 step , -15.62 Actor Loss, 1.65 Critic Loss,  0.05 Threshold , -0.08 Top reward, -2.43 Avg reward\n",
            "[0, 0, 0]\n",
            "333 episode , 106 step , -12.42 Actor Loss, 1.58 Critic Loss,  0.05 Threshold , 0.08 Top reward, -1.11 Avg reward\n",
            "[0, 0, 0]\n",
            "334 episode , 108 step , -12.30 Actor Loss, 1.40 Critic Loss,  0.05 Threshold , 0.07 Top reward, -1.13 Avg reward\n",
            "[0, 0, 0]\n",
            "335 episode , 55 step , -9.82 Actor Loss, 1.59 Critic Loss,  0.05 Threshold , -0.13 Top reward, -2.06 Avg reward\n",
            "[0, 0, 0]\n",
            "336 episode , 196 step , -8.92 Actor Loss, 1.73 Critic Loss,  0.05 Threshold , 0.10 Top reward, -0.62 Avg reward\n",
            "[0, 0, 0]\n",
            "337 episode , 165 step , -7.42 Actor Loss, 1.78 Critic Loss,  0.05 Threshold , 0.17 Top reward, -0.81 Avg reward\n",
            "[0, 0, 0]\n",
            "338 episode , 60 step , -7.75 Actor Loss, 1.89 Critic Loss,  0.05 Threshold , 0.09 Top reward, -1.98 Avg reward\n",
            "[0, 0, 0]\n",
            "339 episode , 73 step , -3.32 Actor Loss, 2.29 Critic Loss,  0.05 Threshold , 0.20 Top reward, -1.72 Avg reward\n",
            "[0, 0, 0]\n",
            "340 episode , 76 step , -2.45 Actor Loss, 2.45 Critic Loss,  0.05 Threshold , 0.12 Top reward, -1.58 Avg reward\n",
            "[0, 0, 0]\n",
            "341 episode , 104 step , -2.33 Actor Loss, 2.81 Critic Loss,  0.05 Threshold , 0.16 Top reward, -1.17 Avg reward\n",
            "[0, 0, 0]\n",
            "342 episode , 280 step , -1.44 Actor Loss, 2.31 Critic Loss,  0.05 Threshold , 0.19 Top reward, -0.52 Avg reward\n",
            "[0, 0, 0]\n",
            "343 episode , 501 step , -0.67 Actor Loss, 2.31 Critic Loss,  0.05 Threshold , 0.16 Top reward, -0.32 Avg reward\n",
            "[0, 0, 0]\n",
            "344 episode , 176 step , -0.14 Actor Loss, 2.35 Critic Loss,  0.05 Threshold , 0.20 Top reward, -0.77 Avg reward\n",
            "[0, 0, 0]\n",
            "345 episode , 100 step , -0.13 Actor Loss, 2.61 Critic Loss,  0.05 Threshold , 0.01 Top reward, -1.22 Avg reward\n",
            "[0, 0, 0]\n",
            "346 episode , 103 step , -2.36 Actor Loss, 2.16 Critic Loss,  0.05 Threshold , 0.03 Top reward, -1.22 Avg reward\n",
            "[0, 0, 0]\n",
            "347 episode , 225 step , 0.47 Actor Loss, 2.37 Critic Loss,  0.05 Threshold , 0.21 Top reward, -0.62 Avg reward\n",
            "[0, 0, 0]\n",
            "348 episode , 102 step , 1.20 Actor Loss, 2.30 Critic Loss,  0.05 Threshold , 0.08 Top reward, -1.22 Avg reward\n",
            "[0, 0, 0]\n",
            "349 episode , 71 step , 1.14 Actor Loss, 2.45 Critic Loss,  0.05 Threshold , 0.15 Top reward, -1.59 Avg reward\n",
            "[0, 0, 0]\n",
            "350 episode , 67 step , 1.50 Actor Loss, 2.60 Critic Loss,  0.05 Threshold , 0.13 Top reward, -1.65 Avg reward\n",
            "[0, 0, 0]\n",
            "351 episode , 64 step , 3.33 Actor Loss, 2.81 Critic Loss,  0.05 Threshold , 0.18 Top reward, -1.70 Avg reward\n",
            "[0, 0, 0]\n",
            "352 episode , 131 step , 4.10 Actor Loss, 2.51 Critic Loss,  0.05 Threshold , 0.35 Top reward, -0.85 Avg reward\n",
            "[0, 0, 0]\n",
            "353 episode , 69 step , 3.54 Actor Loss, 2.60 Critic Loss,  0.05 Threshold , 0.25 Top reward, -1.60 Avg reward\n",
            "[0, 0, 0]\n",
            "354 episode , 52 step , 6.59 Actor Loss, 3.10 Critic Loss,  0.05 Threshold , 0.19 Top reward, -2.09 Avg reward\n",
            "[0, 0, 0]\n",
            "355 episode , 48 step , 6.71 Actor Loss, 2.79 Critic Loss,  0.05 Threshold , 0.22 Top reward, -2.28 Avg reward\n",
            "[0, 0, 0]\n",
            "356 episode , 69 step , 5.79 Actor Loss, 3.06 Critic Loss,  0.05 Threshold , 0.31 Top reward, -1.60 Avg reward\n",
            "[0, 0, 0]\n",
            "357 episode , 50 step , 7.01 Actor Loss, 3.40 Critic Loss,  0.05 Threshold , 0.23 Top reward, -2.18 Avg reward\n",
            "[0, 0, 0]\n",
            "358 episode , 77 step , 8.02 Actor Loss, 3.16 Critic Loss,  0.05 Threshold , 0.25 Top reward, -1.38 Avg reward\n",
            "[0, 0, 0]\n",
            "359 episode , 226 step , 4.23 Actor Loss, 3.11 Critic Loss,  0.05 Threshold , 0.09 Top reward, -0.61 Avg reward\n",
            "[0, 0, 0]\n",
            "360 episode , 56 step , 1.66 Actor Loss, 3.07 Critic Loss,  0.05 Threshold , 0.18 Top reward, -1.87 Avg reward\n",
            "[0, 0, 0]\n",
            "361 episode , 55 step , -0.36 Actor Loss, 3.00 Critic Loss,  0.05 Threshold , 0.18 Top reward, -1.92 Avg reward\n",
            "[0, 0, 0]\n",
            "362 episode , 74 step , -0.09 Actor Loss, 2.99 Critic Loss,  0.05 Threshold , 0.29 Top reward, -1.41 Avg reward\n",
            "[0, 0, 0]\n",
            "363 episode , 48 step , -0.82 Actor Loss, 3.43 Critic Loss,  0.05 Threshold , 0.05 Top reward, -2.38 Avg reward\n",
            "[0, 0, 0]\n",
            "364 episode , 1100 step , -0.52 Actor Loss, 2.95 Critic Loss,  0.05 Threshold , 0.32 Top reward, -0.20 Avg reward\n",
            "[0, 0, 0]\n",
            "365 episode , 1600 step , -9.35 Actor Loss, 1.74 Critic Loss,  0.05 Threshold , 0.15 Top reward, -0.09 Avg reward\n",
            "[0, 0, 0]\n",
            "366 episode , 415 step , -12.92 Actor Loss, 1.18 Critic Loss,  0.05 Threshold , 0.15 Top reward, -0.37 Avg reward\n",
            "[0, 0, 0]\n",
            "367 episode , 1600 step , -15.85 Actor Loss, 0.76 Critic Loss,  0.05 Threshold , 0.18 Top reward, -0.10 Avg reward\n",
            "[0, 0, 0]\n",
            "368 episode , 44 step , -19.45 Actor Loss, 0.50 Critic Loss,  0.05 Threshold , -0.07 Top reward, -2.49 Avg reward\n",
            "[0, 0, 0]\n",
            "369 episode , 263 step , -19.79 Actor Loss, 0.31 Critic Loss,  0.05 Threshold , -0.01 Top reward, -0.53 Avg reward\n",
            "[0, 0, 0]\n",
            "370 episode , 41 step , -20.72 Actor Loss, 0.26 Critic Loss,  0.05 Threshold , -0.11 Top reward, -2.69 Avg reward\n",
            "[0, 0, 0]\n",
            "371 episode , 46 step , -19.82 Actor Loss, 0.27 Critic Loss,  0.05 Threshold , 0.02 Top reward, -2.39 Avg reward\n",
            "[0, 0, 0]\n",
            "372 episode , 51 step , -18.71 Actor Loss, 0.33 Critic Loss,  0.05 Threshold , 0.04 Top reward, -2.15 Avg reward\n",
            "[0, 0, 0]\n",
            "373 episode , 62 step , -17.39 Actor Loss, 0.40 Critic Loss,  0.05 Threshold , 0.01 Top reward, -1.78 Avg reward\n",
            "[0, 0, 0]\n",
            "374 episode , 63 step , -16.82 Actor Loss, 0.44 Critic Loss,  0.05 Threshold , 0.24 Top reward, -1.70 Avg reward\n",
            "[0, 0, 0]\n",
            "375 episode , 78 step , -15.52 Actor Loss, 0.55 Critic Loss,  0.05 Threshold , 0.33 Top reward, -1.28 Avg reward\n",
            "[0, 0, 0]\n",
            "376 episode , 95 step , -15.08 Actor Loss, 0.55 Critic Loss,  0.05 Threshold , 0.22 Top reward, -1.11 Avg reward\n",
            "[0, 0, 0]\n",
            "377 episode , 97 step , -13.57 Actor Loss, 0.68 Critic Loss,  0.05 Threshold , 0.13 Top reward, -1.14 Avg reward\n",
            "[0, 0, 0]\n",
            "378 episode , 1600 step , -13.50 Actor Loss, 0.61 Critic Loss,  0.05 Threshold , 0.33 Top reward, -0.08 Avg reward\n",
            "[0, 0, 0]\n",
            "379 episode , 51 step , -15.34 Actor Loss, 0.47 Critic Loss,  0.05 Threshold , -0.12 Top reward, -2.16 Avg reward\n",
            "[0, 0, 0]\n",
            "380 episode , 37 step , -14.03 Actor Loss, 0.64 Critic Loss,  0.05 Threshold , -0.07 Top reward, -2.94 Avg reward\n",
            "[0, 0, 0]\n",
            "381 episode , 56 step , -14.37 Actor Loss, 0.59 Critic Loss,  0.05 Threshold , -0.05 Top reward, -2.03 Avg reward\n",
            "[0, 0, 0]\n",
            "382 episode , 49 step , -13.84 Actor Loss, 0.62 Critic Loss,  0.05 Threshold , -0.05 Top reward, -2.30 Avg reward\n",
            "[0, 0, 0]\n",
            "383 episode , 48 step , -13.43 Actor Loss, 0.58 Critic Loss,  0.05 Threshold , -0.11 Top reward, -2.28 Avg reward\n",
            "[0, 0, 0]\n",
            "384 episode , 38 step , -13.18 Actor Loss, 0.75 Critic Loss,  0.05 Threshold , -0.11 Top reward, -2.83 Avg reward\n",
            "[0, 0, 0]\n",
            "385 episode , 52 step , -13.41 Actor Loss, 0.73 Critic Loss,  0.05 Threshold , -0.04 Top reward, -2.11 Avg reward\n",
            "[0, 0, 0]\n",
            "386 episode , 1600 step , -13.41 Actor Loss, 0.59 Critic Loss,  0.05 Threshold , 0.26 Top reward, -0.09 Avg reward\n",
            "[0, 0, 0]\n",
            "387 episode , 268 step , -13.19 Actor Loss, 0.50 Critic Loss,  0.05 Threshold , 0.23 Top reward, -0.48 Avg reward\n",
            "[0, 0, 0]\n",
            "388 episode , 136 step , -12.76 Actor Loss, 0.54 Critic Loss,  0.05 Threshold , 0.31 Top reward, -0.74 Avg reward\n",
            "[0, 0, 0]\n",
            "389 episode , 66 step , -11.96 Actor Loss, 0.65 Critic Loss,  0.05 Threshold , 0.15 Top reward, -1.57 Avg reward\n",
            "[0, 0, 0]\n",
            "390 episode , 80 step , -11.57 Actor Loss, 0.65 Critic Loss,  0.05 Threshold , 0.29 Top reward, -1.22 Avg reward\n",
            "[0, 0, 0]\n",
            "391 episode , 75 step , -10.73 Actor Loss, 0.63 Critic Loss,  0.05 Threshold , 0.24 Top reward, -1.35 Avg reward\n",
            "[0, 0, 0]\n",
            "392 episode , 82 step , -10.71 Actor Loss, 0.65 Critic Loss,  0.05 Threshold , 0.35 Top reward, -1.22 Avg reward\n",
            "[0, 0, 0]\n",
            "393 episode , 81 step , -9.95 Actor Loss, 0.74 Critic Loss,  0.05 Threshold , 0.18 Top reward, -1.31 Avg reward\n",
            "[0, 0, 0]\n",
            "394 episode , 97 step , -9.14 Actor Loss, 0.79 Critic Loss,  0.05 Threshold , 0.31 Top reward, -1.04 Avg reward\n",
            "[0, 0, 0]\n",
            "395 episode , 150 step , -9.25 Actor Loss, 0.77 Critic Loss,  0.05 Threshold , 0.16 Top reward, -0.71 Avg reward\n",
            "[0, 0, 0]\n",
            "396 episode , 105 step , -9.27 Actor Loss, 0.77 Critic Loss,  0.05 Threshold , 0.29 Top reward, -0.96 Avg reward\n",
            "[0, 0, 0]\n",
            "397 episode , 104 step , -9.07 Actor Loss, 0.73 Critic Loss,  0.05 Threshold , 0.24 Top reward, -1.02 Avg reward\n",
            "[0, 0, 0]\n",
            "398 episode , 102 step , -9.56 Actor Loss, 0.69 Critic Loss,  0.05 Threshold , 0.19 Top reward, -1.05 Avg reward\n",
            "[0, 0, 0]\n",
            "399 episode , 254 step , -9.21 Actor Loss, 0.67 Critic Loss,  0.05 Threshold , 0.09 Top reward, -0.51 Avg reward\n",
            "[0, 0, 0]\n",
            "400 episode , 82 step , -7.63 Actor Loss, 0.71 Critic Loss,  0.05 Threshold , 0.26 Top reward, -1.22 Avg reward\n",
            "[0, 0, 0]\n",
            "401 episode , 87 step , -7.51 Actor Loss, 0.74 Critic Loss,  0.05 Threshold , 0.18 Top reward, -1.17 Avg reward\n",
            "[0, 0, 0]\n",
            "402 episode , 73 step , -6.92 Actor Loss, 0.75 Critic Loss,  0.05 Threshold , 0.18 Top reward, -1.37 Avg reward\n",
            "[0, 0, 0]\n",
            "403 episode , 357 step , -6.87 Actor Loss, 0.72 Critic Loss,  0.05 Threshold , 0.19 Top reward, -0.36 Avg reward\n",
            "[0, 0, 0]\n",
            "404 episode , 104 step , -6.26 Actor Loss, 0.77 Critic Loss,  0.05 Threshold , 0.22 Top reward, -0.95 Avg reward\n",
            "[0, 0, 0]\n",
            "405 episode , 152 step , -5.49 Actor Loss, 0.77 Critic Loss,  0.05 Threshold , 0.32 Top reward, -0.64 Avg reward\n",
            "[0, 0, 0]\n",
            "406 episode , 114 step , -5.04 Actor Loss, 0.78 Critic Loss,  0.05 Threshold , 0.30 Top reward, -0.85 Avg reward\n",
            "[0, 0, 0]\n",
            "407 episode , 102 step , -4.26 Actor Loss, 0.81 Critic Loss,  0.05 Threshold , 0.29 Top reward, -0.93 Avg reward\n",
            "[0, 0, 0]\n",
            "408 episode , 67 step , -2.61 Actor Loss, 0.85 Critic Loss,  0.05 Threshold , 0.31 Top reward, -1.48 Avg reward\n",
            "[0, 0, 0]\n",
            "409 episode , 75 step , -3.05 Actor Loss, 0.90 Critic Loss,  0.05 Threshold , 0.40 Top reward, -1.27 Avg reward\n",
            "[0, 0, 0]\n",
            "410 episode , 101 step , -2.22 Actor Loss, 0.91 Critic Loss,  0.05 Threshold , 0.35 Top reward, -0.93 Avg reward\n",
            "[0, 0, 0]\n",
            "411 episode , 66 step , -2.04 Actor Loss, 0.96 Critic Loss,  0.05 Threshold , 0.25 Top reward, -1.58 Avg reward\n",
            "[0, 0, 0]\n",
            "412 episode , 652 step , -3.15 Actor Loss, 0.88 Critic Loss,  0.05 Threshold , 0.27 Top reward, -0.28 Avg reward\n",
            "[0, 0, 0]\n",
            "413 episode , 1314 step , -5.22 Actor Loss, 0.65 Critic Loss,  0.05 Threshold , 0.19 Top reward, -0.19 Avg reward\n",
            "[0, 0, 0]\n",
            "414 episode , 82 step , -5.51 Actor Loss, 0.63 Critic Loss,  0.05 Threshold , 0.01 Top reward, -1.50 Avg reward\n",
            "[0, 0, 0]\n",
            "415 episode , 60 step , -5.43 Actor Loss, 0.63 Critic Loss,  0.05 Threshold , 0.02 Top reward, -1.86 Avg reward\n",
            "[0, 0, 0]\n",
            "416 episode , 103 step , -5.01 Actor Loss, 0.68 Critic Loss,  0.05 Threshold , 0.14 Top reward, -1.05 Avg reward\n",
            "[0, 0, 0]\n",
            "417 episode , 84 step , -4.71 Actor Loss, 0.72 Critic Loss,  0.05 Threshold , -0.02 Top reward, -1.34 Avg reward\n",
            "[0, 0, 0]\n",
            "418 episode , 104 step , -4.84 Actor Loss, 0.71 Critic Loss,  0.05 Threshold , 0.03 Top reward, -1.12 Avg reward\n",
            "[0, 0, 0]\n",
            "419 episode , 100 step , -4.45 Actor Loss, 0.68 Critic Loss,  0.05 Threshold , 0.06 Top reward, -1.13 Avg reward\n",
            "[0, 0, 0]\n",
            "420 episode , 129 step , -4.44 Actor Loss, 0.74 Critic Loss,  0.05 Threshold , -0.01 Top reward, -0.97 Avg reward\n",
            "[0, 0, 0]\n",
            "421 episode , 106 step , -4.77 Actor Loss, 0.67 Critic Loss,  0.05 Threshold , 0.07 Top reward, -1.08 Avg reward\n",
            "[0, 0, 0]\n",
            "422 episode , 91 step , -4.96 Actor Loss, 0.69 Critic Loss,  0.05 Threshold , 0.04 Top reward, -1.24 Avg reward\n",
            "[0, 0, 0]\n",
            "423 episode , 70 step , -5.27 Actor Loss, 0.66 Critic Loss,  0.05 Threshold , -0.01 Top reward, -1.60 Avg reward\n",
            "[0, 0, 0]\n",
            "424 episode , 68 step , -5.21 Actor Loss, 0.67 Critic Loss,  0.05 Threshold , 0.02 Top reward, -1.64 Avg reward\n",
            "[0, 0, 0]\n",
            "425 episode , 76 step , -4.15 Actor Loss, 0.69 Critic Loss,  0.05 Threshold , 0.03 Top reward, -1.51 Avg reward\n",
            "[0, 0, 0]\n",
            "426 episode , 61 step , -4.27 Actor Loss, 0.71 Critic Loss,  0.05 Threshold , 0.00 Top reward, -1.83 Avg reward\n",
            "[0, 0, 0]\n",
            "427 episode , 59 step , -4.43 Actor Loss, 0.68 Critic Loss,  0.05 Threshold , -0.04 Top reward, -1.93 Avg reward\n",
            "[0, 0, 0]\n",
            "428 episode , 57 step , -4.07 Actor Loss, 0.72 Critic Loss,  0.05 Threshold , -0.02 Top reward, -1.96 Avg reward\n",
            "[0, 0, 0]\n",
            "429 episode , 73 step , -3.51 Actor Loss, 0.75 Critic Loss,  0.05 Threshold , 0.01 Top reward, -1.55 Avg reward\n",
            "[0, 0, 0]\n",
            "430 episode , 69 step , -3.87 Actor Loss, 0.70 Critic Loss,  0.05 Threshold , -0.00 Top reward, -1.66 Avg reward\n",
            "[0, 0, 0]\n",
            "431 episode , 42 step , -3.46 Actor Loss, 0.74 Critic Loss,  0.05 Threshold , -0.26 Top reward, -2.72 Avg reward\n",
            "[0, 0, 0]\n",
            "432 episode , 46 step , -3.48 Actor Loss, 0.73 Critic Loss,  0.05 Threshold , -0.08 Top reward, -2.48 Avg reward\n",
            "[0, 0, 0]\n",
            "433 episode , 41 step , -3.40 Actor Loss, 0.81 Critic Loss,  0.05 Threshold , -0.26 Top reward, -2.80 Avg reward\n",
            "[0, 0, 0]\n",
            "434 episode , 46 step , -3.44 Actor Loss, 0.77 Critic Loss,  0.05 Threshold , -0.01 Top reward, -2.52 Avg reward\n",
            "[0, 0, 0]\n",
            "435 episode , 41 step , -3.83 Actor Loss, 0.66 Critic Loss,  0.05 Threshold , -0.27 Top reward, -2.81 Avg reward\n",
            "[0, 0, 0]\n",
            "436 episode , 47 step , -3.61 Actor Loss, 0.78 Critic Loss,  0.05 Threshold , -0.03 Top reward, -2.41 Avg reward\n",
            "[0, 0, 0]\n",
            "437 episode , 41 step , -2.76 Actor Loss, 0.82 Critic Loss,  0.05 Threshold , -0.27 Top reward, -2.82 Avg reward\n",
            "[0, 0, 0]\n",
            "438 episode , 42 step , -2.74 Actor Loss, 0.75 Critic Loss,  0.05 Threshold , -0.26 Top reward, -2.74 Avg reward\n",
            "[0, 0, 0]\n",
            "439 episode , 42 step , -3.32 Actor Loss, 0.75 Critic Loss,  0.05 Threshold , -0.23 Top reward, -2.74 Avg reward\n",
            "[0, 0, 0]\n",
            "440 episode , 42 step , -3.36 Actor Loss, 0.76 Critic Loss,  0.05 Threshold , -0.18 Top reward, -2.73 Avg reward\n",
            "[0, 0, 0]\n",
            "441 episode , 49 step , -2.47 Actor Loss, 0.93 Critic Loss,  0.05 Threshold , -0.16 Top reward, -2.34 Avg reward\n",
            "[0, 0, 0]\n",
            "442 episode , 42 step , -3.26 Actor Loss, 0.78 Critic Loss,  0.05 Threshold , -0.25 Top reward, -2.72 Avg reward\n",
            "[0, 0, 0]\n",
            "443 episode , 42 step , -2.73 Actor Loss, 0.76 Critic Loss,  0.05 Threshold , -0.25 Top reward, -2.71 Avg reward\n",
            "[0, 0, 0]\n",
            "444 episode , 52 step , -2.94 Actor Loss, 0.90 Critic Loss,  0.05 Threshold , -0.08 Top reward, -2.19 Avg reward\n",
            "[0, 0, 0]\n",
            "445 episode , 47 step , -1.65 Actor Loss, 0.94 Critic Loss,  0.05 Threshold , -0.03 Top reward, -2.41 Avg reward\n",
            "[0, 0, 0]\n",
            "446 episode , 1600 step , -3.50 Actor Loss, 0.66 Critic Loss,  0.05 Threshold , 0.27 Top reward, -0.09 Avg reward\n",
            "[0, 0, 0]\n",
            "447 episode , 1600 step , -3.06 Actor Loss, 0.49 Critic Loss,  0.05 Threshold , 0.26 Top reward, -0.09 Avg reward\n",
            "[0, 0, 0]\n",
            "448 episode , 1025 step , -5.24 Actor Loss, 0.34 Critic Loss,  0.05 Threshold , 0.26 Top reward, -0.21 Avg reward\n",
            "[0, 0, 0]\n",
            "449 episode , 343 step , -8.81 Actor Loss, 0.21 Critic Loss,  0.05 Threshold , 0.20 Top reward, -0.45 Avg reward\n",
            "[0, 0, 0]\n",
            "450 episode , 447 step , -10.86 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.18 Top reward, -0.36 Avg reward\n",
            "[0, 0, 0]\n",
            "451 episode , 297 step , -11.85 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.06 Top reward, -0.51 Avg reward\n",
            "[0, 0, 0]\n",
            "452 episode , 1600 step , -11.50 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.24 Top reward, -0.10 Avg reward\n",
            "[0, 0, 0]\n",
            "453 episode , 127 step , -10.79 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 0.07 Top reward, -0.88 Avg reward\n",
            "[0, 0, 0]\n",
            "454 episode , 539 step , -10.12 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.08 Top reward, -0.28 Avg reward\n",
            "[0, 0, 0]\n",
            "455 episode , 114 step , -9.48 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , -0.08 Top reward, -1.13 Avg reward\n",
            "[0, 0, 0]\n",
            "456 episode , 286 step , -9.10 Actor Loss, 0.15 Critic Loss,  0.05 Threshold , 0.09 Top reward, -0.43 Avg reward\n",
            "[0, 0, 0]\n",
            "457 episode , 193 step , -8.30 Actor Loss, 0.15 Critic Loss,  0.05 Threshold , 0.18 Top reward, -0.58 Avg reward\n",
            "[0, 0, 0]\n",
            "458 episode , 186 step , -7.75 Actor Loss, 0.20 Critic Loss,  0.05 Threshold , 0.18 Top reward, -0.63 Avg reward\n",
            "[0, 0, 0]\n",
            "459 episode , 238 step , -7.08 Actor Loss, 0.20 Critic Loss,  0.05 Threshold , 0.21 Top reward, -0.50 Avg reward\n",
            "[0, 0, 0]\n",
            "460 episode , 125 step , -6.72 Actor Loss, 0.24 Critic Loss,  0.05 Threshold , 0.21 Top reward, -0.86 Avg reward\n",
            "[0, 0, 0]\n",
            "461 episode , 68 step , -6.76 Actor Loss, 0.34 Critic Loss,  0.05 Threshold , 0.13 Top reward, -1.59 Avg reward\n",
            "[0, 0, 0]\n",
            "462 episode , 55 step , -6.54 Actor Loss, 0.39 Critic Loss,  0.05 Threshold , 0.16 Top reward, -1.92 Avg reward\n",
            "[0, 0, 0]\n",
            "463 episode , 70 step , -6.44 Actor Loss, 0.36 Critic Loss,  0.05 Threshold , 0.17 Top reward, -1.50 Avg reward\n",
            "[0, 0, 0]\n",
            "464 episode , 69 step , -5.96 Actor Loss, 0.38 Critic Loss,  0.05 Threshold , 0.12 Top reward, -1.53 Avg reward\n",
            "[0, 0, 0]\n",
            "465 episode , 70 step , -6.29 Actor Loss, 0.43 Critic Loss,  0.05 Threshold , 0.19 Top reward, -1.50 Avg reward\n",
            "[0, 0, 0]\n",
            "466 episode , 61 step , -6.11 Actor Loss, 0.41 Critic Loss,  0.05 Threshold , 0.25 Top reward, -1.66 Avg reward\n",
            "[0, 0, 0]\n",
            "467 episode , 72 step , -5.69 Actor Loss, 0.43 Critic Loss,  0.05 Threshold , 0.11 Top reward, -1.43 Avg reward\n",
            "[0, 0, 0]\n",
            "468 episode , 62 step , -5.47 Actor Loss, 0.51 Critic Loss,  0.05 Threshold , 0.21 Top reward, -1.65 Avg reward\n",
            "[0, 0, 0]\n",
            "469 episode , 56 step , -5.10 Actor Loss, 0.49 Critic Loss,  0.05 Threshold , 0.36 Top reward, -1.82 Avg reward\n",
            "[0, 0, 0]\n",
            "470 episode , 73 step , -4.93 Actor Loss, 0.48 Critic Loss,  0.05 Threshold , 0.39 Top reward, -1.35 Avg reward\n",
            "[0, 0, 0]\n",
            "471 episode , 59 step , -4.63 Actor Loss, 0.43 Critic Loss,  0.05 Threshold , 0.14 Top reward, -1.74 Avg reward\n",
            "[0, 0, 0]\n",
            "472 episode , 62 step , -4.75 Actor Loss, 0.52 Critic Loss,  0.05 Threshold , 0.19 Top reward, -1.66 Avg reward\n",
            "[0, 0, 0]\n",
            "473 episode , 47 step , -3.93 Actor Loss, 0.51 Critic Loss,  0.05 Threshold , 0.13 Top reward, -2.21 Avg reward\n",
            "[0, 0, 0]\n",
            "474 episode , 60 step , -3.52 Actor Loss, 0.55 Critic Loss,  0.05 Threshold , 0.23 Top reward, -1.71 Avg reward\n",
            "[0, 0, 0]\n",
            "475 episode , 55 step , -3.21 Actor Loss, 0.67 Critic Loss,  0.05 Threshold , 0.19 Top reward, -1.89 Avg reward\n",
            "[0, 0, 0]\n",
            "476 episode , 63 step , -3.25 Actor Loss, 0.57 Critic Loss,  0.05 Threshold , 0.18 Top reward, -1.63 Avg reward\n",
            "[0, 0, 0]\n",
            "477 episode , 57 step , -2.43 Actor Loss, 0.72 Critic Loss,  0.05 Threshold , 0.31 Top reward, -1.81 Avg reward\n",
            "[0, 0, 0]\n",
            "478 episode , 51 step , -2.77 Actor Loss, 0.66 Critic Loss,  0.05 Threshold , 0.25 Top reward, -2.02 Avg reward\n",
            "[0, 0, 0]\n",
            "479 episode , 143 step , -1.74 Actor Loss, 0.63 Critic Loss,  0.05 Threshold , 0.23 Top reward, -0.77 Avg reward\n",
            "[0, 0, 0]\n",
            "480 episode , 58 step , -1.61 Actor Loss, 0.67 Critic Loss,  0.05 Threshold , 0.09 Top reward, -1.81 Avg reward\n",
            "[0, 0, 0]\n",
            "481 episode , 62 step , -0.70 Actor Loss, 0.63 Critic Loss,  0.05 Threshold , 0.32 Top reward, -1.66 Avg reward\n",
            "[0, 0, 0]\n",
            "482 episode , 99 step , -0.39 Actor Loss, 0.73 Critic Loss,  0.05 Threshold , 0.14 Top reward, -1.08 Avg reward\n",
            "[0, 0, 0]\n",
            "483 episode , 80 step , 0.14 Actor Loss, 0.69 Critic Loss,  0.05 Threshold , 0.12 Top reward, -1.31 Avg reward\n",
            "[0, 0, 0]\n",
            "484 episode , 84 step , 0.16 Actor Loss, 0.70 Critic Loss,  0.05 Threshold , 0.10 Top reward, -1.26 Avg reward\n",
            "[0, 0, 0]\n",
            "485 episode , 65 step , 0.75 Actor Loss, 0.75 Critic Loss,  0.05 Threshold , 0.25 Top reward, -1.57 Avg reward\n",
            "[0, 0, 0]\n",
            "486 episode , 95 step , 0.89 Actor Loss, 0.74 Critic Loss,  0.05 Threshold , 0.23 Top reward, -1.09 Avg reward\n",
            "[0, 0, 0]\n",
            "487 episode , 86 step , 1.64 Actor Loss, 0.76 Critic Loss,  0.05 Threshold , 0.29 Top reward, -1.17 Avg reward\n",
            "[0, 0, 0]\n",
            "488 episode , 94 step , 2.43 Actor Loss, 0.84 Critic Loss,  0.05 Threshold , 0.32 Top reward, -1.06 Avg reward\n",
            "[0, 0, 0]\n",
            "489 episode , 71 step , 2.59 Actor Loss, 0.78 Critic Loss,  0.05 Threshold , 0.22 Top reward, -1.45 Avg reward\n",
            "[0, 0, 0]\n",
            "490 episode , 91 step , 3.19 Actor Loss, 0.85 Critic Loss,  0.05 Threshold , 0.25 Top reward, -1.13 Avg reward\n",
            "[0, 0, 0]\n",
            "491 episode , 117 step , 3.88 Actor Loss, 0.82 Critic Loss,  0.05 Threshold , 0.42 Top reward, -0.84 Avg reward\n",
            "[0, 0, 0]\n",
            "492 episode , 94 step , 4.28 Actor Loss, 0.78 Critic Loss,  0.05 Threshold , 0.33 Top reward, -1.07 Avg reward\n",
            "[0, 0, 0]\n",
            "493 episode , 108 step , 4.91 Actor Loss, 0.88 Critic Loss,  0.05 Threshold , 0.39 Top reward, -0.92 Avg reward\n",
            "[0, 0, 0]\n",
            "494 episode , 1600 step , 5.96 Actor Loss, 0.80 Critic Loss,  0.05 Threshold , 0.27 Top reward, -0.07 Avg reward\n",
            "[0, 0, 0]\n",
            "495 episode , 988 step , 6.36 Actor Loss, 0.66 Critic Loss,  0.05 Threshold , 0.31 Top reward, -0.13 Avg reward\n",
            "[0, 0, 0]\n",
            "496 episode , 108 step , 5.72 Actor Loss, 0.61 Critic Loss,  0.05 Threshold , 0.36 Top reward, -0.93 Avg reward\n",
            "[0, 0, 0]\n",
            "497 episode , 1178 step , 2.54 Actor Loss, 0.47 Critic Loss,  0.05 Threshold , 0.25 Top reward, -0.16 Avg reward\n",
            "[0, 0, 0]\n",
            "498 episode , 203 step , -1.16 Actor Loss, 0.35 Critic Loss,  0.05 Threshold , 0.40 Top reward, -0.54 Avg reward\n",
            "[0, 0, 0]\n",
            "499 episode , 99 step , -1.61 Actor Loss, 0.32 Critic Loss,  0.05 Threshold , 0.34 Top reward, -1.01 Avg reward\n",
            "[0, 0, 0]\n",
            "Complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pWWG7HcMD3j",
        "colab_type": "text"
      },
      "source": [
        "## Rendering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHCq9xymdUgJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8f0bd2de-7ebf-4c94-c098-0f315cce96b4"
      },
      "source": [
        "!pip install JSAnimation\n",
        "from matplotlib import animation, rc\n",
        "from JSAnimation.IPython_display import display_animation\n",
        "from IPython.display import display\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import io"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: JSAnimation in /usr/local/lib/python3.6/dist-packages (0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2NMRr68tmra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_video():\n",
        "  mp4list = glob.glob('./*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    print(mp4list)\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jaeim4ulL0y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports specifically so we can render outputs in Colab.\n",
        "fig = plt.figure()\n",
        "def display_frames_as_gif(frame):\n",
        "    \"\"\"Displays a list of frames as a gif, with controls.\"\"\"\n",
        "    patch = plt.imshow(frame[0].astype(int))\n",
        "    def animate(i):\n",
        "        patch.set_data(frame[i].astype(int))\n",
        "\n",
        "    anim = animation.FuncAnimation(\n",
        "        fig, animate, frames=len(frames), interval=30, blit=False\n",
        "    )\n",
        "    #display(display_animation(anim, default_mode='loop'))\n",
        "    # Set up formatting for the movie files\n",
        "    display(HTML(data=anim.to_html5_video()))\n",
        "    #FFwriter = animation.FFMpegWriter()\n",
        "    #anim.save('basic_animation.mp4', writer = FFwriter)\n",
        "    #show_video()\n",
        "# display \n",
        "display_frames_as_gif(frames)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}