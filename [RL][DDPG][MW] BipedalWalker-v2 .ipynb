{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMxoXSCWGwcPRc8AQKO9YdV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gomyk/NNStudy/blob/moonwon/%5BRL%5D%5BDDPG%5D%5BMW%5D%20BipedalWalker-v2%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO9p_LliP05R",
        "colab_type": "text"
      },
      "source": [
        "#Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9duZfSLhJ8X",
        "colab_type": "code",
        "outputId": "057bff4d-d2e2-445d-ca04-d84913345c39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!apt-get install x11-utils\n",
        "!pip install box2d-py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "x11-utils is already the newest version (7.7+3build1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n",
            "Requirement already satisfied: box2d-py in /usr/local/lib/python3.6/dist-packages (2.3.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DE8ejMqcTWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "import math\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "from PIL import Image\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import base64\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "from google.colab import output\n",
        "\n",
        "display = Display(visible=0, size=(400,600),)\n",
        "display.start()\n",
        "env = gym.make(\"BipedalWalker-v2\")\n",
        "env._max_episode_steps = 1600\n",
        "\n",
        "#env = gym.wrappers.Monitor(gym.make(\"CartPole-v1\"), \"video\", force=True, video_callable=lambda c:c%100 ==0)\n",
        "\n",
        "# GPU를 사용할 경우\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3exp-qAP7jv",
        "colab_type": "text"
      },
      "source": [
        "##Replay Memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmc6Jfr2d8_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReplayMemory:\n",
        "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
        "\n",
        "    def __init__(self, action_dim:int , obs_dim: int, size: int, batch_size: int):\n",
        "        \"\"\"Initializate.\"\"\"\n",
        "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.acts_buf = np.zeros([size, action_dim], dtype=np.float32)\n",
        "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.done_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.max_size, self.batch_size = size, batch_size\n",
        "        self.ptr, self.size, = 0, 0\n",
        "\n",
        "    def store(\n",
        "        self,\n",
        "        obs: np.ndarray,\n",
        "        act: np.ndarray, \n",
        "        rew: float, \n",
        "        next_obs: np.ndarray, \n",
        "        done: bool,\n",
        "    ):\n",
        "        \"\"\"Store the transition in buffer.\"\"\"\n",
        "        self.obs_buf[self.ptr] = obs\n",
        "        self.next_obs_buf[self.ptr] = next_obs\n",
        "        self.acts_buf[self.ptr] = act\n",
        "        self.rews_buf[self.ptr] = rew\n",
        "        self.done_buf[self.ptr] = done\n",
        "        self.ptr = (self.ptr + 1) % self.max_size\n",
        "        self.size = min(self.size + 1, self.max_size)\n",
        "\n",
        "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
        "        return dict(obs=self.obs_buf[idxs],\n",
        "                    next_obs=self.next_obs_buf[idxs],\n",
        "                    acts=self.acts_buf[idxs],\n",
        "                    rews=self.rews_buf[idxs],\n",
        "                    done=self.done_buf[idxs])\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwrDEGlnQAeH",
        "colab_type": "text"
      },
      "source": [
        "##Define Noise Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j021icUCet_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OUNoise:\n",
        "    \"\"\"Ornstein-Uhlenbeck process.\n",
        "    Taken from Udacity deep-reinforcement-learning github repository:\n",
        "    https://github.com/udacity/deep-reinforcement-learning/blob/master/\n",
        "    ddpg-pendulum/ddpg_agent.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        size: int, \n",
        "        mu: float = 0.0, \n",
        "        theta: float = 0.15, \n",
        "        sigma: float = 0.2,\n",
        "    ):\n",
        "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
        "        self.state = np.float64(0.0)\n",
        "        self.mu = mu * np.ones(size)\n",
        "        self.theta = theta\n",
        "        self.sigma = sigma\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
        "        self.state = copy.copy(self.mu)\n",
        "\n",
        "    def sample(self) -> np.ndarray:\n",
        "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
        "        x = self.state\n",
        "        dx = self.theta * (self.mu - x) + self.sigma * np.array(\n",
        "            [random.random() for _ in range(len(x))]\n",
        "        )\n",
        "        self.state = x + dx\n",
        "        return self.state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYAZSWC2QGDx",
        "colab_type": "text"
      },
      "source": [
        "##Actor Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1hagvrqKTpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HIDDEN_SIZE = 256\n",
        "HIDDEN_SIZE2 = 128\n",
        "class Actor(nn.Module):\n",
        "\n",
        "    def __init__(self, obs_size, outputs, init_w: float = 3e-3,):\n",
        "        super(Actor, self).__init__()\n",
        "        self.linear = nn.Linear(obs_size, HIDDEN_SIZE)\n",
        "        self.linear2 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE2)\n",
        "        self.linear3 = nn.Linear(HIDDEN_SIZE2, HIDDEN_SIZE)\n",
        "        self.head = nn.Linear(HIDDEN_SIZE2, outputs)\n",
        "\n",
        "        self.head.weight.data.uniform_(-init_w, init_w)\n",
        "        self.head.bias.data.uniform_(-init_w, init_w)\n",
        "\n",
        "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
        "        x = F.relu(self.linear(state))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = F.dropout(x, 0.5)\n",
        "        #x = F.relu(self.linear3(x))\n",
        "        return self.head(x).tanh()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy5GwnzbQJ4o",
        "colab_type": "text"
      },
      "source": [
        "##Critic Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_lqf372OXYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Critic(nn.Module):\n",
        "\n",
        "    def __init__(self, obs_size, action_size, init_w: float = 3e-3,):\n",
        "        super(Critic, self).__init__()\n",
        "        self.linear = nn.Linear(obs_size + action_size, HIDDEN_SIZE)\n",
        "        self.linear2 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE2)\n",
        "        self.linear3 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.head = nn.Linear(HIDDEN_SIZE2, 1)\n",
        "\n",
        "        self.head.weight.data.uniform_(-init_w, init_w)\n",
        "        self.head.bias.data.uniform_(-init_w, init_w)\n",
        "\n",
        "    def forward(self, state: torch.Tensor, action: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward method implementation.\"\"\"\n",
        "        x = torch.cat((state, action), dim=-1)\n",
        "        x = F.relu(self.linear(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = F.dropout(x, 0.5)\n",
        "        #x = F.relu(self.linear3(x))\n",
        "        return self.head(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtxzbD_-QPWZ",
        "colab_type": "text"
      },
      "source": [
        "###Environment Snapshot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVgLn9rKgS79",
        "colab_type": "code",
        "outputId": "5815ff73-5df2-4084-ec65-248910adf052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "env.reset()\n",
        "plt.figure()\n",
        "plt.imshow(env.render(mode='rgb_array'))\n",
        "plt.title('Example extracted screen')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDm4zs8z8fxnhxjNjO/w7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_0DaDLxQVkZ",
        "colab_type": "text"
      },
      "source": [
        "##Prepare to learning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y5GkgVljenU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.99\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.01\n",
        "EPS_DECAY = 2000\n",
        "TARGET_UPDATE = 9\n",
        "ACTOR_LR = 0.0001\n",
        "CRITIC_LR = 0.0003\n",
        "MEMORY_SIZE = 10000\n",
        "EPISODE_SIZE = 1000\n",
        "TAU = 0.005\n",
        "ou_noise_theta = 0.15\n",
        "ou_noise_sigma = 0.2\n",
        "\n",
        "RECORD_INTERVAL = 199\n",
        "\n",
        "# gym 행동 공간에서 행동의 숫자를 얻습니다.\n",
        "#n_actions = env.action_space.n\n",
        "n_actions = 4\n",
        "n_obvs = 24\n",
        "\n",
        "actor = Actor(n_obvs, n_actions).to(device)\n",
        "actor.eval()\n",
        "actor_target = Actor(n_obvs, n_actions).to(device)\n",
        "actor_target.load_state_dict(actor.state_dict())\n",
        "actor_target.eval()\n",
        "\n",
        "critic = Critic(n_obvs, n_actions).to(device)\n",
        "critic.eval()\n",
        "critic_target = Critic(n_obvs, n_actions).to(device)\n",
        "critic_target.load_state_dict(critic.state_dict())\n",
        "critic_target.eval()\n",
        "\n",
        "actor_optimizer = optim.Adam(actor.parameters(), lr=ACTOR_LR)\n",
        "critic_optimizer = optim.Adam(critic.parameters(), lr=CRITIC_LR, weight_decay=0.0001)\n",
        "memory = ReplayMemory(n_actions,n_obvs,MEMORY_SIZE,BATCH_SIZE)\n",
        "\n",
        "noise = OUNoise(\n",
        "            n_actions,\n",
        "            theta=ou_noise_theta,\n",
        "            sigma=ou_noise_sigma,\n",
        "        )\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    steps_done += 1\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    if sample < eps_threshold:\n",
        "            #selected_action = [np.random.uniform(0,1),np.random.uniform(0,1),np.random.uniform(0,1)]\n",
        "            selected_action = np.random.uniform(-1,1,n_actions)\n",
        "    else:\n",
        "        selected_action = actor(\n",
        "             torch.FloatTensor(state).to(device)\n",
        "         ).detach().cpu().numpy()\n",
        "    _noise = noise.sample()\n",
        "    for action in selected_action:\n",
        "      action = np.clip(action + _noise, -1.0, 1.0)\n",
        "    return selected_action\n",
        "episode_durations = []\n",
        "\n",
        "\n",
        "def plot_durations():\n",
        "    plt.figure(2)\n",
        "    plt.clf()\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Total Reward')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # 100개의 에피소드 평균을 가져 와서 도표 그리기\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB_xKtOnUR4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def target_soft_update():\n",
        "        #Soft-update: target = tau*local + (1-tau)*target\n",
        "        tau = TAU\n",
        "        \n",
        "        for t_param, l_param in zip(\n",
        "            actor_target.parameters(), actor.parameters()\n",
        "        ):\n",
        "            t_param.data.copy_(tau * l_param.data + (1.0 - tau) * t_param.data)\n",
        "            \n",
        "        for t_param, l_param in zip(\n",
        "            critic_target.parameters(), critic.parameters()\n",
        "        ):\n",
        "            t_param.data.copy_(tau * l_param.data + (1.0 - tau) * t_param.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpvU9RgzCYsW",
        "colab_type": "text"
      },
      "source": [
        "##Normalizer for obv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW7qP2ZuQf-s",
        "colab_type": "text"
      },
      "source": [
        "##Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1Vbb4tzjnjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return -1 , -1\n",
        "    samples = memory.sample_batch()\n",
        "    state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
        "    next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
        "    action = torch.FloatTensor(samples[\"acts\"]).to(device)\n",
        "    reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
        "    done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
        "    \n",
        "    masks = 1 - done\n",
        "    next_action = actor_target(next_state)\n",
        "    next_value = critic_target(next_state, next_action)\n",
        "    curr_return = reward + GAMMA * next_value * masks\n",
        "\n",
        "    # train critic\n",
        "    values = critic(state, action)\n",
        "    critic_loss = F.smooth_l1_loss(values, curr_return)\n",
        "    critic_optimizer.zero_grad()\n",
        "    critic_loss.backward()\n",
        "    critic_optimizer.step()     \n",
        "    # train actor\n",
        "    loss = critic(state, actor(state))\n",
        "    actor_loss = -loss.mean()\n",
        "        \n",
        "    actor_optimizer.zero_grad()\n",
        "    actor_loss.backward()\n",
        "    actor_optimizer.step()\n",
        "        \n",
        "    # target update\n",
        "    target_soft_update()\n",
        "\n",
        "    return actor_loss.data, critic_loss.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4UN3NpFQiLJ",
        "colab_type": "text"
      },
      "source": [
        "##Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-2dnWNDjp7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frames = []\n",
        "\n",
        "for i_episode in range(EPISODE_SIZE):\n",
        "    # 환경과 상태 초기화\n",
        "    obv = env.reset()\n",
        "    total_actor_loss = 0\n",
        "    total_critic_loss = 0\n",
        "    total_reward = 0\n",
        "    global steps_done\n",
        "    top_reward = -1\n",
        "    total_action_count = [0,0,0]\n",
        "    for t in count():\n",
        "        if i_episode % RECORD_INTERVAL == 0:\n",
        "          frames.append(env.render(mode=\"rgb_array\"))\n",
        "        # 행동 선택과 수행\n",
        "        action = select_action(obv)\n",
        "        next_obv, reward, done, _ = env.step(action)\n",
        "        reward = max(min(reward, 1), -1)\n",
        "        if reward > top_reward:\n",
        "          top_reward = reward\n",
        "        total_reward += reward\n",
        "\n",
        "        # 메모리에 변이 저장\n",
        "        assert obv is not None\n",
        "        memory.store(obv, action, reward, next_obv, done)\n",
        "\n",
        "        # 다음 상태로 이동\n",
        "        obv = next_obv\n",
        "\n",
        "        # 최적화 한단계 수행(목표 네트워크에서)\n",
        "        actor_loss, critic_loss = optimize_model()\n",
        "        total_actor_loss += actor_loss\n",
        "        total_critic_loss += critic_loss\n",
        "        if done:\n",
        "            E = eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "            math.exp(-1. * steps_done / EPS_DECAY)\n",
        "            episode_durations.append(total_reward)\n",
        "            print('%d episode , %d step , %.2f Actor Loss, %.2f Critic Loss,  %.2f Threshold , %.2f Top reward, %.2f Total reward'\\\n",
        "                  %(i_episode,t+1,total_actor_loss/(t+1), total_critic_loss/(t+1) ,E, top_reward, total_reward))\n",
        "            #print(total_action_count)\n",
        "            plot_durations()\n",
        "            total_actor_loss = 0\n",
        "            total_critic_loss = 0\n",
        "            top_reward = 0\n",
        "            total_reward = 0\n",
        "            total_action_count = [0,0,0]\n",
        "            break\n",
        "    #목표 네트워크 업데이트, 모든 웨이트와 바이어스 복사\n",
        "    if i_episode % TARGET_UPDATE == 0:\n",
        "        actor_target.load_state_dict(actor.state_dict())\n",
        "        critic_target.load_state_dict(critic.state_dict())\n",
        "print('Complete')\n",
        "env.render()\n",
        "env.close()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pWWG7HcMD3j",
        "colab_type": "text"
      },
      "source": [
        "## Rendering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lg-4834irdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHCq9xymdUgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install JSAnimation\n",
        "from matplotlib import animation, rc\n",
        "from JSAnimation.IPython_display import display_animation\n",
        "from IPython.display import display\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2NMRr68tmra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_video():\n",
        "  mp4list = glob.glob('./*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    print(mp4list)\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jaeim4ulL0y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports specifically so we can render outputs in Colab.\n",
        "fig = plt.figure()\n",
        "def display_frames_as_gif(frame):\n",
        "    \"\"\"Displays a list of frames as a gif, with controls.\"\"\"\n",
        "    patch = plt.imshow(frame[0].astype(int))\n",
        "    def animate(i):\n",
        "        patch.set_data(frame[i].astype(int))\n",
        "\n",
        "    anim = animation.FuncAnimation(\n",
        "        fig, animate, frames=len(frames), interval=30, blit=False\n",
        "    )\n",
        "    #display(display_animation(anim, default_mode='loop'))\n",
        "    # Set up formatting for the movie files\n",
        "    display(HTML(data=anim.to_html5_video()))\n",
        "    #FFwriter = animation.FFMpegWriter()\n",
        "    #anim.save('basic_animation.mp4', writer = FFwriter)\n",
        "    #show_video()\n",
        "# display \n",
        "display_frames_as_gif(frames)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}