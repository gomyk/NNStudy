{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxitKE2qhD9efQ7u+6jr58",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gomyk/NNStudy/blob/moonwon/%5BRL%5D%5BDDPG%5D%5BMW%5D%20MountainCar-v0%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO9p_LliP05R",
        "colab_type": "text"
      },
      "source": [
        "#Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9duZfSLhJ8X",
        "colab_type": "code",
        "outputId": "fa9fd9a7-d558-4644-a6e6-af55ad16d14a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!apt-get install x11-utils"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "x11-utils is already the newest version (7.7+3build1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DE8ejMqcTWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "import math\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "from PIL import Image\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import base64\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "from google.colab import output\n",
        "\n",
        "display = Display(visible=0, size=(400,600),)\n",
        "display.start()\n",
        "env = gym.make(\"MountainCar-v0\")\n",
        "\n",
        "#env = gym.wrappers.Monitor(gym.make(\"CartPole-v1\"), \"video\", force=True, video_callable=lambda c:c%100 ==0)\n",
        "\n",
        "# GPU를 사용할 경우\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3exp-qAP7jv",
        "colab_type": "text"
      },
      "source": [
        "##Replay Memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmc6Jfr2d8_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReplayMemory:\n",
        "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
        "\n",
        "    def __init__(self, action_dim:int , obs_dim: int, size: int, batch_size: int):\n",
        "        \"\"\"Initializate.\"\"\"\n",
        "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.acts_buf = np.zeros([size, action_dim], dtype=np.float32)\n",
        "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.done_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.max_size, self.batch_size = size, batch_size\n",
        "        self.ptr, self.size, = 0, 0\n",
        "\n",
        "    def store(\n",
        "        self,\n",
        "        obs: np.ndarray,\n",
        "        act: np.ndarray, \n",
        "        rew: float, \n",
        "        next_obs: np.ndarray, \n",
        "        done: bool,\n",
        "    ):\n",
        "        \"\"\"Store the transition in buffer.\"\"\"\n",
        "        self.obs_buf[self.ptr] = obs\n",
        "        self.next_obs_buf[self.ptr] = next_obs\n",
        "        self.acts_buf[self.ptr] = act\n",
        "        self.rews_buf[self.ptr] = rew\n",
        "        self.done_buf[self.ptr] = done\n",
        "        self.ptr = (self.ptr + 1) % self.max_size\n",
        "        self.size = min(self.size + 1, self.max_size)\n",
        "\n",
        "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
        "        return dict(obs=self.obs_buf[idxs],\n",
        "                    next_obs=self.next_obs_buf[idxs],\n",
        "                    acts=self.acts_buf[idxs],\n",
        "                    rews=self.rews_buf[idxs],\n",
        "                    done=self.done_buf[idxs])\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwrDEGlnQAeH",
        "colab_type": "text"
      },
      "source": [
        "##Define Noise Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j021icUCet_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OUNoise:\n",
        "    \"\"\"Ornstein-Uhlenbeck process.\n",
        "    Taken from Udacity deep-reinforcement-learning github repository:\n",
        "    https://github.com/udacity/deep-reinforcement-learning/blob/master/\n",
        "    ddpg-pendulum/ddpg_agent.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        size: int, \n",
        "        mu: float = 0.0, \n",
        "        theta: float = 0.15, \n",
        "        sigma: float = 0.2,\n",
        "    ):\n",
        "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
        "        self.state = np.float64(0.0)\n",
        "        self.mu = mu * np.ones(size)\n",
        "        self.theta = theta\n",
        "        self.sigma = sigma\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
        "        self.state = copy.copy(self.mu)\n",
        "\n",
        "    def sample(self) -> np.ndarray:\n",
        "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
        "        x = self.state\n",
        "        dx = self.theta * (self.mu - x) + self.sigma * np.array(\n",
        "            [random.random() for _ in range(len(x))]\n",
        "        )\n",
        "        self.state = x + dx\n",
        "        return self.state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYAZSWC2QGDx",
        "colab_type": "text"
      },
      "source": [
        "##Actor Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1hagvrqKTpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HIDDEN_SIZE = 128\n",
        "class Actor(nn.Module):\n",
        "\n",
        "    def __init__(self, obs_size, outputs, init_w: float = 3e-3,):\n",
        "        super(Actor, self).__init__()\n",
        "        self.linear = nn.Linear(obs_size, HIDDEN_SIZE)\n",
        "        self.linear2 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.linear3 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.head = nn.Linear(HIDDEN_SIZE, outputs)\n",
        "\n",
        "        self.head.weight.data.uniform_(-init_w, init_w)\n",
        "        self.head.bias.data.uniform_(-init_w, init_w)\n",
        "\n",
        "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
        "        x = F.relu(self.linear(state))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = F.relu(self.linear3(x))\n",
        "        return self.head(x).tanh()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy5GwnzbQJ4o",
        "colab_type": "text"
      },
      "source": [
        "##Critic Netword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_lqf372OXYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Critic(nn.Module):\n",
        "\n",
        "    def __init__(self, obs_size, action_size, init_w: float = 3e-3,):\n",
        "        super(Critic, self).__init__()\n",
        "        self.linear = nn.Linear(obs_size + action_size, HIDDEN_SIZE)\n",
        "        self.linear2 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.linear3 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.head = nn.Linear(HIDDEN_SIZE, 1)\n",
        "\n",
        "        self.head.weight.data.uniform_(-init_w, init_w)\n",
        "        self.head.bias.data.uniform_(-init_w, init_w)\n",
        "\n",
        "    def forward(self, state: torch.Tensor, action: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward method implementation.\"\"\"\n",
        "        x = torch.cat((state, action), dim=-1)\n",
        "        x = F.relu(self.linear(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = F.relu(self.linear3(x))\n",
        "        return self.head(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtxzbD_-QPWZ",
        "colab_type": "text"
      },
      "source": [
        "###Environment Snapshot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVgLn9rKgS79",
        "colab_type": "code",
        "outputId": "9add3ce1-91ab-4296-aba6-d20cbf2b4bd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "env.reset()\n",
        "plt.figure()\n",
        "plt.imshow(env.render(mode='rgb_array'))\n",
        "plt.title('Example extracted screen')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_0DaDLxQVkZ",
        "colab_type": "text"
      },
      "source": [
        "##Prepare to learning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y5GkgVljenU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "GAMMA = 0.99\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 2000\n",
        "TARGET_UPDATE = 10\n",
        "ACTOR_LR = 0.001\n",
        "CRITIC_LR = 0.001\n",
        "MEMORY_SIZE = 10000\n",
        "EPISODE_SIZE = 1000\n",
        "TAU = 0.005\n",
        "ou_noise_theta = 1.0\n",
        "ou_noise_sigma = 0.1\n",
        "\n",
        "RECORD_INTERVAL = 100\n",
        "\n",
        "# gym 행동 공간에서 행동의 숫자를 얻습니다.\n",
        "n_actions = env.action_space.n\n",
        "n_obvs = 2\n",
        "\n",
        "actor = Actor(n_obvs, n_actions).to(device)\n",
        "actor.eval()\n",
        "actor_target = Actor(n_obvs, n_actions).to(device)\n",
        "actor_target.load_state_dict(actor.state_dict())\n",
        "actor_target.eval()\n",
        "\n",
        "critic = Critic(n_obvs, n_actions).to(device)\n",
        "critic.eval()\n",
        "critic_target = Critic(n_obvs, n_actions).to(device)\n",
        "critic_target.load_state_dict(critic.state_dict())\n",
        "critic_target.eval()\n",
        "\n",
        "actor_optimizer = optim.Adam(actor.parameters(), lr=ACTOR_LR)\n",
        "critic_optimizer = optim.Adam(critic.parameters(), lr=CRITIC_LR)\n",
        "memory = ReplayMemory(n_actions,n_obvs,MEMORY_SIZE,BATCH_SIZE)\n",
        "\n",
        "noise = OUNoise(\n",
        "            n_actions,\n",
        "            theta=ou_noise_theta,\n",
        "            sigma=ou_noise_sigma,\n",
        "        )\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    steps_done += 1\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    if sample < eps_threshold:\n",
        "            selected_action = [np.random.uniform(0,1),np.random.uniform(0,1),np.random.uniform(0,1)]\n",
        "    else:\n",
        "        selected_action = actor(\n",
        "             torch.FloatTensor(state).to(device)\n",
        "         ).detach().cpu().numpy()\n",
        "    _noise = noise.sample()\n",
        "    for action in selected_action:\n",
        "      action = np.clip(action + _noise, -1.0, 1.0)\n",
        "    return selected_action\n",
        "episode_durations = []\n",
        "\n",
        "\n",
        "def plot_durations():\n",
        "    plt.figure(2)\n",
        "    plt.clf()\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # 100개의 에피소드 평균을 가져 와서 도표 그리기\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB_xKtOnUR4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def target_soft_update():\n",
        "        #Soft-update: target = tau*local + (1-tau)*target\n",
        "        tau = TAU\n",
        "        \n",
        "        for t_param, l_param in zip(\n",
        "            actor_target.parameters(), actor.parameters()\n",
        "        ):\n",
        "            t_param.data.copy_(tau * l_param.data + (1.0 - tau) * t_param.data)\n",
        "            \n",
        "        for t_param, l_param in zip(\n",
        "            critic_target.parameters(), critic.parameters()\n",
        "        ):\n",
        "            t_param.data.copy_(tau * l_param.data + (1.0 - tau) * t_param.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW7qP2ZuQf-s",
        "colab_type": "text"
      },
      "source": [
        "##Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1Vbb4tzjnjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return -1 , -1\n",
        "    samples = memory.sample_batch()\n",
        "    state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
        "    next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
        "    action = torch.FloatTensor(samples[\"acts\"]).to(device)\n",
        "    reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
        "    done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
        "    \n",
        "    masks = 1 - done\n",
        "    next_action = actor_target(next_state)\n",
        "    next_value = critic_target(next_state, next_action)\n",
        "    curr_return = reward + GAMMA * next_value * masks\n",
        "\n",
        "    # train critic\n",
        "    values = critic(state, action)\n",
        "    critic_loss = F.smooth_l1_loss(values, curr_return)\n",
        "    critic_optimizer.zero_grad()\n",
        "    critic_loss.backward()\n",
        "    critic_optimizer.step()     \n",
        "    # train actor\n",
        "    actor_loss = critic(state, actor(state)).mean()\n",
        "        \n",
        "    actor_optimizer.zero_grad()\n",
        "    actor_loss.backward()\n",
        "    actor_optimizer.step()\n",
        "        \n",
        "    # target update\n",
        "    target_soft_update()\n",
        "\n",
        "    return actor_loss.data, critic_loss.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4UN3NpFQiLJ",
        "colab_type": "text"
      },
      "source": [
        "##Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-2dnWNDjp7y",
        "colab_type": "code",
        "outputId": "d008d924-4b83-43a6-cbf7-6eaa5dee2d3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "frames = []\n",
        "for i_episode in range(EPISODE_SIZE):\n",
        "    # 환경과 상태 초기화\n",
        "    obv = env.reset()\n",
        "    total_actor_loss = 0\n",
        "    total_critic_loss = 0\n",
        "    global steps_done\n",
        "    top_reward = -1\n",
        "    total_action_count = [0,0,0]\n",
        "    for t in count():\n",
        "        if i_episode % RECORD_INTERVAL == 0:\n",
        "          frames.append(env.render(mode=\"rgb_array\"))\n",
        "        # 행동 선택과 수행\n",
        "        action = select_action(obv)\n",
        "        next_obv, reward, done, _ = env.step(np.argmax(action))\n",
        "        total_action_count[np.argmax(action)] += 1\n",
        "        reward  = obv[0] + 1.0\n",
        "        if reward > top_reward:\n",
        "          top_reward = reward\n",
        "        if done :\n",
        "          if t != 199:\n",
        "            reward += 100\n",
        "            print('success')\n",
        "\n",
        "        # 메모리에 변이 저장\n",
        "        assert obv is not None\n",
        "        memory.store(obv, action, reward, next_obv, done)\n",
        "\n",
        "        # 다음 상태로 이동\n",
        "        obv = next_obv\n",
        "\n",
        "        # 최적화 한단계 수행(목표 네트워크에서)\n",
        "        actor_loss, critic_loss = optimize_model()\n",
        "        total_actor_loss += actor_loss\n",
        "        total_critic_loss += critic_loss\n",
        "        if done:\n",
        "            E = eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "            math.exp(-1. * steps_done / EPS_DECAY)\n",
        "            episode_durations.append(t + 1)\n",
        "            print('%d episode , %d step , %.2f Actor Loss, %.2f Critic Loss,  %.2f Threshold , %.2f Top reward'\\\n",
        "                  %(i_episode,t+1,total_actor_loss/(t+1), total_critic_loss/(t+1) ,E, top_reward))\n",
        "            print(total_action_count)\n",
        "            plot_durations()\n",
        "            total_actor_loss = 0\n",
        "            total_critic_loss = 0\n",
        "            top_reward = 0\n",
        "            total_action_count = [0,0,0]\n",
        "            break\n",
        "    #목표 네트워크 업데이트, 모든 웨이트와 바이어스 복사\n",
        "    if i_episode % TARGET_UPDATE == 0:\n",
        "        actor_target.load_state_dict(actor.state_dict())\n",
        "        critic_target.load_state_dict(critic.state_dict())\n",
        "print('Complete')\n",
        "env.render()\n",
        "env.close()\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 episode , 200 step , -1.00 Actor Loss, -1.00 Critic Loss,  0.82 Threshold , 0.58 Top reward\n",
            "[93, 53, 54]\n",
            "1 episode , 200 step , 0.04 Actor Loss, -0.27 Critic Loss,  0.75 Threshold , 0.58 Top reward\n",
            "[76, 56, 68]\n",
            "2 episode , 200 step , 0.73 Actor Loss, 0.00 Critic Loss,  0.68 Threshold , 0.61 Top reward\n",
            "[44, 48, 108]\n",
            "3 episode , 200 step , 1.09 Actor Loss, 0.00 Critic Loss,  0.62 Threshold , 0.69 Top reward\n",
            "[47, 38, 115]\n",
            "4 episode , 200 step , 1.49 Actor Loss, 0.00 Critic Loss,  0.57 Threshold , 0.62 Top reward\n",
            "[38, 49, 113]\n",
            "5 episode , 200 step , 1.92 Actor Loss, 0.00 Critic Loss,  0.52 Threshold , 0.70 Top reward\n",
            "[36, 34, 130]\n",
            "6 episode , 200 step , 2.38 Actor Loss, 0.01 Critic Loss,  0.47 Threshold , 0.66 Top reward\n",
            "[26, 39, 135]\n",
            "7 episode , 200 step , 2.84 Actor Loss, 0.01 Critic Loss,  0.43 Threshold , 0.69 Top reward\n",
            "[30, 34, 136]\n",
            "8 episode , 200 step , 3.30 Actor Loss, 0.01 Critic Loss,  0.40 Threshold , 0.80 Top reward\n",
            "[25, 25, 150]\n",
            "9 episode , 200 step , 3.72 Actor Loss, 0.01 Critic Loss,  0.36 Threshold , 0.70 Top reward\n",
            "[116, 30, 54]\n",
            "10 episode , 200 step , 4.09 Actor Loss, 0.02 Critic Loss,  0.33 Threshold , 0.58 Top reward\n",
            "[154, 17, 29]\n",
            "11 episode , 200 step , 4.72 Actor Loss, 0.02 Critic Loss,  0.31 Threshold , 0.52 Top reward\n",
            "[156, 27, 17]\n",
            "12 episode , 200 step , 5.00 Actor Loss, 0.02 Critic Loss,  0.28 Threshold , 0.59 Top reward\n",
            "[160, 19, 21]\n",
            "13 episode , 200 step , 5.27 Actor Loss, 0.02 Critic Loss,  0.26 Threshold , 0.56 Top reward\n",
            "[158, 19, 23]\n",
            "14 episode , 200 step , 5.52 Actor Loss, 0.03 Critic Loss,  0.24 Threshold , 0.53 Top reward\n",
            "[163, 21, 16]\n",
            "15 episode , 200 step , 5.76 Actor Loss, 0.03 Critic Loss,  0.22 Threshold , 0.59 Top reward\n",
            "[171, 19, 10]\n",
            "16 episode , 200 step , 5.99 Actor Loss, 0.02 Critic Loss,  0.21 Threshold , 0.56 Top reward\n",
            "[169, 16, 15]\n",
            "17 episode , 200 step , 6.24 Actor Loss, 0.03 Critic Loss,  0.19 Threshold , 0.56 Top reward\n",
            "[175, 14, 11]\n",
            "18 episode , 200 step , 6.46 Actor Loss, 0.03 Critic Loss,  0.18 Threshold , 0.48 Top reward\n",
            "[178, 12, 10]\n",
            "19 episode , 200 step , 6.68 Actor Loss, 0.03 Critic Loss,  0.17 Threshold , 0.47 Top reward\n",
            "[175, 13, 12]\n",
            "20 episode , 200 step , 6.89 Actor Loss, 0.03 Critic Loss,  0.15 Threshold , 0.48 Top reward\n",
            "[178, 13, 9]\n",
            "21 episode , 200 step , 7.23 Actor Loss, 0.03 Critic Loss,  0.14 Threshold , 0.46 Top reward\n",
            "[183, 10, 7]\n",
            "22 episode , 200 step , 7.43 Actor Loss, 0.04 Critic Loss,  0.14 Threshold , 0.53 Top reward\n",
            "[160, 31, 9]\n",
            "23 episode , 200 step , 7.62 Actor Loss, 0.03 Critic Loss,  0.13 Threshold , 0.58 Top reward\n",
            "[178, 9, 13]\n",
            "24 episode , 200 step , 7.78 Actor Loss, 0.04 Critic Loss,  0.12 Threshold , 0.60 Top reward\n",
            "[181, 7, 12]\n",
            "25 episode , 200 step , 7.97 Actor Loss, 0.04 Critic Loss,  0.11 Threshold , 0.57 Top reward\n",
            "[179, 11, 10]\n",
            "26 episode , 200 step , 8.08 Actor Loss, 0.04 Critic Loss,  0.11 Threshold , 0.61 Top reward\n",
            "[186, 9, 5]\n",
            "27 episode , 200 step , 8.31 Actor Loss, 0.04 Critic Loss,  0.10 Threshold , 0.55 Top reward\n",
            "[186, 8, 6]\n",
            "28 episode , 200 step , 8.48 Actor Loss, 0.04 Critic Loss,  0.10 Threshold , 0.44 Top reward\n",
            "[192, 7, 1]\n",
            "29 episode , 200 step , 8.65 Actor Loss, 0.04 Critic Loss,  0.09 Threshold , 0.59 Top reward\n",
            "[187, 6, 7]\n",
            "30 episode , 200 step , 8.83 Actor Loss, 0.05 Critic Loss,  0.09 Threshold , 0.54 Top reward\n",
            "[186, 6, 8]\n",
            "31 episode , 200 step , 9.26 Actor Loss, 0.05 Critic Loss,  0.08 Threshold , 0.51 Top reward\n",
            "[187, 7, 6]\n",
            "32 episode , 200 step , 9.45 Actor Loss, 0.04 Critic Loss,  0.08 Threshold , 0.46 Top reward\n",
            "[187, 9, 4]\n",
            "33 episode , 200 step , 9.61 Actor Loss, 0.05 Critic Loss,  0.08 Threshold , 0.50 Top reward\n",
            "[187, 4, 9]\n",
            "34 episode , 200 step , 9.78 Actor Loss, 0.05 Critic Loss,  0.08 Threshold , 0.56 Top reward\n",
            "[189, 4, 7]\n",
            "35 episode , 200 step , 9.93 Actor Loss, 0.05 Critic Loss,  0.07 Threshold , 0.46 Top reward\n",
            "[198, 1, 1]\n",
            "36 episode , 200 step , 10.11 Actor Loss, 0.05 Critic Loss,  0.07 Threshold , 0.45 Top reward\n",
            "[188, 7, 5]\n",
            "37 episode , 200 step , 10.23 Actor Loss, 0.05 Critic Loss,  0.07 Threshold , 0.45 Top reward\n",
            "[185, 5, 10]\n",
            "38 episode , 200 step , 10.41 Actor Loss, 0.05 Critic Loss,  0.07 Threshold , 0.48 Top reward\n",
            "[195, 2, 3]\n",
            "39 episode , 200 step , 10.56 Actor Loss, 0.06 Critic Loss,  0.07 Threshold , 0.56 Top reward\n",
            "[192, 4, 4]\n",
            "40 episode , 200 step , 10.73 Actor Loss, 0.06 Critic Loss,  0.06 Threshold , 0.49 Top reward\n",
            "[188, 6, 6]\n",
            "41 episode , 200 step , 11.04 Actor Loss, 0.06 Critic Loss,  0.06 Threshold , 0.58 Top reward\n",
            "[193, 5, 2]\n",
            "42 episode , 200 step , 11.21 Actor Loss, 0.06 Critic Loss,  0.06 Threshold , 0.50 Top reward\n",
            "[183, 9, 8]\n",
            "43 episode , 200 step , 11.35 Actor Loss, 0.07 Critic Loss,  0.06 Threshold , 0.57 Top reward\n",
            "[190, 4, 6]\n",
            "44 episode , 200 step , 11.48 Actor Loss, 0.07 Critic Loss,  0.06 Threshold , 0.55 Top reward\n",
            "[192, 2, 6]\n",
            "45 episode , 200 step , 11.61 Actor Loss, 0.06 Critic Loss,  0.06 Threshold , 0.46 Top reward\n",
            "[187, 11, 2]\n",
            "46 episode , 200 step , 11.72 Actor Loss, 0.06 Critic Loss,  0.06 Threshold , 0.41 Top reward\n",
            "[170, 25, 5]\n",
            "47 episode , 200 step , 11.87 Actor Loss, 0.07 Critic Loss,  0.06 Threshold , 0.60 Top reward\n",
            "[182, 13, 5]\n",
            "48 episode , 200 step , 12.02 Actor Loss, 0.06 Critic Loss,  0.06 Threshold , 0.44 Top reward\n",
            "[195, 2, 3]\n",
            "49 episode , 200 step , 12.17 Actor Loss, 0.06 Critic Loss,  0.06 Threshold , 0.44 Top reward\n",
            "[191, 5, 4]\n",
            "50 episode , 200 step , 12.31 Actor Loss, 0.07 Critic Loss,  0.06 Threshold , 0.58 Top reward\n",
            "[189, 10, 1]\n",
            "51 episode , 200 step , 12.60 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.50 Top reward\n",
            "[188, 4, 8]\n",
            "52 episode , 200 step , 12.77 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.49 Top reward\n",
            "[195, 1, 4]\n",
            "53 episode , 200 step , 12.93 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.49 Top reward\n",
            "[191, 5, 4]\n",
            "54 episode , 200 step , 13.10 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.57 Top reward\n",
            "[195, 3, 2]\n",
            "55 episode , 200 step , 13.26 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.46 Top reward\n",
            "[195, 1, 4]\n",
            "56 episode , 200 step , 13.44 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.55 Top reward\n",
            "[194, 4, 2]\n",
            "57 episode , 200 step , 13.60 Actor Loss, 0.06 Critic Loss,  0.05 Threshold , 0.48 Top reward\n",
            "[190, 5, 5]\n",
            "58 episode , 200 step , 13.77 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.59 Top reward\n",
            "[191, 5, 4]\n",
            "59 episode , 200 step , 13.92 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.45 Top reward\n",
            "[194, 2, 4]\n",
            "60 episode , 200 step , 14.10 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.53 Top reward\n",
            "[194, 2, 4]\n",
            "61 episode , 200 step , 14.49 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.62 Top reward\n",
            "[193, 4, 3]\n",
            "62 episode , 200 step , 14.64 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.65 Top reward\n",
            "[194, 3, 3]\n",
            "63 episode , 200 step , 14.80 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.51 Top reward\n",
            "[197, 1, 2]\n",
            "64 episode , 200 step , 14.96 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.45 Top reward\n",
            "[195, 3, 2]\n",
            "65 episode , 200 step , 15.13 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.44 Top reward\n",
            "[191, 3, 6]\n",
            "66 episode , 200 step , 15.30 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.50 Top reward\n",
            "[192, 1, 7]\n",
            "67 episode , 200 step , 15.46 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.55 Top reward\n",
            "[191, 7, 2]\n",
            "68 episode , 200 step , 15.61 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.42 Top reward\n",
            "[193, 2, 5]\n",
            "69 episode , 200 step , 15.77 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.42 Top reward\n",
            "[195, 3, 2]\n",
            "70 episode , 200 step , 15.91 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.51 Top reward\n",
            "[192, 3, 5]\n",
            "71 episode , 200 step , 16.24 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.48 Top reward\n",
            "[191, 5, 4]\n",
            "72 episode , 200 step , 16.39 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.46 Top reward\n",
            "[193, 4, 3]\n",
            "73 episode , 200 step , 16.53 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.59 Top reward\n",
            "[189, 4, 7]\n",
            "74 episode , 200 step , 16.67 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.56 Top reward\n",
            "[191, 6, 3]\n",
            "75 episode , 200 step , 16.81 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.44 Top reward\n",
            "[191, 5, 4]\n",
            "76 episode , 200 step , 16.95 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.50 Top reward\n",
            "[193, 3, 4]\n",
            "77 episode , 200 step , 17.08 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.53 Top reward\n",
            "[195, 2, 3]\n",
            "78 episode , 200 step , 17.22 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.53 Top reward\n",
            "[197, 1, 2]\n",
            "79 episode , 200 step , 17.35 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.63 Top reward\n",
            "[194, 3, 3]\n",
            "80 episode , 200 step , 17.50 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.48 Top reward\n",
            "[196, 3, 1]\n",
            "81 episode , 200 step , 17.74 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.47 Top reward\n",
            "[192, 2, 6]\n",
            "82 episode , 200 step , 17.86 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.63 Top reward\n",
            "[189, 6, 5]\n",
            "83 episode , 200 step , 17.99 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.55 Top reward\n",
            "[191, 6, 3]\n",
            "84 episode , 200 step , 18.11 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.60 Top reward\n",
            "[186, 7, 7]\n",
            "85 episode , 200 step , 18.22 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.46 Top reward\n",
            "[197, 0, 3]\n",
            "86 episode , 200 step , 18.36 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.62 Top reward\n",
            "[189, 5, 6]\n",
            "87 episode , 200 step , 18.47 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.44 Top reward\n",
            "[192, 3, 5]\n",
            "88 episode , 200 step , 18.60 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.41 Top reward\n",
            "[192, 4, 4]\n",
            "89 episode , 200 step , 18.72 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.60 Top reward\n",
            "[191, 4, 5]\n",
            "90 episode , 200 step , 18.83 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.47 Top reward\n",
            "[196, 1, 3]\n",
            "91 episode , 200 step , 19.07 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.42 Top reward\n",
            "[192, 5, 3]\n",
            "92 episode , 200 step , 19.18 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.42 Top reward\n",
            "[191, 6, 3]\n",
            "93 episode , 200 step , 19.31 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.44 Top reward\n",
            "[191, 6, 3]\n",
            "94 episode , 200 step , 19.41 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.50 Top reward\n",
            "[192, 3, 5]\n",
            "95 episode , 200 step , 19.52 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.52 Top reward\n",
            "[197, 3, 0]\n",
            "96 episode , 200 step , 19.62 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.45 Top reward\n",
            "[194, 3, 3]\n",
            "97 episode , 200 step , 19.74 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.60 Top reward\n",
            "[193, 4, 3]\n",
            "98 episode , 200 step , 19.85 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.42 Top reward\n",
            "[192, 5, 3]\n",
            "99 episode , 200 step , 19.95 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.48 Top reward\n",
            "[195, 3, 2]\n",
            "100 episode , 200 step , 20.07 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.71 Top reward\n",
            "[184, 1, 15]\n",
            "101 episode , 200 step , 20.24 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.48 Top reward\n",
            "[194, 6, 0]\n",
            "102 episode , 200 step , 20.34 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.49 Top reward\n",
            "[189, 7, 4]\n",
            "103 episode , 200 step , 20.45 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.52 Top reward\n",
            "[195, 3, 2]\n",
            "104 episode , 200 step , 20.55 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.42 Top reward\n",
            "[195, 2, 3]\n",
            "105 episode , 200 step , 20.66 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.63 Top reward\n",
            "[193, 2, 5]\n",
            "106 episode , 200 step , 20.76 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.43 Top reward\n",
            "[193, 2, 5]\n",
            "107 episode , 200 step , 20.85 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.52 Top reward\n",
            "[194, 3, 3]\n",
            "108 episode , 200 step , 20.97 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.48 Top reward\n",
            "[191, 3, 6]\n",
            "109 episode , 200 step , 21.06 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.55 Top reward\n",
            "[188, 6, 6]\n",
            "110 episode , 200 step , 21.15 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.58 Top reward\n",
            "[196, 3, 1]\n",
            "111 episode , 200 step , 21.34 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.57 Top reward\n",
            "[191, 7, 2]\n",
            "112 episode , 200 step , 21.42 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.50 Top reward\n",
            "[195, 3, 2]\n",
            "113 episode , 200 step , 21.51 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.53 Top reward\n",
            "[195, 4, 1]\n",
            "114 episode , 200 step , 21.59 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.48 Top reward\n",
            "[197, 2, 1]\n",
            "115 episode , 200 step , 21.68 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.59 Top reward\n",
            "[194, 3, 3]\n",
            "116 episode , 200 step , 21.73 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.54 Top reward\n",
            "[195, 3, 2]\n",
            "117 episode , 200 step , 21.84 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.49 Top reward\n",
            "[194, 4, 2]\n",
            "118 episode , 200 step , 21.89 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.57 Top reward\n",
            "[188, 10, 2]\n",
            "119 episode , 200 step , 21.97 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.59 Top reward\n",
            "[194, 1, 5]\n",
            "120 episode , 200 step , 22.03 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.43 Top reward\n",
            "[198, 2, 0]\n",
            "121 episode , 200 step , 22.22 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.48 Top reward\n",
            "[195, 4, 1]\n",
            "122 episode , 200 step , 22.28 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.52 Top reward\n",
            "[192, 3, 5]\n",
            "123 episode , 200 step , 22.36 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.58 Top reward\n",
            "[188, 7, 5]\n",
            "124 episode , 200 step , 22.45 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.58 Top reward\n",
            "[195, 3, 2]\n",
            "125 episode , 200 step , 22.51 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.53 Top reward\n",
            "[194, 2, 4]\n",
            "126 episode , 200 step , 22.59 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.45 Top reward\n",
            "[195, 4, 1]\n",
            "127 episode , 200 step , 22.66 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.46 Top reward\n",
            "[195, 3, 2]\n",
            "128 episode , 200 step , 22.73 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.45 Top reward\n",
            "[195, 3, 2]\n",
            "129 episode , 200 step , 22.82 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.53 Top reward\n",
            "[192, 6, 2]\n",
            "130 episode , 200 step , 22.89 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.52 Top reward\n",
            "[193, 2, 5]\n",
            "131 episode , 200 step , 23.02 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.58 Top reward\n",
            "[195, 3, 2]\n",
            "132 episode , 200 step , 23.07 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.54 Top reward\n",
            "[196, 1, 3]\n",
            "133 episode , 200 step , 23.15 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.52 Top reward\n",
            "[193, 3, 4]\n",
            "134 episode , 200 step , 23.22 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.45 Top reward\n",
            "[191, 6, 3]\n",
            "135 episode , 200 step , 23.30 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.43 Top reward\n",
            "[193, 2, 5]\n",
            "136 episode , 200 step , 23.39 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.45 Top reward\n",
            "[194, 0, 6]\n",
            "137 episode , 200 step , 23.43 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.60 Top reward\n",
            "[192, 5, 3]\n",
            "138 episode , 200 step , 23.50 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.44 Top reward\n",
            "[196, 2, 2]\n",
            "139 episode , 200 step , 23.57 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.47 Top reward\n",
            "[195, 2, 3]\n",
            "140 episode , 200 step , 23.64 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.50 Top reward\n",
            "[193, 3, 4]\n",
            "141 episode , 200 step , 23.71 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 0.47 Top reward\n",
            "[195, 4, 1]\n",
            "142 episode , 200 step , 23.77 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.58 Top reward\n",
            "[193, 6, 1]\n",
            "143 episode , 200 step , 23.79 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.52 Top reward\n",
            "[194, 3, 3]\n",
            "144 episode , 200 step , 23.83 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.44 Top reward\n",
            "[198, 1, 1]\n",
            "145 episode , 200 step , 23.91 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.47 Top reward\n",
            "[193, 1, 6]\n",
            "146 episode , 200 step , 23.98 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.45 Top reward\n",
            "[193, 4, 3]\n",
            "147 episode , 200 step , 24.06 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.50 Top reward\n",
            "[193, 4, 3]\n",
            "148 episode , 200 step , 24.14 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.46 Top reward\n",
            "[194, 3, 3]\n",
            "149 episode , 200 step , 24.20 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.60 Top reward\n",
            "[194, 4, 2]\n",
            "150 episode , 200 step , 24.26 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.42 Top reward\n",
            "[195, 2, 3]\n",
            "151 episode , 200 step , 24.38 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.47 Top reward\n",
            "[191, 2, 7]\n",
            "152 episode , 200 step , 24.43 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.57 Top reward\n",
            "[195, 3, 2]\n",
            "153 episode , 200 step , 24.47 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.44 Top reward\n",
            "[191, 7, 2]\n",
            "154 episode , 200 step , 24.56 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.48 Top reward\n",
            "[193, 5, 2]\n",
            "155 episode , 200 step , 24.61 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 0.56 Top reward\n",
            "[194, 4, 2]\n",
            "156 episode , 200 step , 24.68 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.45 Top reward\n",
            "[190, 4, 6]\n",
            "157 episode , 200 step , 24.74 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.45 Top reward\n",
            "[190, 5, 5]\n",
            "158 episode , 200 step , 24.82 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.46 Top reward\n",
            "[191, 6, 3]\n",
            "159 episode , 200 step , 24.86 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 0.55 Top reward\n",
            "[191, 3, 6]\n",
            "160 episode , 200 step , 24.91 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.59 Top reward\n",
            "[194, 2, 4]\n",
            "161 episode , 200 step , 25.01 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 0.45 Top reward\n",
            "[196, 3, 1]\n",
            "162 episode , 200 step , 25.07 Actor Loss, 0.15 Critic Loss,  0.05 Threshold , 0.51 Top reward\n",
            "[189, 5, 6]\n",
            "163 episode , 200 step , 25.02 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.43 Top reward\n",
            "[193, 2, 5]\n",
            "164 episode , 200 step , 24.83 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.41 Top reward\n",
            "[194, 4, 2]\n",
            "165 episode , 200 step , 24.75 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.51 Top reward\n",
            "[195, 3, 2]\n",
            "166 episode , 200 step , 24.82 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.57 Top reward\n",
            "[198, 1, 1]\n",
            "167 episode , 200 step , 24.85 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.62 Top reward\n",
            "[196, 0, 4]\n",
            "168 episode , 200 step , 24.87 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.59 Top reward\n",
            "[194, 1, 5]\n",
            "169 episode , 200 step , 24.91 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 0.43 Top reward\n",
            "[194, 3, 3]\n",
            "170 episode , 200 step , 24.97 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.62 Top reward\n",
            "[193, 2, 5]\n",
            "171 episode , 200 step , 24.99 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 0.46 Top reward\n",
            "[193, 5, 2]\n",
            "172 episode , 200 step , 25.06 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 0.53 Top reward\n",
            "[195, 5, 0]\n",
            "173 episode , 200 step , 25.11 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.50 Top reward\n",
            "[193, 1, 6]\n",
            "174 episode , 200 step , 25.16 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 0.54 Top reward\n",
            "[194, 3, 3]\n",
            "175 episode , 200 step , 25.23 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.48 Top reward\n",
            "[192, 4, 4]\n",
            "176 episode , 200 step , 25.26 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 0.57 Top reward\n",
            "[189, 5, 6]\n",
            "177 episode , 200 step , 25.30 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.61 Top reward\n",
            "[193, 2, 5]\n",
            "178 episode , 200 step , 25.30 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 0.83 Top reward\n",
            "[160, 6, 34]\n",
            "179 episode , 200 step , 25.31 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.52 Top reward\n",
            "[196, 1, 3]\n",
            "180 episode , 200 step , 25.30 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.87 Top reward\n",
            "[60, 18, 122]\n",
            "181 episode , 200 step , 26.03 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[55, 48, 97]\n",
            "182 episode , 200 step , 26.14 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 0.57 Top reward\n",
            "[3, 185, 12]\n",
            "183 episode , 200 step , 26.23 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.52 Top reward\n",
            "[46, 142, 12]\n",
            "184 episode , 200 step , 26.31 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 1.22 Top reward\n",
            "[152, 22, 26]\n",
            "185 episode , 200 step , 26.24 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 1.14 Top reward\n",
            "[149, 27, 24]\n",
            "success\n",
            "186 episode , 116 step , 26.04 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 1.50 Top reward\n",
            "[43, 6, 67]\n",
            "187 episode , 200 step , 26.22 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[84, 2, 114]\n",
            "188 episode , 200 step , 26.42 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.50 Top reward\n",
            "[199, 1, 0]\n",
            "189 episode , 200 step , 26.48 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.56 Top reward\n",
            "[186, 5, 9]\n",
            "190 episode , 200 step , 26.46 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.46 Top reward\n",
            "[193, 5, 2]\n",
            "191 episode , 200 step , 26.56 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.52 Top reward\n",
            "[190, 4, 6]\n",
            "192 episode , 200 step , 26.61 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 0.43 Top reward\n",
            "[195, 1, 4]\n",
            "193 episode , 200 step , 26.70 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 0.41 Top reward\n",
            "[196, 1, 3]\n",
            "194 episode , 200 step , 26.74 Actor Loss, 0.15 Critic Loss,  0.05 Threshold , 0.43 Top reward\n",
            "[194, 4, 2]\n",
            "195 episode , 200 step , 26.76 Actor Loss, 0.15 Critic Loss,  0.05 Threshold , 0.63 Top reward\n",
            "[195, 1, 4]\n",
            "196 episode , 200 step , 26.79 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.54 Top reward\n",
            "[198, 2, 0]\n",
            "197 episode , 200 step , 26.82 Actor Loss, 0.15 Critic Loss,  0.05 Threshold , 0.51 Top reward\n",
            "[193, 4, 3]\n",
            "198 episode , 200 step , 26.85 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 0.57 Top reward\n",
            "[195, 2, 3]\n",
            "199 episode , 200 step , 26.58 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 0.68 Top reward\n",
            "[77, 6, 117]\n",
            "200 episode , 200 step , 26.53 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 1.19 Top reward\n",
            "[138, 1, 61]\n",
            "201 episode , 200 step , 26.45 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 1.15 Top reward\n",
            "[156, 4, 40]\n",
            "success\n",
            "202 episode , 157 step , 26.31 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 1.48 Top reward\n",
            "[104, 9, 44]\n",
            "success\n",
            "203 episode , 147 step , 26.20 Actor Loss, 0.15 Critic Loss,  0.05 Threshold , 1.49 Top reward\n",
            "[81, 3, 63]\n",
            "204 episode , 200 step , 26.17 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[148, 7, 45]\n",
            "205 episode , 200 step , 26.14 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 0.46 Top reward\n",
            "[191, 5, 4]\n",
            "206 episode , 200 step , 26.14 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.47 Top reward\n",
            "[189, 7, 4]\n",
            "207 episode , 200 step , 26.11 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 0.43 Top reward\n",
            "[196, 0, 4]\n",
            "208 episode , 200 step , 26.06 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.87 Top reward\n",
            "[175, 2, 23]\n",
            "209 episode , 200 step , 25.99 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 0.49 Top reward\n",
            "[195, 2, 3]\n",
            "210 episode , 200 step , 26.00 Actor Loss, 0.15 Critic Loss,  0.05 Threshold , 0.57 Top reward\n",
            "[193, 1, 6]\n",
            "211 episode , 200 step , 25.87 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.52 Top reward\n",
            "[197, 1, 2]\n",
            "success\n",
            "212 episode , 168 step , 25.84 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 1.47 Top reward\n",
            "[119, 4, 45]\n",
            "213 episode , 200 step , 25.80 Actor Loss, 0.15 Critic Loss,  0.05 Threshold , 0.56 Top reward\n",
            "[189, 4, 7]\n",
            "success\n",
            "214 episode , 162 step , 25.67 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 1.49 Top reward\n",
            "[108, 9, 45]\n",
            "215 episode , 200 step , 25.55 Actor Loss, 0.15 Critic Loss,  0.05 Threshold , 1.37 Top reward\n",
            "[159, 7, 34]\n",
            "success\n",
            "216 episode , 155 step , 25.41 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 1.48 Top reward\n",
            "[91, 15, 49]\n",
            "success\n",
            "217 episode , 161 step , 25.27 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 1.49 Top reward\n",
            "[104, 11, 46]\n",
            "success\n",
            "218 episode , 156 step , 25.22 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 1.49 Top reward\n",
            "[102, 9, 45]\n",
            "success\n",
            "219 episode , 160 step , 25.12 Actor Loss, 0.18 Critic Loss,  0.05 Threshold , 1.48 Top reward\n",
            "[105, 9, 46]\n",
            "220 episode , 200 step , 25.08 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 1.46 Top reward\n",
            "[144, 13, 43]\n",
            "221 episode , 200 step , 24.80 Actor Loss, 0.19 Critic Loss,  0.05 Threshold , 0.93 Top reward\n",
            "[165, 19, 16]\n",
            "222 episode , 200 step , 24.56 Actor Loss, 0.18 Critic Loss,  0.05 Threshold , 1.11 Top reward\n",
            "[167, 8, 25]\n",
            "223 episode , 200 step , 24.45 Actor Loss, 0.18 Critic Loss,  0.05 Threshold , 1.07 Top reward\n",
            "[160, 12, 28]\n",
            "224 episode , 200 step , 24.33 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 0.92 Top reward\n",
            "[164, 21, 15]\n",
            "225 episode , 200 step , 24.23 Actor Loss, 0.19 Critic Loss,  0.05 Threshold , 0.90 Top reward\n",
            "[165, 25, 10]\n",
            "226 episode , 200 step , 24.06 Actor Loss, 0.18 Critic Loss,  0.05 Threshold , 0.44 Top reward\n",
            "[188, 4, 8]\n",
            "227 episode , 200 step , 24.09 Actor Loss, 0.20 Critic Loss,  0.05 Threshold , 0.56 Top reward\n",
            "[189, 7, 4]\n",
            "228 episode , 200 step , 24.02 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 0.59 Top reward\n",
            "[182, 13, 5]\n",
            "229 episode , 200 step , 24.04 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[183, 13, 4]\n",
            "230 episode , 200 step , 24.00 Actor Loss, 0.18 Critic Loss,  0.05 Threshold , 0.49 Top reward\n",
            "[192, 3, 5]\n",
            "231 episode , 200 step , 23.88 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 0.58 Top reward\n",
            "[193, 3, 4]\n",
            "232 episode , 200 step , 23.85 Actor Loss, 0.18 Critic Loss,  0.05 Threshold , 0.47 Top reward\n",
            "[190, 9, 1]\n",
            "233 episode , 200 step , 23.78 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 0.56 Top reward\n",
            "[196, 1, 3]\n",
            "234 episode , 200 step , 23.80 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 0.49 Top reward\n",
            "[193, 3, 4]\n",
            "235 episode , 200 step , 23.73 Actor Loss, 0.18 Critic Loss,  0.05 Threshold , 0.56 Top reward\n",
            "[195, 3, 2]\n",
            "236 episode , 200 step , 23.70 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 0.52 Top reward\n",
            "[192, 3, 5]\n",
            "237 episode , 200 step , 23.78 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 0.45 Top reward\n",
            "[197, 2, 1]\n",
            "238 episode , 200 step , 23.91 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 0.45 Top reward\n",
            "[193, 3, 4]\n",
            "239 episode , 200 step , 23.96 Actor Loss, 0.15 Critic Loss,  0.05 Threshold , 0.60 Top reward\n",
            "[191, 6, 3]\n",
            "240 episode , 200 step , 23.96 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 0.44 Top reward\n",
            "[190, 5, 5]\n",
            "241 episode , 200 step , 23.98 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 0.53 Top reward\n",
            "[198, 1, 1]\n",
            "242 episode , 200 step , 23.90 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 0.62 Top reward\n",
            "[191, 1, 8]\n",
            "243 episode , 200 step , 23.85 Actor Loss, 0.18 Critic Loss,  0.05 Threshold , 0.53 Top reward\n",
            "[193, 5, 2]\n",
            "244 episode , 200 step , 23.72 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 0.72 Top reward\n",
            "[133, 38, 29]\n",
            "245 episode , 200 step , 23.64 Actor Loss, 0.18 Critic Loss,  0.05 Threshold , 0.88 Top reward\n",
            "[141, 22, 37]\n",
            "246 episode , 200 step , 23.45 Actor Loss, 0.18 Critic Loss,  0.05 Threshold , 0.93 Top reward\n",
            "[161, 10, 29]\n",
            "247 episode , 200 step , 23.25 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 0.41 Top reward\n",
            "[191, 3, 6]\n",
            "248 episode , 200 step , 23.14 Actor Loss, 0.18 Critic Loss,  0.05 Threshold , 1.01 Top reward\n",
            "[146, 34, 20]\n",
            "249 episode , 200 step , 22.87 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 1.04 Top reward\n",
            "[134, 39, 27]\n",
            "250 episode , 200 step , 22.70 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 0.56 Top reward\n",
            "[26, 99, 75]\n",
            "251 episode , 200 step , 22.48 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 1.00 Top reward\n",
            "[147, 22, 31]\n",
            "252 episode , 200 step , 22.31 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 0.94 Top reward\n",
            "[151, 28, 21]\n",
            "253 episode , 200 step , 22.22 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 0.99 Top reward\n",
            "[147, 14, 39]\n",
            "254 episode , 200 step , 22.06 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 1.04 Top reward\n",
            "[131, 12, 57]\n",
            "255 episode , 200 step , 21.82 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 1.02 Top reward\n",
            "[136, 16, 48]\n",
            "256 episode , 200 step , 21.62 Actor Loss, 0.15 Critic Loss,  0.05 Threshold , 1.01 Top reward\n",
            "[139, 10, 51]\n",
            "257 episode , 200 step , 21.39 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 0.99 Top reward\n",
            "[150, 4, 46]\n",
            "258 episode , 200 step , 21.07 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 0.99 Top reward\n",
            "[151, 6, 43]\n",
            "259 episode , 200 step , 20.90 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 0.99 Top reward\n",
            "[146, 5, 49]\n",
            "260 episode , 200 step , 20.76 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 0.98 Top reward\n",
            "[140, 7, 53]\n",
            "261 episode , 200 step , 20.45 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 1.00 Top reward\n",
            "[151, 8, 41]\n",
            "262 episode , 200 step , 20.28 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 0.95 Top reward\n",
            "[135, 27, 38]\n",
            "263 episode , 200 step , 20.10 Actor Loss, 0.17 Critic Loss,  0.05 Threshold , 1.00 Top reward\n",
            "[144, 19, 37]\n",
            "264 episode , 200 step , 20.00 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 0.94 Top reward\n",
            "[108, 64, 28]\n",
            "265 episode , 200 step , 19.88 Actor Loss, 0.16 Critic Loss,  0.05 Threshold , 0.95 Top reward\n",
            "[130, 33, 37]\n",
            "266 episode , 200 step , 19.76 Actor Loss, 0.15 Critic Loss,  0.05 Threshold , 0.95 Top reward\n",
            "[135, 25, 40]\n",
            "267 episode , 200 step , 19.72 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.94 Top reward\n",
            "[139, 20, 41]\n",
            "268 episode , 200 step , 19.68 Actor Loss, 0.14 Critic Loss,  0.05 Threshold , 0.93 Top reward\n",
            "[151, 21, 28]\n",
            "269 episode , 200 step , 19.59 Actor Loss, 0.13 Critic Loss,  0.05 Threshold , 0.90 Top reward\n",
            "[154, 18, 28]\n",
            "270 episode , 200 step , 19.56 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[168, 14, 18]\n",
            "271 episode , 200 step , 19.63 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.72 Top reward\n",
            "[173, 13, 14]\n",
            "272 episode , 200 step , 19.66 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.70 Top reward\n",
            "[190, 5, 5]\n",
            "273 episode , 200 step , 19.74 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.72 Top reward\n",
            "[179, 11, 10]\n",
            "274 episode , 200 step , 19.76 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.69 Top reward\n",
            "[182, 5, 13]\n",
            "275 episode , 200 step , 19.82 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.67 Top reward\n",
            "[175, 17, 8]\n",
            "276 episode , 200 step , 19.80 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.70 Top reward\n",
            "[173, 12, 15]\n",
            "277 episode , 200 step , 19.74 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.71 Top reward\n",
            "[175, 17, 8]\n",
            "278 episode , 200 step , 19.74 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.67 Top reward\n",
            "[186, 8, 6]\n",
            "279 episode , 200 step , 19.66 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.70 Top reward\n",
            "[188, 5, 7]\n",
            "280 episode , 200 step , 19.67 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.67 Top reward\n",
            "[167, 19, 14]\n",
            "281 episode , 200 step , 19.72 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.66 Top reward\n",
            "[169, 25, 6]\n",
            "282 episode , 200 step , 19.65 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 0.63 Top reward\n",
            "[182, 14, 4]\n",
            "283 episode , 200 step , 19.55 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.59 Top reward\n",
            "[182, 14, 4]\n",
            "284 episode , 200 step , 19.54 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.60 Top reward\n",
            "[189, 11, 0]\n",
            "285 episode , 200 step , 19.54 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.64 Top reward\n",
            "[184, 13, 3]\n",
            "286 episode , 200 step , 19.47 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.59 Top reward\n",
            "[182, 7, 11]\n",
            "287 episode , 200 step , 19.46 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.87 Top reward\n",
            "[166, 12, 22]\n",
            "288 episode , 200 step , 19.32 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.98 Top reward\n",
            "[165, 10, 25]\n",
            "289 episode , 200 step , 19.28 Actor Loss, 0.12 Critic Loss,  0.05 Threshold , 1.01 Top reward\n",
            "[169, 1, 30]\n",
            "290 episode , 200 step , 19.15 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 1.04 Top reward\n",
            "[165, 5, 30]\n",
            "291 episode , 200 step , 19.00 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 1.09 Top reward\n",
            "[166, 2, 32]\n",
            "292 episode , 200 step , 18.90 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 1.11 Top reward\n",
            "[161, 3, 36]\n",
            "293 episode , 200 step , 18.91 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 1.03 Top reward\n",
            "[165, 1, 34]\n",
            "294 episode , 200 step , 18.82 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.95 Top reward\n",
            "[172, 1, 27]\n",
            "295 episode , 200 step , 18.83 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 1.02 Top reward\n",
            "[173, 6, 21]\n",
            "296 episode , 200 step , 18.87 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.94 Top reward\n",
            "[170, 7, 23]\n",
            "297 episode , 200 step , 18.88 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.83 Top reward\n",
            "[172, 7, 21]\n",
            "298 episode , 200 step , 18.87 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[171, 13, 16]\n",
            "299 episode , 200 step , 18.90 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[177, 8, 15]\n",
            "300 episode , 200 step , 18.85 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[175, 13, 12]\n",
            "301 episode , 200 step , 18.91 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[172, 12, 16]\n",
            "302 episode , 200 step , 18.97 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.83 Top reward\n",
            "[155, 19, 26]\n",
            "303 episode , 200 step , 18.94 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[169, 15, 16]\n",
            "304 episode , 200 step , 18.99 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.85 Top reward\n",
            "[168, 15, 17]\n",
            "305 episode , 200 step , 19.02 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.84 Top reward\n",
            "[169, 11, 20]\n",
            "306 episode , 200 step , 19.05 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.86 Top reward\n",
            "[157, 17, 26]\n",
            "307 episode , 200 step , 19.10 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.83 Top reward\n",
            "[169, 9, 22]\n",
            "308 episode , 200 step , 19.19 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[172, 7, 21]\n",
            "309 episode , 200 step , 19.26 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.83 Top reward\n",
            "[168, 12, 20]\n",
            "310 episode , 200 step , 19.31 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.62 Top reward\n",
            "[185, 5, 10]\n",
            "311 episode , 200 step , 19.51 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.45 Top reward\n",
            "[197, 1, 2]\n",
            "312 episode , 200 step , 19.66 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.43 Top reward\n",
            "[183, 14, 3]\n",
            "313 episode , 200 step , 19.76 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[182, 5, 13]\n",
            "314 episode , 200 step , 19.83 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[176, 5, 19]\n",
            "315 episode , 200 step , 19.82 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.83 Top reward\n",
            "[182, 2, 16]\n",
            "316 episode , 200 step , 19.90 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.94 Top reward\n",
            "[164, 2, 34]\n",
            "317 episode , 200 step , 19.97 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.89 Top reward\n",
            "[169, 3, 28]\n",
            "318 episode , 200 step , 19.92 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.86 Top reward\n",
            "[169, 6, 25]\n",
            "319 episode , 200 step , 19.99 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[173, 6, 21]\n",
            "320 episode , 200 step , 19.94 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[177, 2, 21]\n",
            "321 episode , 200 step , 19.97 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[179, 4, 17]\n",
            "322 episode , 200 step , 19.96 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[178, 5, 17]\n",
            "323 episode , 200 step , 20.00 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[157, 9, 34]\n",
            "324 episode , 200 step , 19.96 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[178, 10, 12]\n",
            "325 episode , 200 step , 20.03 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[179, 11, 10]\n",
            "326 episode , 200 step , 19.99 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.70 Top reward\n",
            "[179, 9, 12]\n",
            "327 episode , 200 step , 20.02 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.70 Top reward\n",
            "[183, 6, 11]\n",
            "328 episode , 200 step , 20.04 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.72 Top reward\n",
            "[174, 5, 21]\n",
            "329 episode , 200 step , 20.00 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.90 Top reward\n",
            "[166, 16, 18]\n",
            "330 episode , 200 step , 20.02 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[173, 10, 17]\n",
            "331 episode , 200 step , 20.00 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[182, 12, 6]\n",
            "332 episode , 200 step , 19.93 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.86 Top reward\n",
            "[160, 25, 15]\n",
            "333 episode , 200 step , 19.89 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.87 Top reward\n",
            "[168, 25, 7]\n",
            "334 episode , 200 step , 19.78 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[166, 11, 23]\n",
            "335 episode , 200 step , 19.79 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.84 Top reward\n",
            "[181, 5, 14]\n",
            "336 episode , 200 step , 19.73 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.61 Top reward\n",
            "[186, 4, 10]\n",
            "337 episode , 200 step , 19.78 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.72 Top reward\n",
            "[181, 3, 16]\n",
            "338 episode , 200 step , 19.73 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.94 Top reward\n",
            "[164, 14, 22]\n",
            "339 episode , 200 step , 19.81 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.87 Top reward\n",
            "[171, 11, 18]\n",
            "340 episode , 200 step , 19.70 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[179, 13, 8]\n",
            "341 episode , 200 step , 19.69 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[181, 4, 15]\n",
            "342 episode , 200 step , 19.69 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.71 Top reward\n",
            "[180, 4, 16]\n",
            "343 episode , 200 step , 19.75 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[174, 7, 19]\n",
            "344 episode , 200 step , 19.79 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[178, 11, 11]\n",
            "345 episode , 200 step , 19.75 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.89 Top reward\n",
            "[164, 23, 13]\n",
            "346 episode , 200 step , 19.76 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[185, 6, 9]\n",
            "347 episode , 200 step , 19.78 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[183, 4, 13]\n",
            "348 episode , 200 step , 19.77 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[185, 1, 14]\n",
            "349 episode , 200 step , 19.77 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[179, 4, 17]\n",
            "350 episode , 200 step , 19.78 Actor Loss, 0.06 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[187, 4, 9]\n",
            "351 episode , 200 step , 19.86 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[185, 3, 12]\n",
            "352 episode , 200 step , 19.88 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[178, 8, 14]\n",
            "353 episode , 200 step , 19.90 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[182, 2, 16]\n",
            "354 episode , 200 step , 19.89 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[181, 4, 15]\n",
            "355 episode , 200 step , 20.00 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[176, 4, 20]\n",
            "356 episode , 200 step , 19.99 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[185, 0, 15]\n",
            "357 episode , 200 step , 19.95 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[177, 2, 21]\n",
            "358 episode , 200 step , 19.94 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[181, 2, 17]\n",
            "359 episode , 200 step , 19.94 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[182, 4, 14]\n",
            "360 episode , 200 step , 19.93 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[180, 5, 15]\n",
            "361 episode , 200 step , 19.77 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[177, 2, 21]\n",
            "362 episode , 200 step , 19.66 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[175, 4, 21]\n",
            "363 episode , 200 step , 19.57 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[178, 3, 19]\n",
            "364 episode , 200 step , 19.49 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.83 Top reward\n",
            "[170, 6, 24]\n",
            "365 episode , 200 step , 19.50 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.87 Top reward\n",
            "[175, 8, 17]\n",
            "366 episode , 200 step , 19.41 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.83 Top reward\n",
            "[177, 14, 9]\n",
            "367 episode , 200 step , 19.44 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[176, 3, 21]\n",
            "368 episode , 200 step , 19.41 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[178, 4, 18]\n",
            "369 episode , 200 step , 19.41 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[173, 3, 24]\n",
            "370 episode , 200 step , 19.39 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[181, 2, 17]\n",
            "371 episode , 200 step , 19.34 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.84 Top reward\n",
            "[160, 12, 28]\n",
            "372 episode , 200 step , 19.41 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[174, 13, 13]\n",
            "373 episode , 200 step , 19.33 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.83 Top reward\n",
            "[158, 13, 29]\n",
            "374 episode , 200 step , 19.24 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.98 Top reward\n",
            "[134, 33, 33]\n",
            "375 episode , 200 step , 19.27 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.99 Top reward\n",
            "[147, 40, 13]\n",
            "376 episode , 200 step , 19.26 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.96 Top reward\n",
            "[153, 29, 18]\n",
            "377 episode , 200 step , 19.19 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.95 Top reward\n",
            "[159, 29, 12]\n",
            "378 episode , 200 step , 19.12 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.92 Top reward\n",
            "[157, 29, 14]\n",
            "379 episode , 200 step , 19.01 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[160, 25, 15]\n",
            "380 episode , 200 step , 19.18 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[160, 33, 7]\n",
            "381 episode , 200 step , 19.06 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.92 Top reward\n",
            "[158, 29, 13]\n",
            "382 episode , 200 step , 19.04 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.87 Top reward\n",
            "[154, 35, 11]\n",
            "383 episode , 200 step , 19.03 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.89 Top reward\n",
            "[150, 43, 7]\n",
            "384 episode , 200 step , 19.04 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.93 Top reward\n",
            "[155, 33, 12]\n",
            "385 episode , 200 step , 18.99 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.89 Top reward\n",
            "[161, 24, 15]\n",
            "386 episode , 200 step , 18.97 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.89 Top reward\n",
            "[158, 24, 18]\n",
            "387 episode , 200 step , 18.88 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.43 Top reward\n",
            "[192, 6, 2]\n",
            "388 episode , 200 step , 18.92 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.90 Top reward\n",
            "[170, 5, 25]\n",
            "389 episode , 200 step , 18.93 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.92 Top reward\n",
            "[168, 8, 24]\n",
            "390 episode , 200 step , 18.94 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[176, 3, 21]\n",
            "391 episode , 200 step , 18.97 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.96 Top reward\n",
            "[165, 1, 34]\n",
            "392 episode , 200 step , 18.95 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 1.00 Top reward\n",
            "[162, 1, 37]\n",
            "393 episode , 200 step , 18.84 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.99 Top reward\n",
            "[164, 4, 32]\n",
            "394 episode , 200 step , 18.83 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.99 Top reward\n",
            "[161, 2, 37]\n",
            "395 episode , 200 step , 18.74 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.97 Top reward\n",
            "[165, 2, 33]\n",
            "396 episode , 200 step , 18.71 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.88 Top reward\n",
            "[164, 4, 32]\n",
            "397 episode , 200 step , 18.70 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.88 Top reward\n",
            "[169, 4, 27]\n",
            "398 episode , 200 step , 18.70 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.88 Top reward\n",
            "[136, 14, 50]\n",
            "399 episode , 200 step , 18.74 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.85 Top reward\n",
            "[124, 4, 72]\n",
            "400 episode , 200 step , 18.72 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.94 Top reward\n",
            "[139, 14, 47]\n",
            "401 episode , 200 step , 18.85 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.95 Top reward\n",
            "[150, 9, 41]\n",
            "402 episode , 200 step , 18.83 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.92 Top reward\n",
            "[152, 17, 31]\n",
            "403 episode , 200 step , 18.82 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.98 Top reward\n",
            "[133, 14, 53]\n",
            "404 episode , 200 step , 18.81 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.96 Top reward\n",
            "[145, 21, 34]\n",
            "405 episode , 200 step , 18.88 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.98 Top reward\n",
            "[126, 31, 43]\n",
            "406 episode , 200 step , 18.89 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 1.04 Top reward\n",
            "[109, 29, 62]\n",
            "407 episode , 200 step , 19.00 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 1.01 Top reward\n",
            "[121, 48, 31]\n",
            "408 episode , 200 step , 19.04 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.86 Top reward\n",
            "[153, 21, 26]\n",
            "409 episode , 200 step , 19.05 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.91 Top reward\n",
            "[141, 34, 25]\n",
            "410 episode , 200 step , 19.10 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.92 Top reward\n",
            "[146, 30, 24]\n",
            "411 episode , 200 step , 19.34 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.88 Top reward\n",
            "[160, 19, 21]\n",
            "412 episode , 200 step , 19.33 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.86 Top reward\n",
            "[174, 9, 17]\n",
            "413 episode , 200 step , 19.35 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[174, 9, 17]\n",
            "414 episode , 200 step , 19.39 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.83 Top reward\n",
            "[165, 18, 17]\n",
            "415 episode , 200 step , 19.39 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.89 Top reward\n",
            "[143, 22, 35]\n",
            "416 episode , 200 step , 19.45 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[158, 4, 38]\n",
            "417 episode , 200 step , 19.49 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[162, 15, 23]\n",
            "418 episode , 200 step , 19.52 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[165, 15, 20]\n",
            "419 episode , 200 step , 19.53 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[169, 8, 23]\n",
            "420 episode , 200 step , 19.57 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[170, 11, 19]\n",
            "421 episode , 200 step , 19.56 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[174, 7, 19]\n",
            "422 episode , 200 step , 19.56 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[169, 11, 20]\n",
            "423 episode , 200 step , 19.54 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[168, 18, 14]\n",
            "424 episode , 200 step , 19.55 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[175, 11, 14]\n",
            "425 episode , 200 step , 19.51 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[181, 8, 11]\n",
            "426 episode , 200 step , 19.53 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[174, 7, 19]\n",
            "427 episode , 200 step , 19.54 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[183, 5, 12]\n",
            "428 episode , 200 step , 19.54 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[178, 12, 10]\n",
            "429 episode , 200 step , 19.53 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[172, 3, 25]\n",
            "430 episode , 200 step , 19.58 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[178, 4, 18]\n",
            "431 episode , 200 step , 19.67 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[170, 4, 26]\n",
            "432 episode , 200 step , 19.69 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[178, 5, 17]\n",
            "433 episode , 200 step , 19.71 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[175, 9, 16]\n",
            "434 episode , 200 step , 19.73 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[179, 4, 17]\n",
            "435 episode , 200 step , 19.75 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[172, 7, 21]\n",
            "436 episode , 200 step , 19.79 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[175, 5, 20]\n",
            "437 episode , 200 step , 19.73 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[182, 1, 17]\n",
            "438 episode , 200 step , 19.71 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[176, 9, 15]\n",
            "439 episode , 200 step , 19.76 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[172, 10, 18]\n",
            "440 episode , 200 step , 19.71 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[179, 6, 15]\n",
            "441 episode , 200 step , 19.66 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[164, 25, 11]\n",
            "442 episode , 200 step , 19.64 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[169, 14, 17]\n",
            "443 episode , 200 step , 19.68 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[172, 13, 15]\n",
            "444 episode , 200 step , 19.70 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[156, 31, 13]\n",
            "445 episode , 200 step , 19.74 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[154, 31, 15]\n",
            "446 episode , 200 step , 19.77 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[181, 7, 12]\n",
            "447 episode , 200 step , 19.83 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[180, 5, 15]\n",
            "448 episode , 200 step , 19.92 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[152, 35, 13]\n",
            "449 episode , 200 step , 19.98 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[158, 22, 20]\n",
            "450 episode , 200 step , 19.99 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[178, 6, 16]\n",
            "451 episode , 200 step , 20.02 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[189, 2, 9]\n",
            "452 episode , 200 step , 20.09 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.67 Top reward\n",
            "[190, 2, 8]\n",
            "453 episode , 200 step , 20.15 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.66 Top reward\n",
            "[187, 2, 11]\n",
            "454 episode , 200 step , 20.18 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.61 Top reward\n",
            "[191, 4, 5]\n",
            "455 episode , 200 step , 20.31 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.57 Top reward\n",
            "[188, 3, 9]\n",
            "456 episode , 200 step , 20.40 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.60 Top reward\n",
            "[189, 5, 6]\n",
            "457 episode , 200 step , 20.48 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.54 Top reward\n",
            "[195, 4, 1]\n",
            "458 episode , 200 step , 20.61 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.58 Top reward\n",
            "[185, 5, 10]\n",
            "459 episode , 200 step , 20.76 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.62 Top reward\n",
            "[190, 2, 8]\n",
            "460 episode , 200 step , 20.84 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.66 Top reward\n",
            "[181, 9, 10]\n",
            "461 episode , 200 step , 20.91 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[185, 3, 12]\n",
            "462 episode , 200 step , 20.95 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.70 Top reward\n",
            "[174, 16, 10]\n",
            "463 episode , 200 step , 20.98 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.69 Top reward\n",
            "[184, 11, 5]\n",
            "464 episode , 200 step , 21.07 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.71 Top reward\n",
            "[185, 6, 9]\n",
            "465 episode , 200 step , 21.16 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.70 Top reward\n",
            "[178, 8, 14]\n",
            "466 episode , 200 step , 21.21 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[191, 2, 7]\n",
            "467 episode , 200 step , 21.21 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[179, 5, 16]\n",
            "468 episode , 200 step , 21.31 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[186, 2, 12]\n",
            "469 episode , 200 step , 21.26 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[186, 4, 10]\n",
            "470 episode , 200 step , 21.36 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[183, 3, 14]\n",
            "471 episode , 200 step , 21.46 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.71 Top reward\n",
            "[182, 2, 16]\n",
            "472 episode , 200 step , 21.54 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[188, 0, 12]\n",
            "473 episode , 200 step , 21.61 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.40 Top reward\n",
            "[195, 2, 3]\n",
            "474 episode , 200 step , 21.66 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[186, 1, 13]\n",
            "475 episode , 200 step , 21.70 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[180, 3, 17]\n",
            "476 episode , 200 step , 21.70 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[173, 5, 22]\n",
            "477 episode , 200 step , 21.71 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[170, 5, 25]\n",
            "478 episode , 200 step , 21.72 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[179, 7, 14]\n",
            "479 episode , 200 step , 21.77 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[183, 1, 16]\n",
            "480 episode , 200 step , 21.73 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[179, 4, 17]\n",
            "481 episode , 200 step , 21.78 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[170, 11, 19]\n",
            "482 episode , 200 step , 21.86 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[170, 11, 19]\n",
            "483 episode , 200 step , 21.85 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[171, 11, 18]\n",
            "484 episode , 200 step , 21.86 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[171, 14, 15]\n",
            "485 episode , 200 step , 21.86 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[159, 8, 33]\n",
            "486 episode , 200 step , 21.88 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[173, 2, 25]\n",
            "487 episode , 200 step , 21.95 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[72, 5, 123]\n",
            "488 episode , 200 step , 21.99 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.85 Top reward\n",
            "[148, 4, 48]\n",
            "489 episode , 200 step , 22.03 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.84 Top reward\n",
            "[179, 2, 19]\n",
            "490 episode , 200 step , 22.07 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[186, 3, 11]\n",
            "491 episode , 200 step , 22.04 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[174, 5, 21]\n",
            "492 episode , 200 step , 22.09 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[178, 6, 16]\n",
            "493 episode , 200 step , 22.06 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[175, 8, 17]\n",
            "494 episode , 200 step , 22.08 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[175, 1, 24]\n",
            "495 episode , 200 step , 22.13 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.85 Top reward\n",
            "[162, 17, 21]\n",
            "496 episode , 200 step , 22.13 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.86 Top reward\n",
            "[162, 15, 23]\n",
            "497 episode , 200 step , 22.10 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[179, 10, 11]\n",
            "498 episode , 200 step , 22.09 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.90 Top reward\n",
            "[167, 13, 20]\n",
            "499 episode , 200 step , 22.02 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.84 Top reward\n",
            "[173, 10, 17]\n",
            "500 episode , 200 step , 21.98 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[175, 10, 15]\n",
            "501 episode , 200 step , 22.08 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[171, 13, 16]\n",
            "502 episode , 200 step , 22.07 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[177, 7, 16]\n",
            "503 episode , 200 step , 22.03 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[177, 7, 16]\n",
            "504 episode , 200 step , 22.02 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[167, 5, 28]\n",
            "505 episode , 200 step , 21.97 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[170, 2, 28]\n",
            "506 episode , 200 step , 21.89 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[181, 3, 16]\n",
            "507 episode , 200 step , 21.80 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[181, 6, 13]\n",
            "508 episode , 200 step , 21.73 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[179, 4, 17]\n",
            "509 episode , 200 step , 21.65 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[171, 2, 27]\n",
            "510 episode , 200 step , 21.56 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[183, 2, 15]\n",
            "511 episode , 200 step , 21.68 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[184, 1, 15]\n",
            "512 episode , 200 step , 21.61 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[173, 7, 20]\n",
            "513 episode , 200 step , 21.64 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[178, 4, 18]\n",
            "514 episode , 200 step , 21.62 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[176, 3, 21]\n",
            "515 episode , 200 step , 21.52 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.85 Top reward\n",
            "[168, 9, 23]\n",
            "516 episode , 200 step , 21.58 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.94 Top reward\n",
            "[161, 13, 26]\n",
            "517 episode , 200 step , 21.51 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.85 Top reward\n",
            "[166, 11, 23]\n",
            "518 episode , 200 step , 21.48 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.85 Top reward\n",
            "[172, 19, 9]\n",
            "519 episode , 200 step , 21.49 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.83 Top reward\n",
            "[168, 9, 23]\n",
            "520 episode , 200 step , 21.47 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[172, 7, 21]\n",
            "521 episode , 200 step , 21.44 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.84 Top reward\n",
            "[170, 5, 25]\n",
            "522 episode , 200 step , 21.42 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[175, 9, 16]\n",
            "523 episode , 200 step , 21.40 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[182, 10, 8]\n",
            "524 episode , 200 step , 21.32 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[179, 7, 14]\n",
            "525 episode , 200 step , 21.39 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[179, 7, 14]\n",
            "526 episode , 200 step , 21.39 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[176, 5, 19]\n",
            "527 episode , 200 step , 21.38 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[166, 7, 27]\n",
            "528 episode , 200 step , 21.41 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[175, 5, 20]\n",
            "529 episode , 200 step , 21.47 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[173, 2, 25]\n",
            "530 episode , 200 step , 21.43 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[177, 6, 17]\n",
            "531 episode , 200 step , 21.49 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[181, 2, 17]\n",
            "532 episode , 200 step , 21.53 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[175, 6, 19]\n",
            "533 episode , 200 step , 21.52 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[168, 8, 24]\n",
            "534 episode , 200 step , 21.54 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.83 Top reward\n",
            "[177, 2, 21]\n",
            "535 episode , 200 step , 21.53 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.86 Top reward\n",
            "[163, 7, 30]\n",
            "536 episode , 200 step , 21.51 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.86 Top reward\n",
            "[167, 6, 27]\n",
            "537 episode , 200 step , 21.48 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[178, 6, 16]\n",
            "538 episode , 200 step , 21.49 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[177, 3, 20]\n",
            "539 episode , 200 step , 21.48 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[179, 7, 14]\n",
            "540 episode , 200 step , 21.50 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[179, 2, 19]\n",
            "541 episode , 200 step , 21.57 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[186, 1, 13]\n",
            "542 episode , 200 step , 21.59 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[183, 6, 11]\n",
            "543 episode , 200 step , 21.58 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[169, 12, 19]\n",
            "544 episode , 200 step , 21.60 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[180, 2, 18]\n",
            "545 episode , 200 step , 21.63 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[183, 3, 14]\n",
            "546 episode , 200 step , 21.67 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.43 Top reward\n",
            "[196, 3, 1]\n",
            "547 episode , 200 step , 21.79 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.43 Top reward\n",
            "[193, 2, 5]\n",
            "548 episode , 200 step , 21.86 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[183, 3, 14]\n",
            "549 episode , 200 step , 21.85 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[180, 3, 17]\n",
            "550 episode , 200 step , 21.88 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[178, 3, 19]\n",
            "551 episode , 200 step , 22.04 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.46 Top reward\n",
            "[195, 3, 2]\n",
            "552 episode , 200 step , 22.17 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.43 Top reward\n",
            "[191, 5, 4]\n",
            "553 episode , 200 step , 22.26 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.49 Top reward\n",
            "[192, 3, 5]\n",
            "554 episode , 200 step , 22.34 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[183, 1, 16]\n",
            "555 episode , 200 step , 22.31 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.41 Top reward\n",
            "[195, 3, 2]\n",
            "556 episode , 200 step , 22.42 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[178, 3, 19]\n",
            "557 episode , 200 step , 22.48 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[175, 4, 21]\n",
            "558 episode , 200 step , 22.49 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[179, 3, 18]\n",
            "559 episode , 200 step , 22.46 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[179, 4, 17]\n",
            "560 episode , 200 step , 22.43 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[179, 3, 18]\n",
            "561 episode , 200 step , 22.42 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[175, 4, 21]\n",
            "562 episode , 200 step , 22.46 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[175, 9, 16]\n",
            "563 episode , 200 step , 22.48 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[183, 2, 15]\n",
            "564 episode , 200 step , 22.40 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[174, 2, 24]\n",
            "565 episode , 200 step , 22.44 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[171, 6, 23]\n",
            "566 episode , 200 step , 22.42 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[176, 3, 21]\n",
            "567 episode , 200 step , 22.41 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[176, 1, 23]\n",
            "568 episode , 200 step , 22.46 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[180, 3, 17]\n",
            "569 episode , 200 step , 22.41 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[176, 5, 19]\n",
            "570 episode , 200 step , 22.40 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[184, 7, 9]\n",
            "571 episode , 200 step , 22.45 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.72 Top reward\n",
            "[182, 3, 15]\n",
            "572 episode , 200 step , 22.51 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[176, 3, 21]\n",
            "573 episode , 200 step , 22.53 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[155, 3, 42]\n",
            "574 episode , 200 step , 22.54 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[184, 4, 12]\n",
            "575 episode , 200 step , 22.57 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[179, 3, 18]\n",
            "576 episode , 200 step , 22.55 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[187, 1, 12]\n",
            "577 episode , 200 step , 22.58 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[178, 2, 20]\n",
            "578 episode , 200 step , 22.57 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[176, 14, 10]\n",
            "579 episode , 200 step , 22.56 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[177, 17, 6]\n",
            "580 episode , 200 step , 22.53 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[174, 23, 3]\n",
            "581 episode , 200 step , 22.48 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[170, 17, 13]\n",
            "582 episode , 200 step , 22.52 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[159, 37, 4]\n",
            "583 episode , 200 step , 22.51 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[166, 25, 9]\n",
            "584 episode , 200 step , 22.57 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.83 Top reward\n",
            "[176, 3, 21]\n",
            "585 episode , 200 step , 22.55 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[168, 12, 20]\n",
            "586 episode , 200 step , 22.58 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[169, 9, 22]\n",
            "587 episode , 200 step , 22.54 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[181, 12, 7]\n",
            "588 episode , 200 step , 22.48 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[167, 2, 31]\n",
            "589 episode , 200 step , 22.53 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[162, 4, 34]\n",
            "590 episode , 200 step , 22.53 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[163, 4, 33]\n",
            "591 episode , 200 step , 22.54 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.64 Top reward\n",
            "[1, 4, 195]\n",
            "592 episode , 200 step , 22.67 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[172, 5, 23]\n",
            "593 episode , 200 step , 22.65 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[165, 4, 31]\n",
            "594 episode , 200 step , 22.64 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[165, 2, 33]\n",
            "595 episode , 200 step , 22.69 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[180, 3, 17]\n",
            "596 episode , 200 step , 22.69 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[163, 2, 35]\n",
            "597 episode , 200 step , 22.52 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[177, 6, 17]\n",
            "598 episode , 200 step , 22.48 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[181, 2, 17]\n",
            "599 episode , 200 step , 22.41 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[182, 3, 15]\n",
            "600 episode , 200 step , 22.41 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[172, 5, 23]\n",
            "601 episode , 200 step , 22.32 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[179, 6, 15]\n",
            "602 episode , 200 step , 22.22 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[182, 3, 15]\n",
            "603 episode , 200 step , 22.10 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[183, 1, 16]\n",
            "604 episode , 200 step , 22.00 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[184, 2, 14]\n",
            "605 episode , 200 step , 22.01 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[175, 9, 16]\n",
            "606 episode , 200 step , 21.87 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[177, 7, 16]\n",
            "607 episode , 200 step , 21.91 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[186, 3, 11]\n",
            "608 episode , 200 step , 21.86 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[182, 8, 10]\n",
            "609 episode , 200 step , 21.90 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[176, 8, 16]\n",
            "610 episode , 200 step , 21.93 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[178, 3, 19]\n",
            "611 episode , 200 step , 21.91 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[188, 2, 10]\n",
            "612 episode , 200 step , 21.89 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[178, 4, 18]\n",
            "613 episode , 200 step , 21.93 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[179, 2, 19]\n",
            "614 episode , 200 step , 21.95 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[174, 7, 19]\n",
            "615 episode , 200 step , 21.96 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.85 Top reward\n",
            "[177, 3, 20]\n",
            "616 episode , 200 step , 21.91 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[179, 5, 16]\n",
            "617 episode , 200 step , 21.97 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[188, 1, 11]\n",
            "618 episode , 200 step , 21.99 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[188, 1, 11]\n",
            "619 episode , 200 step , 21.95 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[186, 3, 11]\n",
            "620 episode , 200 step , 21.96 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[183, 1, 16]\n",
            "621 episode , 200 step , 22.06 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.43 Top reward\n",
            "[190, 7, 3]\n",
            "622 episode , 200 step , 22.11 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[182, 3, 15]\n",
            "623 episode , 200 step , 22.13 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[178, 6, 16]\n",
            "624 episode , 200 step , 22.11 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[187, 2, 11]\n",
            "625 episode , 200 step , 22.09 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[181, 5, 14]\n",
            "626 episode , 200 step , 22.13 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[179, 1, 20]\n",
            "627 episode , 200 step , 22.15 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[182, 6, 12]\n",
            "628 episode , 200 step , 22.11 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[185, 3, 12]\n",
            "629 episode , 200 step , 22.14 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[184, 6, 10]\n",
            "630 episode , 200 step , 22.13 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[184, 5, 11]\n",
            "631 episode , 200 step , 22.13 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[182, 3, 15]\n",
            "632 episode , 200 step , 22.09 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[181, 5, 14]\n",
            "633 episode , 200 step , 22.14 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[181, 5, 14]\n",
            "634 episode , 200 step , 22.08 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[179, 3, 18]\n",
            "635 episode , 200 step , 22.06 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[183, 3, 14]\n",
            "636 episode , 200 step , 22.09 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[179, 3, 18]\n",
            "637 episode , 200 step , 22.10 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[181, 2, 17]\n",
            "638 episode , 200 step , 22.08 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[177, 3, 20]\n",
            "639 episode , 200 step , 22.12 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[175, 4, 21]\n",
            "640 episode , 200 step , 22.13 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[179, 3, 18]\n",
            "641 episode , 200 step , 22.06 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[178, 4, 18]\n",
            "642 episode , 200 step , 21.96 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[184, 4, 12]\n",
            "643 episode , 200 step , 21.99 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[183, 3, 14]\n",
            "644 episode , 200 step , 21.94 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[187, 4, 9]\n",
            "645 episode , 200 step , 21.98 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.72 Top reward\n",
            "[176, 4, 20]\n",
            "646 episode , 200 step , 22.02 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[175, 6, 19]\n",
            "647 episode , 200 step , 22.00 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[185, 3, 12]\n",
            "648 episode , 200 step , 21.99 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[181, 4, 15]\n",
            "649 episode , 200 step , 22.03 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.72 Top reward\n",
            "[182, 3, 15]\n",
            "650 episode , 200 step , 22.11 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[175, 7, 18]\n",
            "651 episode , 200 step , 22.12 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.65 Top reward\n",
            "[85, 17, 98]\n",
            "652 episode , 200 step , 22.20 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.68 Top reward\n",
            "[190, 3, 7]\n",
            "653 episode , 200 step , 22.27 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.68 Top reward\n",
            "[184, 4, 12]\n",
            "654 episode , 200 step , 22.30 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[172, 3, 25]\n",
            "655 episode , 200 step , 22.32 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[179, 5, 16]\n",
            "656 episode , 200 step , 22.35 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[178, 5, 17]\n",
            "657 episode , 200 step , 22.35 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[176, 4, 20]\n",
            "658 episode , 200 step , 22.39 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[177, 10, 13]\n",
            "659 episode , 200 step , 22.34 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.83 Top reward\n",
            "[173, 11, 16]\n",
            "660 episode , 200 step , 22.33 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[171, 11, 18]\n",
            "661 episode , 200 step , 22.24 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[170, 23, 7]\n",
            "662 episode , 200 step , 22.24 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.83 Top reward\n",
            "[167, 15, 18]\n",
            "663 episode , 200 step , 22.28 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.44 Top reward\n",
            "[196, 3, 1]\n",
            "664 episode , 200 step , 22.36 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.43 Top reward\n",
            "[193, 2, 5]\n",
            "665 episode , 200 step , 22.49 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[169, 18, 13]\n",
            "666 episode , 200 step , 22.43 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[176, 12, 12]\n",
            "667 episode , 200 step , 22.44 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[167, 20, 13]\n",
            "668 episode , 200 step , 22.42 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[154, 11, 35]\n",
            "669 episode , 200 step , 22.43 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[179, 6, 15]\n",
            "670 episode , 200 step , 22.45 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[180, 10, 10]\n",
            "671 episode , 200 step , 22.38 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[177, 8, 15]\n",
            "672 episode , 200 step , 22.29 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[162, 17, 21]\n",
            "673 episode , 200 step , 22.26 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[166, 14, 20]\n",
            "674 episode , 200 step , 22.22 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[178, 10, 12]\n",
            "675 episode , 200 step , 22.17 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[164, 10, 26]\n",
            "676 episode , 200 step , 22.17 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[163, 10, 27]\n",
            "677 episode , 200 step , 22.20 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[173, 10, 17]\n",
            "678 episode , 200 step , 22.22 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[166, 9, 25]\n",
            "679 episode , 200 step , 22.23 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[180, 2, 18]\n",
            "680 episode , 200 step , 22.23 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[172, 8, 20]\n",
            "681 episode , 200 step , 22.23 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[182, 2, 16]\n",
            "682 episode , 200 step , 22.24 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[178, 10, 12]\n",
            "683 episode , 200 step , 22.24 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[178, 10, 12]\n",
            "684 episode , 200 step , 22.23 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[179, 4, 17]\n",
            "685 episode , 200 step , 22.26 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[163, 6, 31]\n",
            "686 episode , 200 step , 22.22 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[170, 9, 21]\n",
            "687 episode , 200 step , 22.24 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[179, 2, 19]\n",
            "688 episode , 200 step , 22.21 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[168, 9, 23]\n",
            "689 episode , 200 step , 22.20 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[182, 6, 12]\n",
            "690 episode , 200 step , 22.20 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[184, 2, 14]\n",
            "691 episode , 200 step , 22.19 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[180, 4, 16]\n",
            "692 episode , 200 step , 22.20 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[174, 10, 16]\n",
            "693 episode , 200 step , 22.23 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[175, 8, 17]\n",
            "694 episode , 200 step , 22.23 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[180, 6, 14]\n",
            "695 episode , 200 step , 22.17 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[187, 1, 12]\n",
            "696 episode , 200 step , 22.18 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[178, 5, 17]\n",
            "697 episode , 200 step , 22.17 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[180, 7, 13]\n",
            "698 episode , 200 step , 22.12 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[188, 1, 11]\n",
            "699 episode , 200 step , 22.10 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[175, 8, 17]\n",
            "700 episode , 200 step , 22.10 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[176, 12, 12]\n",
            "701 episode , 200 step , 22.04 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[179, 6, 15]\n",
            "702 episode , 200 step , 21.98 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[184, 5, 11]\n",
            "703 episode , 200 step , 21.96 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[172, 8, 20]\n",
            "704 episode , 200 step , 21.91 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[170, 5, 25]\n",
            "705 episode , 200 step , 21.90 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[172, 8, 20]\n",
            "706 episode , 200 step , 21.93 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[175, 9, 16]\n",
            "707 episode , 200 step , 21.87 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[177, 5, 18]\n",
            "708 episode , 200 step , 21.84 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[178, 9, 13]\n",
            "709 episode , 200 step , 21.84 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[179, 8, 13]\n",
            "710 episode , 200 step , 21.91 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[174, 8, 18]\n",
            "711 episode , 200 step , 21.92 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[172, 7, 21]\n",
            "712 episode , 200 step , 21.91 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[172, 18, 10]\n",
            "713 episode , 200 step , 21.88 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.83 Top reward\n",
            "[165, 25, 10]\n",
            "714 episode , 200 step , 21.75 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.84 Top reward\n",
            "[165, 22, 13]\n",
            "715 episode , 200 step , 21.69 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.85 Top reward\n",
            "[169, 13, 18]\n",
            "716 episode , 200 step , 21.70 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[170, 16, 14]\n",
            "717 episode , 200 step , 21.72 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[174, 17, 9]\n",
            "718 episode , 200 step , 21.70 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[171, 13, 16]\n",
            "719 episode , 200 step , 21.75 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[168, 19, 13]\n",
            "720 episode , 200 step , 21.78 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[169, 15, 16]\n",
            "721 episode , 200 step , 21.81 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[166, 16, 18]\n",
            "722 episode , 200 step , 21.83 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[176, 12, 12]\n",
            "723 episode , 200 step , 21.82 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[178, 12, 10]\n",
            "724 episode , 200 step , 21.81 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[178, 11, 11]\n",
            "725 episode , 200 step , 21.93 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[185, 8, 7]\n",
            "726 episode , 200 step , 21.92 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[182, 8, 10]\n",
            "727 episode , 200 step , 21.86 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[174, 14, 12]\n",
            "728 episode , 200 step , 21.95 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[175, 6, 19]\n",
            "729 episode , 200 step , 21.94 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[178, 4, 18]\n",
            "730 episode , 200 step , 21.95 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[178, 1, 21]\n",
            "731 episode , 200 step , 21.99 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[175, 11, 14]\n",
            "732 episode , 200 step , 21.93 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[176, 11, 13]\n",
            "733 episode , 200 step , 21.98 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[175, 10, 15]\n",
            "734 episode , 200 step , 21.97 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[174, 14, 12]\n",
            "735 episode , 200 step , 21.93 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[177, 10, 13]\n",
            "736 episode , 200 step , 21.95 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[171, 2, 27]\n",
            "737 episode , 200 step , 21.94 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[172, 8, 20]\n",
            "738 episode , 200 step , 21.87 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[180, 9, 11]\n",
            "739 episode , 200 step , 21.92 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[180, 3, 17]\n",
            "740 episode , 200 step , 21.95 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[179, 7, 14]\n",
            "741 episode , 200 step , 21.93 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[166, 4, 30]\n",
            "742 episode , 200 step , 21.96 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[180, 6, 14]\n",
            "743 episode , 200 step , 21.91 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[184, 7, 9]\n",
            "744 episode , 200 step , 21.88 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[175, 8, 17]\n",
            "745 episode , 200 step , 21.93 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[173, 6, 21]\n",
            "746 episode , 200 step , 21.95 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[181, 8, 11]\n",
            "747 episode , 200 step , 21.91 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[177, 9, 14]\n",
            "748 episode , 200 step , 21.92 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[178, 5, 17]\n",
            "749 episode , 200 step , 21.93 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[183, 4, 13]\n",
            "750 episode , 200 step , 21.93 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[184, 6, 10]\n",
            "751 episode , 200 step , 21.92 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[182, 5, 13]\n",
            "752 episode , 200 step , 21.92 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[179, 3, 18]\n",
            "753 episode , 200 step , 21.96 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[175, 5, 20]\n",
            "754 episode , 200 step , 21.90 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[173, 7, 20]\n",
            "755 episode , 200 step , 21.92 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[185, 0, 15]\n",
            "756 episode , 200 step , 21.97 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[177, 3, 20]\n",
            "757 episode , 200 step , 22.03 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[177, 3, 20]\n",
            "758 episode , 200 step , 22.07 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[181, 6, 13]\n",
            "759 episode , 200 step , 22.03 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[181, 1, 18]\n",
            "760 episode , 200 step , 22.09 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[170, 9, 21]\n",
            "761 episode , 200 step , 22.03 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[174, 6, 20]\n",
            "762 episode , 200 step , 21.97 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[175, 7, 18]\n",
            "763 episode , 200 step , 22.01 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[166, 7, 27]\n",
            "764 episode , 200 step , 22.05 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[180, 6, 14]\n",
            "765 episode , 200 step , 22.02 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[171, 9, 20]\n",
            "766 episode , 200 step , 22.04 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[174, 13, 13]\n",
            "767 episode , 200 step , 22.03 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[166, 13, 21]\n",
            "768 episode , 200 step , 22.02 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[175, 9, 16]\n",
            "769 episode , 200 step , 22.01 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[181, 12, 7]\n",
            "770 episode , 200 step , 22.05 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[174, 10, 16]\n",
            "771 episode , 200 step , 22.04 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[171, 11, 18]\n",
            "772 episode , 200 step , 22.01 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[176, 13, 11]\n",
            "773 episode , 200 step , 22.00 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[180, 10, 10]\n",
            "774 episode , 200 step , 21.97 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[182, 7, 11]\n",
            "775 episode , 200 step , 21.97 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[180, 6, 14]\n",
            "776 episode , 200 step , 21.97 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[179, 7, 14]\n",
            "777 episode , 200 step , 21.94 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[173, 9, 18]\n",
            "778 episode , 200 step , 21.91 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[162, 20, 18]\n",
            "779 episode , 200 step , 21.94 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.83 Top reward\n",
            "[170, 10, 20]\n",
            "780 episode , 200 step , 21.89 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[169, 14, 17]\n",
            "781 episode , 200 step , 21.93 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.84 Top reward\n",
            "[165, 15, 20]\n",
            "782 episode , 200 step , 21.87 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.85 Top reward\n",
            "[168, 14, 18]\n",
            "783 episode , 200 step , 21.90 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.84 Top reward\n",
            "[81, 13, 106]\n",
            "784 episode , 200 step , 21.95 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.69 Top reward\n",
            "[108, 7, 85]\n",
            "785 episode , 200 step , 22.07 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.64 Top reward\n",
            "[33, 10, 157]\n",
            "786 episode , 200 step , 22.16 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.61 Top reward\n",
            "[173, 10, 17]\n",
            "787 episode , 200 step , 22.19 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.68 Top reward\n",
            "[173, 6, 21]\n",
            "788 episode , 200 step , 22.27 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.68 Top reward\n",
            "[164, 7, 29]\n",
            "789 episode , 200 step , 22.28 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[171, 3, 26]\n",
            "790 episode , 200 step , 22.34 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[172, 2, 26]\n",
            "791 episode , 200 step , 22.31 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[166, 2, 32]\n",
            "792 episode , 200 step , 22.27 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[180, 9, 11]\n",
            "793 episode , 200 step , 22.28 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[169, 4, 27]\n",
            "794 episode , 200 step , 22.27 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[165, 3, 32]\n",
            "795 episode , 200 step , 22.30 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[179, 5, 16]\n",
            "796 episode , 200 step , 22.31 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[186, 5, 9]\n",
            "797 episode , 200 step , 22.27 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[173, 1, 26]\n",
            "798 episode , 200 step , 22.28 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[184, 4, 12]\n",
            "799 episode , 200 step , 22.30 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[175, 16, 9]\n",
            "800 episode , 200 step , 22.32 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[170, 14, 16]\n",
            "801 episode , 200 step , 22.35 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[176, 11, 13]\n",
            "802 episode , 200 step , 22.34 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[178, 7, 15]\n",
            "803 episode , 200 step , 22.33 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[182, 6, 12]\n",
            "804 episode , 200 step , 22.31 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[181, 5, 14]\n",
            "805 episode , 200 step , 22.29 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[176, 10, 14]\n",
            "806 episode , 200 step , 22.25 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[167, 19, 14]\n",
            "807 episode , 200 step , 22.24 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[177, 12, 11]\n",
            "808 episode , 200 step , 22.22 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[171, 14, 15]\n",
            "809 episode , 200 step , 22.15 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[177, 9, 14]\n",
            "810 episode , 200 step , 22.18 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[182, 6, 12]\n",
            "811 episode , 200 step , 22.21 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[166, 15, 19]\n",
            "812 episode , 200 step , 22.21 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[167, 21, 12]\n",
            "813 episode , 200 step , 22.19 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[170, 16, 14]\n",
            "814 episode , 200 step , 22.15 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[170, 16, 14]\n",
            "815 episode , 200 step , 22.14 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[169, 18, 13]\n",
            "816 episode , 200 step , 22.16 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[172, 14, 14]\n",
            "817 episode , 200 step , 22.14 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[168, 14, 18]\n",
            "818 episode , 200 step , 22.13 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[172, 6, 22]\n",
            "819 episode , 200 step , 22.13 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[172, 7, 21]\n",
            "820 episode , 200 step , 22.14 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[172, 16, 12]\n",
            "821 episode , 200 step , 22.16 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[172, 8, 20]\n",
            "822 episode , 200 step , 22.18 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[186, 3, 11]\n",
            "823 episode , 200 step , 22.16 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[178, 6, 16]\n",
            "824 episode , 200 step , 22.20 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[178, 7, 15]\n",
            "825 episode , 200 step , 22.17 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[178, 8, 14]\n",
            "826 episode , 200 step , 22.17 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[182, 5, 13]\n",
            "827 episode , 200 step , 22.15 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[184, 3, 13]\n",
            "828 episode , 200 step , 22.14 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[177, 10, 13]\n",
            "829 episode , 200 step , 22.17 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[154, 9, 37]\n",
            "830 episode , 200 step , 22.16 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[186, 4, 10]\n",
            "831 episode , 200 step , 22.25 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[180, 2, 18]\n",
            "832 episode , 200 step , 22.25 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[170, 8, 22]\n",
            "833 episode , 200 step , 22.29 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.84 Top reward\n",
            "[168, 22, 10]\n",
            "834 episode , 200 step , 22.27 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.85 Top reward\n",
            "[162, 19, 19]\n",
            "835 episode , 200 step , 22.19 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.84 Top reward\n",
            "[162, 23, 15]\n",
            "836 episode , 200 step , 22.10 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.83 Top reward\n",
            "[159, 25, 16]\n",
            "837 episode , 200 step , 21.97 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[159, 21, 20]\n",
            "838 episode , 200 step , 21.92 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.85 Top reward\n",
            "[152, 42, 6]\n",
            "839 episode , 200 step , 21.88 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.84 Top reward\n",
            "[150, 36, 14]\n",
            "840 episode , 200 step , 21.86 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.85 Top reward\n",
            "[153, 41, 6]\n",
            "841 episode , 200 step , 21.79 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.81 Top reward\n",
            "[154, 37, 9]\n",
            "842 episode , 200 step , 21.77 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.82 Top reward\n",
            "[156, 27, 17]\n",
            "843 episode , 200 step , 21.85 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[171, 15, 14]\n",
            "844 episode , 200 step , 21.91 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[177, 7, 16]\n",
            "845 episode , 200 step , 21.91 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[174, 14, 12]\n",
            "846 episode , 200 step , 21.94 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[171, 20, 9]\n",
            "847 episode , 200 step , 21.95 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[172, 7, 21]\n",
            "848 episode , 200 step , 21.98 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[176, 3, 21]\n",
            "849 episode , 200 step , 21.99 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[175, 4, 21]\n",
            "850 episode , 200 step , 21.97 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[174, 7, 19]\n",
            "851 episode , 200 step , 22.01 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[154, 25, 21]\n",
            "852 episode , 200 step , 21.99 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[166, 25, 9]\n",
            "853 episode , 200 step , 21.98 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[158, 28, 14]\n",
            "854 episode , 200 step , 22.02 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[160, 15, 25]\n",
            "855 episode , 200 step , 22.02 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[185, 2, 13]\n",
            "856 episode , 200 step , 22.03 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[178, 5, 17]\n",
            "857 episode , 200 step , 22.01 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[176, 5, 19]\n",
            "858 episode , 200 step , 22.01 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[177, 4, 19]\n",
            "859 episode , 200 step , 22.00 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[172, 5, 23]\n",
            "860 episode , 200 step , 22.01 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[174, 7, 19]\n",
            "861 episode , 200 step , 22.15 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[178, 2, 20]\n",
            "862 episode , 200 step , 22.14 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[172, 5, 23]\n",
            "863 episode , 200 step , 22.18 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[184, 4, 12]\n",
            "864 episode , 200 step , 22.08 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[182, 6, 12]\n",
            "865 episode , 200 step , 22.14 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.72 Top reward\n",
            "[189, 4, 7]\n",
            "866 episode , 200 step , 22.19 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[176, 3, 21]\n",
            "867 episode , 200 step , 22.13 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[175, 6, 19]\n",
            "868 episode , 200 step , 22.19 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[185, 2, 13]\n",
            "869 episode , 200 step , 22.15 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[186, 2, 12]\n",
            "870 episode , 200 step , 22.17 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[176, 5, 19]\n",
            "871 episode , 200 step , 22.27 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[175, 2, 23]\n",
            "872 episode , 200 step , 22.30 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[175, 7, 18]\n",
            "873 episode , 200 step , 22.28 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[175, 4, 21]\n",
            "874 episode , 200 step , 22.28 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[172, 5, 23]\n",
            "875 episode , 200 step , 22.28 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[178, 5, 17]\n",
            "876 episode , 200 step , 22.31 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[175, 4, 21]\n",
            "877 episode , 200 step , 22.34 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[185, 4, 11]\n",
            "878 episode , 200 step , 22.33 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[187, 1, 12]\n",
            "879 episode , 200 step , 22.39 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[186, 5, 9]\n",
            "880 episode , 200 step , 22.35 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[178, 3, 19]\n",
            "881 episode , 200 step , 22.38 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[178, 6, 16]\n",
            "882 episode , 200 step , 22.35 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[183, 7, 10]\n",
            "883 episode , 200 step , 22.32 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[176, 8, 16]\n",
            "884 episode , 200 step , 22.35 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[179, 8, 13]\n",
            "885 episode , 200 step , 22.34 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[182, 2, 16]\n",
            "886 episode , 200 step , 22.32 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[184, 2, 14]\n",
            "887 episode , 200 step , 22.35 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[180, 7, 13]\n",
            "888 episode , 200 step , 22.40 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[181, 5, 14]\n",
            "889 episode , 200 step , 22.34 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[181, 2, 17]\n",
            "890 episode , 200 step , 22.37 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[183, 3, 14]\n",
            "891 episode , 200 step , 22.43 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[185, 3, 12]\n",
            "892 episode , 200 step , 22.36 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[184, 5, 11]\n",
            "893 episode , 200 step , 22.40 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[174, 4, 22]\n",
            "894 episode , 200 step , 22.31 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[186, 2, 12]\n",
            "895 episode , 200 step , 22.24 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[178, 8, 14]\n",
            "896 episode , 200 step , 22.20 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.84 Top reward\n",
            "[150, 16, 34]\n",
            "897 episode , 200 step , 22.20 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[160, 9, 31]\n",
            "898 episode , 200 step , 22.18 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[161, 18, 21]\n",
            "899 episode , 200 step , 22.23 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[136, 27, 37]\n",
            "900 episode , 200 step , 22.25 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[142, 19, 39]\n",
            "901 episode , 200 step , 22.32 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[164, 18, 18]\n",
            "902 episode , 200 step , 22.34 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[171, 14, 15]\n",
            "903 episode , 200 step , 22.33 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[173, 15, 12]\n",
            "904 episode , 200 step , 22.37 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[170, 17, 13]\n",
            "905 episode , 200 step , 22.37 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[180, 9, 11]\n",
            "906 episode , 200 step , 22.35 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[181, 13, 6]\n",
            "907 episode , 200 step , 22.40 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[179, 11, 10]\n",
            "908 episode , 200 step , 22.39 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[174, 11, 15]\n",
            "909 episode , 200 step , 22.41 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[181, 13, 6]\n",
            "910 episode , 200 step , 22.44 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[181, 9, 10]\n",
            "911 episode , 200 step , 22.43 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[187, 0, 13]\n",
            "912 episode , 200 step , 22.41 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[186, 4, 10]\n",
            "913 episode , 200 step , 22.39 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[181, 5, 14]\n",
            "914 episode , 200 step , 22.47 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.43 Top reward\n",
            "[192, 4, 4]\n",
            "915 episode , 200 step , 22.59 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[182, 3, 15]\n",
            "916 episode , 200 step , 22.53 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[174, 9, 17]\n",
            "917 episode , 200 step , 22.57 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[181, 1, 18]\n",
            "918 episode , 200 step , 22.57 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[178, 1, 21]\n",
            "919 episode , 200 step , 22.55 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[183, 6, 11]\n",
            "920 episode , 200 step , 22.61 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[177, 6, 17]\n",
            "921 episode , 200 step , 22.56 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[184, 4, 12]\n",
            "922 episode , 200 step , 22.56 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[171, 4, 25]\n",
            "923 episode , 200 step , 22.54 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[177, 2, 21]\n",
            "924 episode , 200 step , 22.60 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.62 Top reward\n",
            "[28, 156, 16]\n",
            "925 episode , 200 step , 22.67 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[171, 4, 25]\n",
            "926 episode , 200 step , 22.63 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[181, 3, 16]\n",
            "927 episode , 200 step , 22.68 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[179, 6, 15]\n",
            "928 episode , 200 step , 22.66 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[177, 4, 19]\n",
            "929 episode , 200 step , 22.62 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[178, 8, 14]\n",
            "930 episode , 200 step , 22.63 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[178, 6, 16]\n",
            "931 episode , 200 step , 22.60 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[185, 3, 12]\n",
            "932 episode , 200 step , 22.59 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[176, 5, 19]\n",
            "933 episode , 200 step , 22.61 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[146, 2, 52]\n",
            "934 episode , 200 step , 22.67 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.80 Top reward\n",
            "[172, 4, 24]\n",
            "935 episode , 200 step , 22.61 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[182, 5, 13]\n",
            "936 episode , 200 step , 22.69 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[183, 1, 16]\n",
            "937 episode , 200 step , 22.70 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[181, 6, 13]\n",
            "938 episode , 200 step , 22.68 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[181, 3, 16]\n",
            "939 episode , 200 step , 22.66 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[184, 2, 14]\n",
            "940 episode , 200 step , 22.68 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[183, 1, 16]\n",
            "941 episode , 200 step , 22.66 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[188, 2, 10]\n",
            "942 episode , 200 step , 22.67 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[182, 4, 14]\n",
            "943 episode , 200 step , 22.66 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[173, 4, 23]\n",
            "944 episode , 200 step , 22.73 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[174, 4, 22]\n",
            "945 episode , 200 step , 22.68 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[172, 2, 26]\n",
            "946 episode , 200 step , 22.74 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[187, 1, 12]\n",
            "947 episode , 200 step , 22.75 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[182, 6, 12]\n",
            "948 episode , 200 step , 22.75 Actor Loss, 0.11 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[176, 9, 15]\n",
            "949 episode , 200 step , 22.71 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[184, 2, 14]\n",
            "950 episode , 200 step , 22.69 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[178, 5, 17]\n",
            "951 episode , 200 step , 22.60 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[178, 5, 17]\n",
            "952 episode , 200 step , 22.58 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[186, 2, 12]\n",
            "953 episode , 200 step , 22.59 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[178, 4, 18]\n",
            "954 episode , 200 step , 22.61 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[179, 6, 15]\n",
            "955 episode , 200 step , 22.62 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[181, 5, 14]\n",
            "956 episode , 200 step , 22.57 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[186, 2, 12]\n",
            "957 episode , 200 step , 22.55 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[183, 5, 12]\n",
            "958 episode , 200 step , 22.56 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[166, 6, 28]\n",
            "959 episode , 200 step , 22.53 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[169, 4, 27]\n",
            "960 episode , 200 step , 22.59 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[184, 2, 14]\n",
            "961 episode , 200 step , 22.53 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[185, 4, 11]\n",
            "962 episode , 200 step , 22.59 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[180, 3, 17]\n",
            "963 episode , 200 step , 22.55 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[180, 10, 10]\n",
            "964 episode , 200 step , 22.47 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[175, 6, 19]\n",
            "965 episode , 200 step , 22.42 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[176, 15, 9]\n",
            "966 episode , 200 step , 22.40 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[174, 15, 11]\n",
            "967 episode , 200 step , 22.38 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[173, 15, 12]\n",
            "968 episode , 200 step , 22.40 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[173, 16, 11]\n",
            "969 episode , 200 step , 22.31 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[178, 13, 9]\n",
            "970 episode , 200 step , 22.37 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[175, 10, 15]\n",
            "971 episode , 200 step , 22.34 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[178, 10, 12]\n",
            "972 episode , 200 step , 22.36 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[183, 4, 13]\n",
            "973 episode , 200 step , 22.37 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[178, 5, 17]\n",
            "974 episode , 200 step , 22.30 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.72 Top reward\n",
            "[187, 5, 8]\n",
            "975 episode , 200 step , 22.32 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[175, 5, 20]\n",
            "976 episode , 200 step , 22.30 Actor Loss, 0.10 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[181, 4, 15]\n",
            "977 episode , 200 step , 22.33 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.73 Top reward\n",
            "[181, 2, 17]\n",
            "978 episode , 200 step , 22.37 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[180, 4, 16]\n",
            "979 episode , 200 step , 22.39 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[178, 4, 18]\n",
            "980 episode , 200 step , 22.38 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[185, 0, 15]\n",
            "981 episode , 200 step , 22.35 Actor Loss, 0.07 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[180, 5, 15]\n",
            "982 episode , 200 step , 22.36 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[172, 7, 21]\n",
            "983 episode , 200 step , 22.37 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[188, 3, 9]\n",
            "984 episode , 200 step , 22.36 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[181, 7, 12]\n",
            "985 episode , 200 step , 22.33 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[184, 5, 11]\n",
            "986 episode , 200 step , 22.33 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[180, 8, 12]\n",
            "987 episode , 200 step , 22.31 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[183, 6, 11]\n",
            "988 episode , 200 step , 22.31 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.79 Top reward\n",
            "[174, 5, 21]\n",
            "989 episode , 200 step , 22.27 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[175, 4, 21]\n",
            "990 episode , 200 step , 22.27 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[183, 5, 12]\n",
            "991 episode , 200 step , 22.29 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[173, 7, 20]\n",
            "992 episode , 200 step , 22.27 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.75 Top reward\n",
            "[183, 3, 14]\n",
            "993 episode , 200 step , 22.31 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.85 Top reward\n",
            "[160, 18, 22]\n",
            "994 episode , 200 step , 22.32 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[180, 9, 11]\n",
            "995 episode , 200 step , 22.29 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[176, 3, 21]\n",
            "996 episode , 200 step , 22.27 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.78 Top reward\n",
            "[182, 4, 14]\n",
            "997 episode , 200 step , 22.29 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.76 Top reward\n",
            "[175, 5, 20]\n",
            "998 episode , 200 step , 22.31 Actor Loss, 0.08 Critic Loss,  0.05 Threshold , 0.77 Top reward\n",
            "[185, 3, 12]\n",
            "999 episode , 200 step , 22.27 Actor Loss, 0.09 Critic Loss,  0.05 Threshold , 0.74 Top reward\n",
            "[181, 1, 18]\n",
            "Complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng5OCmZk1OCmYmVnD/wcYR2SoGBcPvgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pWWG7HcMD3j",
        "colab_type": "text"
      },
      "source": [
        "## Rendering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jaeim4ulL0y7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "outputId": "130725a6-9128-448e-99f0-68974c8fdde0"
      },
      "source": [
        "# Imports specifically so we can render outputs in Colab.\n",
        "!pip install JSAnimation\n",
        "from matplotlib import animation\n",
        "from JSAnimation.IPython_display import display_animation\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "def display_frames_as_gif(frames):\n",
        "    \"\"\"Displays a list of frames as a gif, with controls.\"\"\"\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis('off')\n",
        "\n",
        "    def animate(i):\n",
        "        patch.set_data(frames[i])\n",
        "\n",
        "    anim = animation.FuncAnimation(\n",
        "        plt.gcf(), animate, frames = len(frames), interval=50\n",
        "    )\n",
        "    display(display_animation(anim, default_mode='loop'))\n",
        "    \n",
        "        \n",
        "# display \n",
        "display_frames_as_gif(frames)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting JSAnimation\n",
            "  Downloading https://files.pythonhosted.org/packages/3c/e6/a93a578400c38a43af8b4271334ed2444b42d65580f1d6721c9fe32e9fd8/JSAnimation-0.1.tar.gz\n",
            "Building wheels for collected packages: JSAnimation\n",
            "  Building wheel for JSAnimation (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for JSAnimation: filename=JSAnimation-0.1-cp36-none-any.whl size=11425 sha256=6d076dd2d580c40fe841827d07179aedb442f11778b70d2a05583fd250bc3f0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/c2/b2/b444dffc3eed9c78139288d301c4009a42c0dd061d3b62cead\n",
            "Successfully built JSAnimation\n",
            "Installing collected packages: JSAnimation\n",
            "Successfully installed JSAnimation-0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-9399f442a5ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdisplay_frames_as_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-9399f442a5ce>\u001b[0m in \u001b[0;36mdisplay_frames_as_gif\u001b[0;34m(frames)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manimate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     )\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay_animation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/JSAnimation/IPython_display.py\u001b[0m in \u001b[0;36mdisplay_animation\u001b[0;34m(anim, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;34m\"\"\"Display the animation with an IPython HTML object\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manim_to_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/JSAnimation/IPython_display.py\u001b[0m in \u001b[0;36manim_to_html\u001b[0;34m(anim, fps, embed_frames, default_mode)\u001b[0m\n\u001b[1;32m     74\u001b[0m             anim.save(f.name,  writer=HTMLWriter(fps=fps,\n\u001b[1;32m     75\u001b[0m                                                  \u001b[0membed_frames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membed_frames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                                                  default_mode=default_mode))\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                             \u001b[0mprogress_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                             \u001b[0mframe_number\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrab_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0;31m# Reconnect signal for first draw if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msaving\u001b[0;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36mfinish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;31m# are available to be assembled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0mMovieWriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Will call clean-up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36mfinish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;34m'''Finish any processing for writing the movie.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrab_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36mcleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0mMovieWriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;31m# Delete temporary files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36mcleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_frame_sink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;31m# Use the encoding/errors that universal_newlines would use.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextIOWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m         \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextIOWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8LGoLHib8F3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}