{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x168565fb4b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.CIFAR100('./data/', train=True, transform= trans, download=True)\n",
    "test_data = torchvision.datasets.CIFAR100('./data/', train=False, transform= trans, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=8,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=8,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_channel_1 = 32\n",
    "conv_channel_2 = 32\n",
    "conv_channel_3 = 64\n",
    "conv_channel_4 = 64\n",
    "conv_channel_5 = 128\n",
    "\n",
    "hidden1_size = 1024\n",
    "#hidden2_size = 300\n",
    "hidden2_size = 1024\n",
    "out_size = 100\n",
    "epoch = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def fit(epoch, data_loader, model, opt, phase):\n",
    "    if phase=='train':\n",
    "        volatile = False\n",
    "        model.train()\n",
    "    else:\n",
    "        volatile = True\n",
    "        model.eval()       \n",
    "        \n",
    "    learning_loss = 0.\n",
    "    learning_correct = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(data_loader):\n",
    "        if phase == 'train':\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        inputs = Variable(inputs, volatile).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss_value = loss(outputs, labels)\n",
    "        learning_loss += loss_value.item() * inputs.shape[0]\n",
    "        \n",
    "        if phase == 'train':\n",
    "            loss_value.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        learning_correct += (preds == labels).sum().item()\n",
    "        \n",
    "    epoch_loss = learning_loss /len(data_loader.dataset)\n",
    "    epoch_correct = learning_correct / len(data_loader.dataset) * 100.\n",
    "    \n",
    "    print(f'epoch = {epoch} -> {phase:{5}} / loss = {epoch_loss:{8}.{3}}, correct = {epoch_correct:{8}.{4}}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class commonLinear(nn.Module):\n",
    "    def __init__(self, nin):\n",
    "        super(commonLinear, self).__init__()\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Linear(nin, hidden2_size),\n",
    "            nn.ReLU(),\n",
    "#             nn.Linear(hidden1_size, hidden2_size),\n",
    "#             nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden2_size, out_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class normalCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(normalCNN,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, conv_channel_1, 3, padding=1),\n",
    "            nn.BatchNorm2d(conv_channel_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(conv_channel_1, conv_channel_2, 3, padding=1),\n",
    "            nn.BatchNorm2d(conv_channel_2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(conv_channel_2, conv_channel_3, 3, padding=1),\n",
    "            nn.BatchNorm2d(conv_channel_3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(conv_channel_3, conv_channel_4, 3, padding=1),\n",
    "            nn.BatchNorm2d(conv_channel_4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(conv_channel_4, conv_channel_5, 3, padding=1),\n",
    "            nn.BatchNorm2d(conv_channel_5),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2,2)\n",
    "        )\n",
    "        \n",
    "        self.fc = commonLinear(conv_channel_5*4*4)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv(x)\n",
    "        x=x.view(-1,conv_channel_5*4*4)\n",
    "        x=self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalCNN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU()\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU()\n",
      "    (17): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (fc): commonLinear(\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=1024, out_features=100, bias=True)\n",
      "      (4): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn1 = normalCNN().cuda()\n",
    "opt1 = optim.SGD(cnn1.parameters(), lr=0.01, momentum=0.9)\n",
    "print(cnn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0 -> train / loss =     4.16, correct =    7.972%\n",
      "epoch = 0 -> eval  / loss =     3.36, correct =     20.0%\n",
      "77.9985\n",
      "\n",
      "epoch = 1 -> train / loss =     3.23, correct =     21.8%\n",
      "epoch = 1 -> eval  / loss =     2.63, correct =    32.87%\n",
      "76.0277\n",
      "\n",
      "epoch = 2 -> train / loss =     2.69, correct =    31.69%\n",
      "epoch = 2 -> eval  / loss =     2.33, correct =    39.54%\n",
      "75.2807\n",
      "\n",
      "epoch = 3 -> train / loss =     2.36, correct =    38.62%\n",
      "epoch = 3 -> eval  / loss =     2.14, correct =    43.91%\n",
      "75.4553\n",
      "\n",
      "epoch = 4 -> train / loss =      2.1, correct =    44.61%\n",
      "epoch = 4 -> eval  / loss =     2.04, correct =    46.25%\n",
      "75.4493\n",
      "\n",
      "epoch = 5 -> train / loss =     1.91, correct =    48.57%\n",
      "epoch = 5 -> eval  / loss =     1.95, correct =    48.68%\n",
      "74.9187\n",
      "\n",
      "epoch = 6 -> train / loss =     1.73, correct =    52.73%\n",
      "epoch = 6 -> eval  / loss =     1.92, correct =    50.02%\n",
      "75.0623\n",
      "\n",
      "epoch = 7 -> train / loss =     1.58, correct =    56.45%\n",
      "epoch = 7 -> eval  / loss =     1.88, correct =    51.31%\n",
      "75.2389\n",
      "\n",
      "epoch = 8 -> train / loss =     1.44, correct =    59.57%\n",
      "epoch = 8 -> eval  / loss =     1.94, correct =    50.95%\n",
      "75.0793\n",
      "\n",
      "epoch = 9 -> train / loss =     1.31, correct =    62.56%\n",
      "epoch = 9 -> eval  / loss =     1.94, correct =    51.67%\n",
      "75.3715\n",
      "\n",
      "epoch = 10 -> train / loss =     1.19, correct =    65.81%\n",
      "epoch = 10 -> eval  / loss =     1.96, correct =    51.12%\n",
      "75.1750\n",
      "\n",
      "epoch = 11 -> train / loss =     1.09, correct =    68.22%\n",
      "epoch = 11 -> eval  / loss =     1.96, correct =    52.29%\n",
      "75.7285\n",
      "\n",
      "epoch = 12 -> train / loss =     1.01, correct =    70.41%\n",
      "epoch = 12 -> eval  / loss =     2.06, correct =    52.14%\n",
      "75.4772\n",
      "\n",
      "epoch = 13 -> train / loss =    0.907, correct =    73.31%\n",
      "epoch = 13 -> eval  / loss =     2.19, correct =    51.35%\n",
      "75.3924\n",
      "\n",
      "epoch = 14 -> train / loss =    0.841, correct =    74.99%\n",
      "epoch = 14 -> eval  / loss =     2.15, correct =    51.69%\n",
      "75.0813\n",
      "\n",
      "epoch = 15 -> train / loss =    0.777, correct =    76.67%\n",
      "epoch = 15 -> eval  / loss =     2.28, correct =    51.75%\n",
      "75.4324\n",
      "\n",
      "epoch = 16 -> train / loss =    0.707, correct =    78.67%\n",
      "epoch = 16 -> eval  / loss =     2.21, correct =    52.35%\n",
      "75.9190\n",
      "\n",
      "epoch = 17 -> train / loss =    0.672, correct =    79.62%\n",
      "epoch = 17 -> eval  / loss =     2.35, correct =    51.51%\n",
      "75.2249\n",
      "\n",
      "epoch = 18 -> train / loss =    0.617, correct =    81.42%\n",
      "epoch = 18 -> eval  / loss =      2.4, correct =    52.52%\n",
      "75.1800\n",
      "\n",
      "epoch = 19 -> train / loss =    0.576, correct =     82.7%\n",
      "epoch = 19 -> eval  / loss =     2.47, correct =    51.79%\n",
      "75.6926\n",
      "\n",
      "epoch = 20 -> train / loss =    0.555, correct =    83.26%\n",
      "epoch = 20 -> eval  / loss =     2.48, correct =    52.16%\n",
      "75.2688\n",
      "\n",
      "epoch = 21 -> train / loss =    0.521, correct =     84.1%\n",
      "epoch = 21 -> eval  / loss =     2.51, correct =    52.28%\n",
      "75.0244\n",
      "\n",
      "epoch = 22 -> train / loss =    0.499, correct =    84.92%\n",
      "epoch = 22 -> eval  / loss =     2.58, correct =    52.19%\n",
      "75.4054\n",
      "\n",
      "epoch = 23 -> train / loss =    0.471, correct =    85.82%\n",
      "epoch = 23 -> eval  / loss =     2.73, correct =    51.57%\n",
      "75.6398\n",
      "\n",
      "epoch = 24 -> train / loss =    0.451, correct =     86.3%\n",
      "epoch = 24 -> eval  / loss =      2.8, correct =    51.18%\n",
      "75.3555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ep in range(epoch):\n",
    "    t= time.time()\n",
    "    fit(ep, train_loader, cnn1, opt1, 'train')\n",
    "    fit(ep, test_loader, cnn1, opt1, 'eval')\n",
    "    print('%.4f'%(time.time()-t))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class depthwiseCNN(nn.Module):\n",
    "    def __init__(self,nin,nout):\n",
    "        super(depthwiseCNN,self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(nin,nin,3,groups=nin, padding=1),\n",
    "            nn.BatchNorm2d(nin),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(nin,nout,1),\n",
    "            nn.BatchNorm2d(nout),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "        \n",
    "class separableCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(separableCNN,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            depthwiseCNN(3,conv_channel_1),\n",
    "            depthwiseCNN(conv_channel_1,conv_channel_2),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            depthwiseCNN(conv_channel_2,conv_channel_3),\n",
    "            depthwiseCNN(conv_channel_3,conv_channel_4),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            depthwiseCNN(conv_channel_4,conv_channel_5),\n",
    "            nn.AvgPool2d(2,2)\n",
    "        )\n",
    "        \n",
    "        self.fc = commonLinear(conv_channel_5*4*4)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv(x)\n",
    "        x=x.view(-1,conv_channel_5*4*4)\n",
    "        x=self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "separableCNN(\n",
      "  (conv): Sequential(\n",
      "    (0): depthwiseCNN(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3)\n",
      "        (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (1): depthwiseCNN(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): depthwiseCNN(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (4): depthwiseCNN(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): depthwiseCNN(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (7): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (fc): commonLinear(\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=1024, out_features=100, bias=True)\n",
      "      (4): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn2 = separableCNN().cuda()\n",
    "opt2 = optim.SGD(cnn2.parameters(), lr=0.01, momentum=0.9)\n",
    "print(cnn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0 -> train / loss =     4.26, correct =    6.438%\n",
      "epoch = 0 -> eval  / loss =     3.52, correct =    16.69%\n",
      "119.0876\n",
      "\n",
      "epoch = 1 -> train / loss =     3.38, correct =    19.11%\n",
      "epoch = 1 -> eval  / loss =      2.8, correct =    29.56%\n",
      "117.5487\n",
      "\n",
      "epoch = 2 -> train / loss =     2.92, correct =    27.82%\n",
      "epoch = 2 -> eval  / loss =     2.49, correct =    35.34%\n",
      "117.6225\n",
      "\n",
      "epoch = 3 -> train / loss =     2.63, correct =    33.36%\n",
      "epoch = 3 -> eval  / loss =      2.4, correct =    37.95%\n",
      "119.0447\n",
      "\n",
      "epoch = 4 -> train / loss =     2.44, correct =    37.28%\n",
      "epoch = 4 -> eval  / loss =     2.24, correct =    42.37%\n",
      "120.0570\n",
      "\n",
      "epoch = 5 -> train / loss =     2.28, correct =    40.43%\n",
      "epoch = 5 -> eval  / loss =     2.21, correct =    42.46%\n",
      "119.1794\n",
      "\n",
      "epoch = 6 -> train / loss =     2.13, correct =    44.04%\n",
      "epoch = 6 -> eval  / loss =     2.08, correct =    45.54%\n",
      "118.5441\n",
      "\n",
      "epoch = 7 -> train / loss =     2.02, correct =    46.48%\n",
      "epoch = 7 -> eval  / loss =     2.09, correct =    45.09%\n",
      "120.3522\n",
      "\n",
      "epoch = 8 -> train / loss =      1.9, correct =    49.28%\n",
      "epoch = 8 -> eval  / loss =     2.07, correct =    46.74%\n",
      "120.1687\n",
      "\n",
      "epoch = 9 -> train / loss =     1.79, correct =    51.56%\n",
      "epoch = 9 -> eval  / loss =     2.05, correct =    47.74%\n",
      "119.6202\n",
      "\n",
      "epoch = 10 -> train / loss =     1.69, correct =    53.66%\n",
      "epoch = 10 -> eval  / loss =     2.11, correct =    46.84%\n",
      "120.1069\n",
      "\n",
      "epoch = 11 -> train / loss =     1.59, correct =    56.13%\n",
      "epoch = 11 -> eval  / loss =     2.02, correct =    48.29%\n",
      "119.1535\n",
      "\n",
      "epoch = 12 -> train / loss =      1.5, correct =    58.42%\n",
      "epoch = 12 -> eval  / loss =     2.11, correct =    47.73%\n",
      "120.9257\n",
      "\n",
      "epoch = 13 -> train / loss =      1.4, correct =    60.72%\n",
      "epoch = 13 -> eval  / loss =     2.12, correct =    48.46%\n",
      "121.4782\n",
      "\n",
      "epoch = 14 -> train / loss =     1.32, correct =    62.87%\n",
      "epoch = 14 -> eval  / loss =     2.14, correct =    48.77%\n",
      "120.7502\n",
      "\n",
      "epoch = 15 -> train / loss =     1.25, correct =    64.43%\n",
      "epoch = 15 -> eval  / loss =      2.2, correct =    49.33%\n",
      "120.7182\n",
      "\n",
      "epoch = 16 -> train / loss =     1.18, correct =    66.37%\n",
      "epoch = 16 -> eval  / loss =     2.17, correct =    48.86%\n",
      "119.4247\n",
      "\n",
      "epoch = 17 -> train / loss =     1.12, correct =     67.9%\n",
      "epoch = 17 -> eval  / loss =     2.21, correct =    48.78%\n",
      "119.0697\n",
      "\n",
      "epoch = 18 -> train / loss =     1.06, correct =    69.44%\n",
      "epoch = 18 -> eval  / loss =      2.3, correct =    48.48%\n",
      "120.0221\n",
      "\n",
      "epoch = 19 -> train / loss =    0.998, correct =    70.94%\n",
      "epoch = 19 -> eval  / loss =      2.3, correct =    48.73%\n",
      "119.7449\n",
      "\n",
      "epoch = 20 -> train / loss =    0.947, correct =     72.4%\n",
      "epoch = 20 -> eval  / loss =     2.44, correct =    48.42%\n",
      "118.8453\n",
      "\n",
      "epoch = 21 -> train / loss =    0.909, correct =     73.4%\n",
      "epoch = 21 -> eval  / loss =     2.42, correct =    49.28%\n",
      "119.0098\n",
      "\n",
      "epoch = 22 -> train / loss =     0.88, correct =    74.22%\n",
      "epoch = 22 -> eval  / loss =     2.46, correct =    48.16%\n",
      "118.6877\n",
      "\n",
      "epoch = 23 -> train / loss =     0.84, correct =    75.44%\n",
      "epoch = 23 -> eval  / loss =     2.52, correct =    47.57%\n",
      "119.4975\n",
      "\n",
      "epoch = 24 -> train / loss =    0.797, correct =    76.51%\n",
      "epoch = 24 -> eval  / loss =     2.62, correct =    48.43%\n",
      "120.1668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ep in range(epoch):\n",
    "    t=time.time()\n",
    "    fit(ep, train_loader, cnn2, opt2, 'train')\n",
    "    fit(ep, test_loader, cnn2, opt2, 'eval')\n",
    "    print('%.4f'%(time.time()-t))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inception(nn.Module):\n",
    "    def __init__(self, nin, nout):\n",
    "        super(inception,self).__init__()\n",
    "        self.model1x1 = nn.Sequential(\n",
    "            nn.Conv2d(nin, int(nout/4), 1)\n",
    "        )\n",
    "        self.model3x3 = nn.Sequential(\n",
    "            nn.Conv2d(nin,int(nout/8),1),\n",
    "            nn.Conv2d(int(nout/8),int(nout/4),3, padding=1)\n",
    "        )\n",
    "        self.model5x5 = nn.Sequential(\n",
    "            nn.Conv2d(nin,int(nout/16),1),\n",
    "            nn.Conv2d(int(nout/16),int(nout/8),3,padding=1),\n",
    "            nn.Conv2d(int(nout/8),int(nout/4),3,padding=1)\n",
    "        )\n",
    "        self.modelmax = nn.Sequential(\n",
    "            nn.MaxPool2d(3, stride=1, padding=1),\n",
    "            nn.Conv2d(nin,int(nout/4),1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        part1x1=self.model1x1(x)\n",
    "        part3x3=self.model3x3(x)\n",
    "        part5x5=self.model5x5(x)\n",
    "        partmax=self.modelmax(x)\n",
    "        outputs= [part1x1, part3x3, part5x5, partmax]\n",
    "        return torch.cat(outputs,1)\n",
    "    \n",
    "class inceptionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(inceptionCNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3,conv_channel_1, 3, padding=1),\n",
    "            nn.BatchNorm2d(conv_channel_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(conv_channel_2, conv_channel_2, 3, padding=1),\n",
    "            nn.BatchNorm2d(conv_channel_1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(conv_channel_1, conv_channel_2, 3, padding=1),\n",
    "            nn.BatchNorm2d(conv_channel_2),\n",
    "            nn.ReLU(),\n",
    "            inception(conv_channel_2, conv_channel_3),\n",
    "            nn.BatchNorm2d(conv_channel_3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            inception(conv_channel_3, conv_channel_4),\n",
    "            nn.BatchNorm2d(conv_channel_4),\n",
    "            nn.ReLU(),\n",
    "            inception(conv_channel_4, conv_channel_5),\n",
    "            nn.BatchNorm2d(conv_channel_5),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2,2)\n",
    "        )\n",
    "        \n",
    "        self.fc=commonLinear(conv_channel_5*4*4)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.conv(x)\n",
    "        x=x.view(-1, conv_channel_5*4*4)\n",
    "        x=self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inceptionCNN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU()\n",
      "    (10): inception(\n",
      "      (model1x1): Sequential(\n",
      "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (model3x3): Sequential(\n",
      "        (0): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (model5x5): Sequential(\n",
      "        (0): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (modelmax): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU()\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): inception(\n",
      "      (model1x1): Sequential(\n",
      "        (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (model3x3): Sequential(\n",
      "        (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (model5x5): Sequential(\n",
      "        (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (modelmax): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU()\n",
      "    (17): inception(\n",
      "      (model1x1): Sequential(\n",
      "        (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (model3x3): Sequential(\n",
      "        (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (model5x5): Sequential(\n",
      "        (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (modelmax): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (18): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU()\n",
      "    (20): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (fc): commonLinear(\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=1024, out_features=100, bias=True)\n",
      "      (4): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn3 = inceptionCNN().cuda()\n",
    "opt3 = optim.SGD(cnn3.parameters(), lr=0.01, momentum=0.9)\n",
    "print(cnn3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0 -> train / loss =     4.18, correct =    7.584%\n",
      "epoch = 0 -> eval  / loss =     3.32, correct =    20.05%\n",
      "170.3735\n",
      "\n",
      "epoch = 1 -> train / loss =     3.32, correct =    20.42%\n",
      "epoch = 1 -> eval  / loss =     2.77, correct =    30.76%\n",
      "170.1372\n",
      "\n",
      "epoch = 2 -> train / loss =     2.88, correct =    28.42%\n",
      "epoch = 2 -> eval  / loss =     2.57, correct =     35.4%\n",
      "169.6704\n",
      "\n",
      "epoch = 3 -> train / loss =     2.62, correct =    33.74%\n",
      "epoch = 3 -> eval  / loss =     2.33, correct =    39.71%\n",
      "168.1554\n",
      "\n",
      "epoch = 4 -> train / loss =     2.42, correct =    37.74%\n",
      "epoch = 4 -> eval  / loss =     2.22, correct =    41.88%\n",
      "168.1624\n",
      "\n",
      "epoch = 5 -> train / loss =     2.25, correct =     41.2%\n",
      "epoch = 5 -> eval  / loss =     2.12, correct =    44.53%\n",
      "167.2399\n",
      "\n",
      "epoch = 6 -> train / loss =     2.11, correct =     44.0%\n",
      "epoch = 6 -> eval  / loss =     2.15, correct =    44.45%\n",
      "166.0850\n",
      "\n",
      "epoch = 7 -> train / loss =     1.97, correct =    47.32%\n",
      "epoch = 7 -> eval  / loss =     2.06, correct =    46.57%\n",
      "165.7200\n",
      "\n",
      "epoch = 8 -> train / loss =     1.87, correct =    49.55%\n",
      "epoch = 8 -> eval  / loss =     2.05, correct =    47.78%\n",
      "166.6216\n",
      "\n",
      "epoch = 9 -> train / loss =     1.75, correct =    52.41%\n",
      "epoch = 9 -> eval  / loss =     2.01, correct =     47.8%\n",
      "169.1279\n",
      "\n",
      "epoch = 10 -> train / loss =     1.65, correct =    54.68%\n",
      "epoch = 10 -> eval  / loss =     2.03, correct =    48.45%\n",
      "168.8207\n",
      "\n",
      "epoch = 11 -> train / loss =     1.56, correct =    56.83%\n",
      "epoch = 11 -> eval  / loss =     2.03, correct =    48.29%\n",
      "167.3207\n",
      "\n",
      "epoch = 12 -> train / loss =     1.46, correct =    59.16%\n",
      "epoch = 12 -> eval  / loss =     2.09, correct =    48.34%\n",
      "165.8386\n",
      "\n",
      "epoch = 13 -> train / loss =     1.37, correct =    61.55%\n",
      "epoch = 13 -> eval  / loss =      2.1, correct =    49.08%\n",
      "165.8376\n",
      "\n",
      "epoch = 14 -> train / loss =     1.29, correct =    63.24%\n",
      "epoch = 14 -> eval  / loss =     2.08, correct =    49.62%\n",
      "164.9430\n",
      "\n",
      "epoch = 15 -> train / loss =     1.22, correct =    65.08%\n",
      "epoch = 15 -> eval  / loss =     2.13, correct =    49.82%\n",
      "165.7210\n",
      "\n",
      "epoch = 16 -> train / loss =     1.16, correct =    66.86%\n",
      "epoch = 16 -> eval  / loss =     2.21, correct =    48.47%\n",
      "165.9194\n",
      "\n",
      "epoch = 17 -> train / loss =     1.08, correct =    68.76%\n",
      "epoch = 17 -> eval  / loss =     2.22, correct =    49.58%\n",
      "167.9161\n",
      "\n",
      "epoch = 18 -> train / loss =     1.02, correct =    70.29%\n",
      "epoch = 18 -> eval  / loss =      2.3, correct =    49.41%\n",
      "166.6196\n",
      "\n",
      "epoch = 19 -> train / loss =    0.972, correct =    71.82%\n",
      "epoch = 19 -> eval  / loss =     2.38, correct =     48.8%\n",
      "166.7033\n",
      "\n",
      "epoch = 20 -> train / loss =    0.913, correct =     73.2%\n",
      "epoch = 20 -> eval  / loss =     2.39, correct =    49.08%\n",
      "166.4420\n",
      "\n",
      "epoch = 21 -> train / loss =    0.875, correct =    74.37%\n",
      "epoch = 21 -> eval  / loss =     2.42, correct =    49.84%\n",
      "166.2515\n",
      "\n",
      "epoch = 22 -> train / loss =    0.829, correct =    75.68%\n",
      "epoch = 22 -> eval  / loss =     2.41, correct =    49.55%\n",
      "166.5338\n",
      "\n",
      "epoch = 23 -> train / loss =    0.801, correct =    76.58%\n",
      "epoch = 23 -> eval  / loss =     2.58, correct =    49.34%\n",
      "166.2246\n",
      "\n",
      "epoch = 24 -> train / loss =     0.77, correct =    77.05%\n",
      "epoch = 24 -> eval  / loss =      2.6, correct =    48.85%\n",
      "166.8240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ep in range(epoch):\n",
    "    t=time.time()\n",
    "    fit(ep, train_loader, cnn3, opt3, 'train')\n",
    "    fit(ep, test_loader, cnn3, opt3, 'eval')\n",
    "    print('%.4f'%(time.time()-t))\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
