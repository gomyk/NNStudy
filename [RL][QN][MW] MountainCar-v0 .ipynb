{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMT3S7DtDFp+fcGJvVcO/ro",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gomyk/NNStudy/blob/moonwon/%5BRL%5D%5BQN%5D%5BMW%5D%20MountainCar-v0%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9duZfSLhJ8X",
        "colab_type": "code",
        "outputId": "a3b36b9d-bd24-4395-8318-79395c7f754d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!apt-get install x11-utils"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "x11-utils is already the newest version (7.7+3build1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DE8ejMqcTWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import base64\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "from google.colab import output\n",
        "\n",
        "display = Display(visible=0, size=(400,600),)\n",
        "display.start()\n",
        "env = gym.make(\"MountainCar-v0\")\n",
        "\n",
        "#env = gym.wrappers.Monitor(gym.make(\"CartPole-v1\"), \"video\", force=True, video_callable=lambda c:c%100 ==0)\n",
        "\n",
        "# GPU를 사용할 경우\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmc6Jfr2d8_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"transition 저장\"\"\"\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = Transition(*args)\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1hagvrqKTpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HIDDEN_SIZE = 256\n",
        "class DQN_custom(nn.Module):\n",
        "\n",
        "    def __init__(self, obs_size, outputs):\n",
        "        super(DQN_custom, self).__init__()\n",
        "        self.linear = nn.Linear(obs_size, HIDDEN_SIZE)\n",
        "        self.linear2 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.linear3 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.head = nn.Linear(HIDDEN_SIZE, outputs)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.linear(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = F.relu(self.linear3(x))\n",
        "        return self.head(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVgLn9rKgS79",
        "colab_type": "code",
        "outputId": "42e860b8-1e0a-452c-98e3-81f79c60be40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "env.reset()\n",
        "plt.figure()\n",
        "plt.imshow(env.render(mode='rgb_array'))\n",
        "plt.title('Example extracted screen')\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAa+UlEQVR4nO3dfZBc1X3m8e9jSQhsZMTLoBKSiDCW\nw8JWLMxEyGXvLobYlsmLSMVLYBMjKLKyd+UK1LK2gVQtYtfUmkqMElcSYjkill9ijF8IMotjy0Je\nL7XhZYQFSAjMgMVKipAGkHhZHDYSv/3jnkZXo+7p7unXe/v5VHX1veeevn1OT8/Tp0/f262IwMzM\niuMtvW6AmZk1x8FtZlYwDm4zs4JxcJuZFYyD28ysYBzcZmYF4+C2npF0uaT7et2OfiJpvqSQNLXX\nbbH+5eAuKUnbJf1C0qu5y5/3ul29Juk8STs7uP+Vkr7Wqf2bAfhVvdx+MyJ+1OtGFI2kqRFxoNft\n6IQy922QeMQ9gCTdKuk7ufWbJW1Q5nhJd0sak7QvLc/N1f2xpM9K+t9pFP89SSdK+rqklyU9JGl+\nrn5I+kNJz0h6XtIfS6r6vJN0hqT1kl6U9KSkiyfow3GS1kjaLWlXatOUOv17G/B94JTcu5BT0ij5\n25K+Jull4HJJiyT9g6T96T7+XNJRuX2elWvrHknXS1oCXA/8btr3Iw20dYqkP0mPzTPAr9f5230m\n7eOV9BhdkNvP9ZKeTts2SZqX+xuskPQU8FS9x1rS9NSm/5P69leSjknbzpO0U9I1kvamPl0xUZut\nAyLClxJegO3Ar9XY9lbgZ8DlwL8Cngfmpm0nAr+T6swAvgX8Xe62PwZGgdOB44DH075+jewd3FeA\nv8nVD2AjcAJwaqr7B2nb5cB9afltwA7girSfs1O7zqzRhzuBL6bbnQw8CHy8gf6dB+wct6+VwD8D\nF5ENZo4BzgEWp7bMB7YBV6f6M4DdwDXA0Wn93Ny+vtZEWz8BPAHMS4/RxvSYTa3S519Oj9EpaX0+\ncHpa/hTwWKoj4N3Aibm/wfq0/2PqPdbAKmBdqj8D+B7w33OP3wHgvwLTgAuB14Dje/2cH6RLzxvg\nS4f+sFlwvwrsz13+fW77ucCLwLPApRPsZyGwL7f+Y+CPcuufB76fW/9NYHNuPYAlufX/CGxIy5dz\nKLh/F/hf4+77i8ANVdo0C3gdOCZXdimwsV7/qB3cP6nzeF4N3Jm7r5/WqLeSXHDXaytwL/CJ3LYP\nUTu43wnsJXuRnDZu25PA0hptCuD83HrNx5os9P8v6QUhbXsv8PPc4/eLfPtSmxb3+jk/SBfPcZfb\nRVFjjjsiHkhvzU8G7qiUS3or2YhrCXB8Kp4haUpEHEzre3K7+kWV9WPH3d2O3PKzwClVmvRLwLmS\n9ufKpgJfrVF3GrBbUqXsLfn7qdW/CeTbiKR3AbcAw2Qj+KnAprR5HvB0A/tspK2ncOTjU1VEjEq6\nmuzF4SxJPwD+U0T8YwNtyt/HRI/1EFl/N+XaK2BKru4Lcfg8+Wsc+Te3DvIc94CStAKYDvwj8Onc\npmvI3m6fGxFvB/515SYt3N283PKp6T7H2wH8z4iYmbscGxH/oUbd14GTcnXfHhFnVSpM0L9aX4c5\nvvxWsimMBelxuJ5Dj8EO4B0N7qdeW3dz5ONTU0T8bUS8nyx8A7g5dz+nT3TTcW2q9Vg/T/bie1Zu\n23ER4WDuIw7uAZRGk58Ffh/4GPBpSQvT5hlk/7j7JZ1A9va5VZ9KH3rOA64Cvlmlzt3AuyR9TNK0\ndPlVSf9ifMWI2A38EPi8pLdLeouk0yX9mwb6twc4UdJxddo8A3gZeFXSGUD+BeRuYLakq9MHeTMk\nnZvb//zKB7D12kr2buAPJc2VdDxwba0GSfplSedLmg78E9nf6Y20+a+B/yZpgTK/IunEGruq+VhH\nxBvAl4BVkk5O9ztH0ofrPF7WRQ7ucvueDj+O+05lJ3Z8Dbg5Ih6JiKfIRpNfTYHwp2QfYD0P3A/8\nfRvacRfZNMNm4H8Aa8ZXiIhXyOZ3LyEbJT9HNpqcXmOflwFHkX04ug/4NlmYTti/iHgC+AbwTDpi\npNq0DcB/Bv4d8ApZkL35YpPa+kGy+fznyI7U+EDa/K10/YKkhydqa9r2JeAHwCPAw8B3a7SH9Fh8\njuxv8xzZNNB1adstZC8CPyR7wVlD9nc8QgOP9WfIPoC+Px1l8yOyd2HWJxThH1KwzpEUZNMNo71u\ni1lZeMRtZlYwHQtuSUvSgf2jkmrO25mZWXM6MlWSzgr7Gdk84E7gIbJjaR9v+52ZmQ2YTo24FwGj\nEfFMRPw/4HZgaYfuy8xsoHTqBJw5HH7A/06yM9mqOumkk2L+/PkdaoqZWfFs376d559/vur5Ez07\nc1LScmA5wKmnnsrIyEivmmJm1neGh4drbuvUVMkuDj8bbG4qe1NErI6I4YgYHhoa6lAzzMzKp1PB\n/RCwQNJpyr4K8xKybxszM7MWdWSqJCIOSPok2RlhU4DbImJrJ+7LzGzQdGyOOyLuAe7p1P7NzAaV\nz5w0MysYB7eZWcE4uM3MCsbBbWbWRpLYtKmV3x2pzz9dZmbWAbXC+5xzWv9+KAe3mVkXVQv0ZsPc\nUyVmZgXjEbeZWRd5qsTMrE+1I6Br8VSJmVmbdTK0wcFtZlY4Dm4zs4JxcJuZFYyD28ysYBzcZmYF\n4+A2MysYB7eZWcE4uM3MCsbBbWZWMC2d8i5pO/AKcBA4EBHDkk4AvgnMB7YDF0fEvtaaaWZmFe0Y\ncX8gIhZGxHBavxbYEBELgA1p3czM2qQTUyVLgbVpeS1wUQfuw8xsYLUa3AH8UNImSctT2ayI2J2W\nnwNmVbuhpOWSRiSNjI2NtdgMM7PB0erXur4/InZJOhlYL+mJ/MaICElVvyYrIlYDqwGGh4c7+1Va\nZmYl0tKIOyJ2peu9wJ3AImCPpNkA6Xpvq400M7NDJh3ckt4maUZlGfgQsAVYByxL1ZYBd7XaSDMz\nO6SVqZJZwJ2SKvv524j4e0kPAXdIuhJ4Fri49WaamVnFpIM7Ip4B3l2l/AXgglYaZWZmtfnMSTOz\ngvGPBZuZtUmaOn7zup6IyR1Q5+A2M2tBoyHdyG0bDXIHt5lZE1oJ6nbt28FtZjaBemE62emOydxX\nhYPbzKyKWiHazqCeaN/Dw8M16zm4zcySamHdyaCeLAe3mQ28ogR2hYPbzAbaZI/s6CUHt5kNpCIG\ndoWD28wGSpEDu8LBbWYDoQyBXeHgNrPSy4d2kQO7wsFtZqVVtsCu8LcDmlkpdfLU9F7ziNvMSqes\nI+0KB7eZlUoltMsY2BUObjMrhbKPsvPqznFLuk3SXklbcmUnSFov6al0fXwql6QvSBqV9Kik93Sy\n8WZmMFihDY19OPllYMm4smuBDRGxANiQ1gE+AixIl+XAre1pppnZkSQdNjUyCKENDQR3RPwEeHFc\n8VJgbVpeC1yUK/9KZO4HZkqa3a7GmplVDNooO2+yhwPOiojdafk5YFZangPsyNXbmcqOIGm5pBFJ\nI2NjY5NshpkNukELbWjDcdyRPWpNP3IRsToihiNieGhoqNVmmNkAGYQjRyYy2eDeU5kCSdd7U/ku\nYF6u3txUZmbWFoMe2jD54F4HLEvLy4C7cuWXpaNLFgMv5aZUzMwmbfwHkYOs7nHckr4BnAecJGkn\ncAPwOeAOSVcCzwIXp+r3ABcCo8BrwBUdaLOZDZhB/iCymrrBHRGX1th0QZW6AaxotVFmZhUeZR/J\nXzJlZn3PoX04n/JuZn3JI+3aPOI2s77j0J6Yg9vM+opDuz4Ht5n1DYd2YxzcZtYXHNqNc3CbWc85\ntJvj4DYzKxgHt5n1lEfbzXNwm1nPOLQnxyfgmFnX+btHWuMRt5l1lUO7dQ5uM+sJh/bkObjNrGs8\np90eDm4z6wqHdvs4uM2s4xza7eXgNrOOcmi3n4PbzDomfwSJtU/d4JZ0m6S9krbkylZK2iVpc7pc\nmNt2naRRSU9K+nCnGm5mxeHRdns1MuL+MrCkSvmqiFiYLvcASDoTuAQ4K93mLyVNaVdjzaw4PEXS\nOXWDOyJ+ArzY4P6WArdHxOsR8XOyX3tf1EL7zKyAHNqd1cop75+UdBkwAlwTEfuAOcD9uTo7U9kR\nJC0HlufW/Uc2KwGHdudN9sPJW4HTgYXAbuDzze4gIlZHxHBEDJ9zzjmAP8gwKzqHdndMKrgjYk9E\nHIyIN4AvcWg6ZBcwL1d1biozM7M2mVRwS5qdW/1toHLEyTrgEknTJZ0GLAAebGSflVdoj7rNismj\n7e6pO8ct6RvAecBJknYCNwDnSVoIBLAd+DhARGyVdAfwOHAAWBERBxttTEQgyfPdZgXj0O6uusEd\nEZdWKV4zQf2bgJtaaZSZFYffJXdf3505mZ8y8RPCrL/lR9oebXdP3wU3+O2WWRF4eqR3+jK4wR9W\nmpnV0rfBDQ5vs37l0XZv9XVwm5nZkfo+uD3qNusf+YMGPNrunb4PbnB4m/UD/zp7/yhEcIPD26xf\nOLR7rzDBDQ5vs17x9Eh/KVRwm5lZAYPbo26z7vJou/8ULrjB4W3WLQ7t/lTI4AaHt1mnObT7V2GD\n28w6xwOi/lbo4Pao26z9fLx2/yt0cIPD26xTHNr9q/DBnefwNmuN57WLoRTBnX+SObzNJsehXRx1\ng1vSPEkbJT0uaaukq1L5CZLWS3oqXR+fyiXpC5JGJT0q6T2d7gT4yWZmg6OREfcB4JqIOBNYDKyQ\ndCZwLbAhIhYAG9I6wEfIft19AbAcuLXtra7B891mk+PRdrHUDe6I2B0RD6flV4BtwBxgKbA2VVsL\nXJSWlwJficz9wExJs9ve8trtBRzeZo1yaBdPU3PckuYDZwMPALMiYnfa9BwwKy3PAXbkbrYzlY3f\n13JJI5JGxsbGmmy2mbWDBzjF1HBwSzoW+A5wdUS8nN8W2Ut1Uy/XEbE6IoYjYnhoaKiZmzayb8BP\nSrNGebRdLA0Ft6RpZKH99Yj4bireU5kCSdd7U/kuYF7u5nNTWVc5vM0m5imS4mrkqBIBa4BtEXFL\nbtM6YFlaXgbclSu/LB1dshh4KTel0hMOb7PDObSLbWoDdd4HfAx4TNLmVHY98DngDklXAs8CF6dt\n9wAXAqPAa8AVbW1xEyLizSeoJD9JzXBol0Hd4I6I+4BaQ9YLqtQPYEWL7WqbfHibmZVBKc6crMfz\n3WYZj7bLYSCCGxzeZg7t8hiY4DYbZB6wlMtABbdH3TaI/P3a5TNQwQ0ObxtcDu3yGLjgBoe3DQ7P\na5fTQAa3mVmRDWxwe9RtZefRdnkNbHCDw9vKy6FdbgMd3ODwtvJxaJffwAe3WZl4ADIYHNx41G3l\n4OO1B4eD28ysYBzcSX7U7ZG3FU1+Xtuj7fJzcOf4CW9mReDgHsfz3VY0Popk8Di4q3B4W1E4tAeT\ng7sGh7f1O4f24Grkx4LnSdoo6XFJWyVdlcpXStolaXO6XJi7zXWSRiU9KenDneyA2SDygGKwNfJj\nwQeAayLiYUkzgE2S1qdtqyLiT/KVJZ0JXAKcBZwC/EjSuyLiYDsb3g2V36v0Dw1bv/LzcjDVHXFH\nxO6IeDgtvwJsA+ZMcJOlwO0R8XpE/Jzs194XtaOxveApE+s3niKxpua4Jc0HzgYeSEWflPSopNsk\nHZ/K5gA7cjfbycRBXxgOb+s1h7ZBE8Et6VjgO8DVEfEycCtwOrAQ2A18vpk7lrRc0oikkbGxsWZu\n2nX5fxKHt/WKQ9sqGgpuSdPIQvvrEfFdgIjYExEHI+IN4Escmg7ZBczL3XxuKjtMRKyOiOGIGB4a\nGmqlD13hfxYz6xeNHFUiYA2wLSJuyZXPzlX7bWBLWl4HXCJpuqTTgAXAg+1rcu94vtt6xaNty2vk\nqJL3AR8DHpO0OZVdD1wqaSEQwHbg4wARsVXSHcDjZEekrCjiESW1+EgT6zaHto1XN7gj4j6g2hDz\nnglucxNwUwvtMjP87s6q85mTk+ApE+sGf7+21eLgniSHt3WLQ9vGc3C3wOFtneJ5bZuIg7tNHN7W\nLg5tq8fB3SL/c5lZtzm428BTJtYuHm1bIxzcbeLwtlY5tK1RDu42cnjbZDm0rRkO7jZzeFuzHNrW\nLAe3mVnBOLg7wKNua5RH2zYZDu4OcXhbPQ5tmywHdxc4vG08h7a1wsHdQRHhkbcdwaFtrXJwd4HD\n2yoc2tYODm6zLvELt7WLg7tLPOq2Co+2rVUO7i5yeA8uT5FYOzm4u8zhPXgc2tZujfzK+9GSHpT0\niKStkm5M5adJekDSqKRvSjoqlU9P66Np+/zOdqG4HN7l59C2TmhkxP06cH5EvBtYCCyRtBi4GVgV\nEe8E9gFXpvpXAvtS+apUz3J8mOBgcGhbp9QN7si8mlanpUsA5wPfTuVrgYvS8tK0Ttp+gZxOVTm8\ny8uhbZ3U0By3pCmSNgN7gfXA08D+iDiQquwE5qTlOcAOgLT9JeDEKvtcLmlE0sjY2FhrvTDrI34h\ntk5rKLgj4mBELATmAouAM1q944hYHRHDETE8NDTU6u4Ky6PucsmPtD3atk5p6qiSiNgPbATeC8yU\nNDVtmgvsSsu7gHkAaftxwAttaW1JObzNrBmNHFUyJGlmWj4G+CCwjSzAP5qqLQPuSsvr0jpp+73h\noUddDu/i87y2dcvU+lWYDayVNIUs6O+IiLslPQ7cLumzwE+BNan+GuCrkkaBF4FLOtDuUooIJCHJ\n//wF49C2bqob3BHxKHB2lfJnyOa7x5f/E/Bv29K6AeTwLpb8OyT/vaxbfOZkH/K0SfE4tK2bHNx9\nyuHd/zw9Yr3i4O5jDu/+5dC2XnJw9zmHd/9xaFuvObgLwOHdPxza1g8c3AXh8O6typE+4NC23nNw\nF4jDu/cc2tYPHNwF4/DuPo+0rd84uAsoH94O8M7x9Ij1Kwd3QeWDxOHdfj4j0vqZg7vA/Es6neGv\nZrV+18iXTFmf68b3m1R7YShbqHmUbUXhEXfJdHPkXXmx8GjfrLs84i6Jyqgb6Mk3C04U3kUYvfpD\nSCsSB3eJVDvapB+CqJ9D3dMjVkSeKimhohxx0uugdGhbUXnEXVLjR98OpkMc2FZ0HnGXXDtO1unn\nUXuzHNpWBo38WPDRkh6U9IikrZJuTOVflvRzSZvTZWEql6QvSBqV9Kik93S6EzaxokyddJpD28qi\nkamS14HzI+JVSdOA+yR9P237VER8e1z9jwAL0uVc4NZ0bT00/qiTSlkzVq5c2VR5v3BgW9k08mPB\nAbyaVqely0TP/qXAV9Lt7pc0U9LsiNjdcmutJePPsmxm7nuicF65cmXV7ePLuh3w499dOLStLBqa\n45Y0RdJmYC+wPiIeSJtuStMhqyRNT2VzgB25m+9MZeP3uVzSiKSRsbGxFrpgzRp/qnwnTqJpJMg7\nZXx/fOq6lU1DwR0RByNiITAXWCTpXwLXAWcAvwqcAHymmTuOiNURMRwRw0NDQ00229phfJjVCu92\nTankt3Xj1HwHtpVVU0eVRMR+YCOwJCJ2R+Z14G+ARanaLmBe7mZzU5n1oUq4tToCH7+fbhrfZge2\nlV0jR5UMSZqZlo8BPgg8IWl2KhNwEbAl3WQdcFk6umQx8JLnt4upCEegeB7bBlEjR5XMBtZKmkIW\n9HdExN2S7pU0BAjYDHwi1b8HuBAYBV4Drmh/s60Tqn1FbH651hTIDTfcMKn7max2TemYFVUjR5U8\nCpxdpfz8GvUDWNF606xXah33Xe3okWZDe7Ic1maHqB+e+MPDwzEyMtLrZlgdzXxZ1I033li1XqNB\n389fTGXWDcPDw4yMjFT9R/B3lVjDJvq1nVpBu3Llypph3cwcusPa7BB/V4k1LX8ESb0jOFauXHnY\nUR+NHrXS6P7NBpFH3NYW7fg+FAe0WWMc3NZ2DmCzzvJUiZlZwTi4zcwKxsFtZlYwDm4zs4JxcJuZ\nFYyD28ysYBzcZmYF4+A2MysYB7eZWcE4uM3MCsbBbWZWMA5uM7OCcXCbmRWMg9vMrGAc3GZmBePg\nNjMrmL74sWBJrwBP9rodHXIS8HyvG9EBZe0XlLdv7lex/FJEDFXb0C+/gPNkRAz3uhGdIGmkjH0r\na7+gvH1zv8rDUyVmZgXj4DYzK5h+Ce7VvW5AB5W1b2XtF5S3b+5XSfTFh5NmZta4fhlxm5lZgxzc\nZmYF0/PglrRE0pOSRiVd2+v2NEvSbZL2StqSKztB0npJT6Xr41O5JH0h9fVRSe/pXcsnJmmepI2S\nHpe0VdJVqbzQfZN0tKQHJT2S+nVjKj9N0gOp/d+UdFQqn57WR9P2+b1sfz2Spkj6qaS703pZ+rVd\n0mOSNksaSWWFfi62oqfBLWkK8BfAR4AzgUslndnLNk3Cl4El48quBTZExAJgQ1qHrJ8L0mU5cGuX\n2jgZB4BrIuJMYDGwIv1tit6314HzI+LdwEJgiaTFwM3Aqoh4J7APuDLVvxLYl8pXpXr97CpgW269\nLP0C+EBELMwds1305+LkRUTPLsB7gR/k1q8DrutlmybZj/nAltz6k8DstDyb7AQjgC8Cl1ar1+8X\n4C7gg2XqG/BW4GHgXLIz76am8jefl8APgPem5ampnnrd9hr9mUsWYOcDdwMqQ79SG7cDJ40rK81z\nsdlLr6dK5gA7cus7U1nRzYqI3Wn5OWBWWi5kf9Pb6LOBByhB39J0wmZgL7AeeBrYHxEHUpV829/s\nV9r+EnBid1vcsD8FPg28kdZPpBz9Agjgh5I2SVqeygr/XJysfjnlvbQiIiQV9phLSccC3wGujoiX\nJb25rah9i4iDwEJJM4E7gTN63KSWSfoNYG9EbJJ0Xq/b0wHvj4hdkk4G1kt6Ir+xqM/Fyer1iHsX\nMC+3PjeVFd0eSbMB0vXeVF6o/kqaRhbaX4+I76biUvQNICL2AxvJphBmSqoMZPJtf7NfaftxwAtd\nbmoj3gf8lqTtwO1k0yV/RvH7BUBE7ErXe8lebBdRoudis3od3A8BC9In30cBlwDretymdlgHLEvL\ny8jmhyvll6VPvRcDL+Xe6vUVZUPrNcC2iLglt6nQfZM0lEbaSDqGbN5+G1mAfzRVG9+vSn8/Ctwb\naeK0n0TEdRExNyLmk/0f3RsRv0fB+wUg6W2SZlSWgQ8BWyj4c7ElvZ5kBy4EfkY2z/hHvW7PJNr/\nDWA38M9kc2lXks0VbgCeAn4EnJDqiuwomqeBx4DhXrd/gn69n2xe8VFgc7pcWPS+Ab8C/DT1awvw\nX1L5O4AHgVHgW8D0VH50Wh9N29/R6z400MfzgLvL0q/Uh0fSZWslJ4r+XGzl4lPezcwKptdTJWZm\n1iQHt5lZwTi4zcwKxsFtZlYwDm4zs4JxcJuZFYyD28ysYP4/l6di8uLJaYIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y5GkgVljenU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.999\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 2000\n",
        "TARGET_UPDATE = 10\n",
        "LR = 0.01\n",
        "MEMORY_SIZE = 10000\n",
        "EPISODE_SIZE = 1000\n",
        "\n",
        "# gym 행동 공간에서 행동의 숫자를 얻습니다.\n",
        "n_actions = env.action_space.n\n",
        "n_obvs = 2\n",
        "\n",
        "policy_net = DQN_custom(n_obvs, n_actions).to(device)\n",
        "policy_net.eval()\n",
        "target_net = DQN_custom(n_obvs, n_actions).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=LR)\n",
        "memory = ReplayMemory(MEMORY_SIZE)\n",
        "\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "def select_action(obs):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    steps_done += 1\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            obs = torch.FloatTensor(obs).to(device)\n",
        "            output = policy_net(obs).cpu()\n",
        "            predicted = np.argmax(output.data.numpy())\n",
        "            return torch.tensor([[predicted]],device=device, dtype=torch.long)\n",
        "    else:\n",
        "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
        "\n",
        "\n",
        "episode_durations = []\n",
        "\n",
        "\n",
        "def plot_durations():\n",
        "    plt.figure(2)\n",
        "    plt.clf()\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # 100개의 에피소드 평균을 가져 와서 도표 그리기\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVXUmcMxG3tf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def select_action_target(obs):\n",
        "      with torch.no_grad():\n",
        "         obs = torch.FloatTensor(obs).to(device)\n",
        "         output = target_net(obs).cpu()\n",
        "         predicted = np.argmax(output.data.numpy())\n",
        "         return torch.tensor([[predicted]],device=device, dtype=torch.long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1Vbb4tzjnjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return -1\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation). 이것은 batch-array의 Transitions을 Transition의 batch-arrays로\n",
        "    # 전환합니다.\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    state_batch = torch.cat(batch.state).to(device)\n",
        "    reward_batch = torch.cat(batch.reward).to(device)\n",
        "    action_batch = torch.cat(batch.action).to(device)\n",
        " \n",
        "    non_final_mask = map(lambda s: s is not None, batch.next_state)\n",
        "    non_final_mask = tuple(non_final_mask)\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    non_final_mask = torch.BoolTensor(non_final_mask)\n",
        "\n",
        "    # We don't want to backprop through the expected action values and volatile\n",
        "    # will save us on temporarily changing the model parameters'\n",
        "    # requires_grad to False!\n",
        "    non_final_next_states = [s.view(1, -1) for s in batch.next_state if s is not None]\n",
        "    non_final_next_states = torch.cat(non_final_next_states, 0).to(device)\n",
        "  \n",
        "\n",
        "    # Q(s_t, a) 계산 - 모델이 Q(s_t)를 계산하고, 취한 행동의 열을 선택합니다.\n",
        "    # 이들은 policy_net에 따라 각 배치 상태에 대해 선택된 행동입니다.\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # 모든 다음 상태를 위한 V(s_{t+1}) 계산\n",
        "    # non_final_next_states의 행동들에 대한 기대값은 \"이전\" target_net을 기반으로 계산됩니다.\n",
        "    # max(1)[0]으로 최고의 보상을 선택하십시오.\n",
        "    # 이것은 마스크를 기반으로 병합되어 기대 상태 값을 갖거나 상태가 최종인 경우 0을 갖습니다.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
        "    # 기대 Q 값 계산\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "    \n",
        "    # Huber 손실 계산\n",
        "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "    # 모델 최적화\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    for param in policy_net.parameters():\n",
        "        param.grad.data.clamp_(-1, 1)\n",
        "    optimizer.step()\n",
        "    return loss.cpu().data.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-2dnWNDjp7y",
        "colab_type": "code",
        "outputId": "835e7442-2127-4cf1-ab5f-5511da7a7460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_episodes = EPISODE_SIZE\n",
        "for i_episode in range(num_episodes):\n",
        "    # 환경과 상태 초기화\n",
        "    obv = env.reset()\n",
        "    total_loss = 0\n",
        "    global steps_done\n",
        "    for t in count():\n",
        "        # 행동 선택과 수행\n",
        "        action = select_action(obv)\n",
        "        next_obv, reward, done, _ = env.step(action.item())\n",
        "        reward  = 0.5 + obv[0]\n",
        "        if reward > 1 :\n",
        "          reward += 1\n",
        "        if done :\n",
        "          if t != 199:\n",
        "            print('success')\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "\n",
        "        if not done:\n",
        "          next_state = torch.FloatTensor([next_obv])\n",
        "        else:\n",
        "          next_state = None\n",
        "        # 메모리에 변이 저장\n",
        "        assert obv is not None\n",
        "        memory.push(torch.FloatTensor([obv]), action, next_state, reward)\n",
        "\n",
        "        # 다음 상태로 이동\n",
        "        obv = next_obv\n",
        "\n",
        "        # 최적화 한단계 수행(목표 네트워크에서)\n",
        "        total_loss += optimize_model()\n",
        "        if done:\n",
        "            E = eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "            math.exp(-1. * steps_done / EPS_DECAY)\n",
        "            episode_durations.append(t + 1)\n",
        "            print('%d episode , %d step , %.2f Loss, %.2f Threshold'%(i_episode,t+1,total_loss/(t+1),E))\n",
        "            plot_durations()\n",
        "            total_loss = 0\n",
        "            break\n",
        "    #목표 네트워크 업데이트, 모든 웨이트와 바이어스 복사\n",
        "    if i_episode % TARGET_UPDATE == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "print('Complete')\n",
        "env.render()\n",
        "env.close()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 episode , 200 step , -0.63 Loss, 0.82 Threshold\n",
            "1 episode , 200 step , 0.00 Loss, 0.75 Threshold\n",
            "2 episode , 200 step , 0.00 Loss, 0.68 Threshold\n",
            "3 episode , 200 step , 0.00 Loss, 0.62 Threshold\n",
            "4 episode , 200 step , 0.00 Loss, 0.57 Threshold\n",
            "5 episode , 200 step , 0.00 Loss, 0.52 Threshold\n",
            "6 episode , 200 step , 0.00 Loss, 0.47 Threshold\n",
            "7 episode , 200 step , 0.00 Loss, 0.43 Threshold\n",
            "8 episode , 200 step , 0.00 Loss, 0.40 Threshold\n",
            "9 episode , 200 step , 0.00 Loss, 0.36 Threshold\n",
            "10 episode , 200 step , 0.00 Loss, 0.33 Threshold\n",
            "11 episode , 200 step , 0.00 Loss, 0.31 Threshold\n",
            "12 episode , 200 step , 0.00 Loss, 0.28 Threshold\n",
            "13 episode , 200 step , 0.00 Loss, 0.26 Threshold\n",
            "14 episode , 200 step , 0.00 Loss, 0.24 Threshold\n",
            "15 episode , 200 step , 0.00 Loss, 0.22 Threshold\n",
            "16 episode , 200 step , 0.00 Loss, 0.21 Threshold\n",
            "17 episode , 200 step , 0.00 Loss, 0.19 Threshold\n",
            "18 episode , 200 step , 0.00 Loss, 0.18 Threshold\n",
            "19 episode , 200 step , 0.00 Loss, 0.17 Threshold\n",
            "20 episode , 200 step , 0.00 Loss, 0.15 Threshold\n",
            "21 episode , 200 step , 0.00 Loss, 0.14 Threshold\n",
            "22 episode , 200 step , 0.00 Loss, 0.14 Threshold\n",
            "23 episode , 200 step , 0.00 Loss, 0.13 Threshold\n",
            "24 episode , 200 step , 0.00 Loss, 0.12 Threshold\n",
            "25 episode , 200 step , 0.00 Loss, 0.11 Threshold\n",
            "26 episode , 200 step , 0.00 Loss, 0.11 Threshold\n",
            "27 episode , 200 step , 0.00 Loss, 0.10 Threshold\n",
            "28 episode , 200 step , 0.00 Loss, 0.10 Threshold\n",
            "29 episode , 200 step , 0.00 Loss, 0.09 Threshold\n",
            "30 episode , 200 step , 0.00 Loss, 0.09 Threshold\n",
            "31 episode , 200 step , 0.00 Loss, 0.08 Threshold\n",
            "32 episode , 200 step , 0.00 Loss, 0.08 Threshold\n",
            "33 episode , 200 step , 0.00 Loss, 0.08 Threshold\n",
            "34 episode , 200 step , 0.00 Loss, 0.08 Threshold\n",
            "35 episode , 200 step , 0.00 Loss, 0.07 Threshold\n",
            "36 episode , 200 step , 0.00 Loss, 0.07 Threshold\n",
            "37 episode , 200 step , 0.00 Loss, 0.07 Threshold\n",
            "38 episode , 200 step , 0.00 Loss, 0.07 Threshold\n",
            "39 episode , 200 step , 0.00 Loss, 0.07 Threshold\n",
            "40 episode , 200 step , 0.00 Loss, 0.06 Threshold\n",
            "41 episode , 200 step , 0.00 Loss, 0.06 Threshold\n",
            "42 episode , 200 step , 0.00 Loss, 0.06 Threshold\n",
            "43 episode , 200 step , 0.00 Loss, 0.06 Threshold\n",
            "44 episode , 200 step , 0.00 Loss, 0.06 Threshold\n",
            "45 episode , 200 step , 0.00 Loss, 0.06 Threshold\n",
            "46 episode , 200 step , 0.00 Loss, 0.06 Threshold\n",
            "47 episode , 200 step , 0.00 Loss, 0.06 Threshold\n",
            "48 episode , 200 step , 0.00 Loss, 0.06 Threshold\n",
            "49 episode , 200 step , 0.00 Loss, 0.06 Threshold\n",
            "50 episode , 200 step , 0.00 Loss, 0.06 Threshold\n",
            "51 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "52 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "53 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "54 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "55 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "56 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "57 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "58 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "59 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "60 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "61 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "62 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "63 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "64 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "65 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "66 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "67 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "68 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "69 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "70 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "71 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "72 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "73 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "74 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "75 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "76 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "77 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "78 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "79 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "80 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "81 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "82 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "83 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "84 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "85 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "86 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "87 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "88 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "89 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "90 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "91 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "92 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "93 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "94 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "95 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "96 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "97 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "98 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "99 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "100 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "101 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "102 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "103 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "104 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "105 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "106 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "107 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "108 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "109 episode , 200 step , 0.00 Loss, 0.05 Threshold\n",
            "110 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "111 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "112 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "113 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "114 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "115 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "116 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "117 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "118 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "119 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "120 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "121 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "122 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "123 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "124 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "125 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "126 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "127 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "128 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "129 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "130 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "131 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "132 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "133 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "134 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "135 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "136 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "137 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "138 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "139 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "140 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "141 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "142 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "143 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "144 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "145 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "146 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "147 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "148 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "149 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "150 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "151 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "152 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "153 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "154 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "155 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "156 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "157 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "158 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "159 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "160 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "161 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "162 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "163 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "164 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "165 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "166 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "167 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "168 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "169 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "170 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "171 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "172 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "173 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "174 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "175 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "176 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "177 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "178 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "179 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "180 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "181 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "182 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "183 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "184 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "185 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "186 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "187 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "188 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "189 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "190 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "191 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "192 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "193 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "194 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "195 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "196 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "197 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "198 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "199 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "200 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "201 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "202 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "203 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "204 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "205 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "206 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "207 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "208 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "209 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "210 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "211 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "212 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "213 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "214 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "215 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "216 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "217 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "218 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "219 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "220 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "221 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "222 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "223 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "224 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "225 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "226 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "227 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "228 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "229 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "230 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "231 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "232 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "233 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "234 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "235 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "236 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "237 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "238 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "239 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "240 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "241 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "242 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "243 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "244 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "245 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "246 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "247 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "248 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "249 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "250 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "251 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "252 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "253 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "254 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "255 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "256 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "257 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "258 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "259 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "260 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "261 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "262 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "263 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "264 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "265 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "266 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "267 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "268 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "269 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "270 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "271 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "272 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "273 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "274 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "275 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "276 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "277 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "278 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "279 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "280 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "281 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "282 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "283 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "284 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "285 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "286 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "287 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "288 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "289 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "290 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "291 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "292 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "293 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "294 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "295 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "296 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "297 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "298 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "299 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "300 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "301 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "302 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "303 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "304 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "305 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "306 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "307 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "308 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "309 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "310 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "311 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "312 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "313 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "314 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "315 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "316 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "317 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "318 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "319 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "320 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "321 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "322 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "323 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "324 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "325 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "326 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "327 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "328 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "329 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "330 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "331 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "332 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "333 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "334 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "335 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "336 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "337 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "338 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "339 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "340 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "341 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "342 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "343 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "344 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "345 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "346 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "347 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "348 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "349 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "350 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "351 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "352 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "353 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "354 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "355 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "356 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "357 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "358 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "359 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "360 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "361 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "362 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "363 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "364 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "365 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "366 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "367 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "368 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "369 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "370 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "371 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "372 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "373 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "374 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "375 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "376 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "377 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "378 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "379 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "380 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "381 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "382 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "383 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "384 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "385 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "386 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "387 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "388 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "389 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "390 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "391 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "392 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "393 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "394 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "395 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "396 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "397 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "398 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "399 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "400 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "401 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "402 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "403 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "404 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "405 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "406 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "407 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "408 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "409 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "410 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "411 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "412 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "413 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "414 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "415 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "416 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "417 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "418 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "419 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "420 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "421 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "422 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "423 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "424 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "425 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "426 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "427 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "428 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "429 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "430 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "431 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "432 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "433 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "434 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "435 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "436 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "437 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "438 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "439 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "440 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "441 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "442 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "443 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "444 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "445 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "446 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "447 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "448 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "449 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "450 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "451 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "452 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "453 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "454 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "455 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "456 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "457 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "458 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "459 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "460 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "461 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "462 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "463 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "464 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "465 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "466 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "467 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "468 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "469 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "470 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "471 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "472 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "473 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "474 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "475 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "476 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "477 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "478 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "479 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "480 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "481 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "482 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "483 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "484 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "485 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "486 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "487 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "488 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "489 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "490 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "491 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "492 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "493 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "494 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "495 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "496 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "497 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "498 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "499 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "500 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "501 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "502 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "503 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "504 episode , 200 step , 0.01 Loss, 0.05 Threshold\n",
            "505 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "506 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "507 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "508 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "509 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "510 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "511 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "512 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "513 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "514 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "515 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "516 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "517 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "518 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "519 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "520 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "521 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "522 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "523 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "524 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "525 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "526 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "527 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "528 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "529 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "530 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "531 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "532 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "533 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "534 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "535 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "536 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "537 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "538 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "539 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "540 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "541 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "542 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "543 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "544 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "545 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "546 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "547 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "548 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "549 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "550 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "551 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "552 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "553 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "554 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "555 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "556 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "557 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "558 episode , 200 step , 0.03 Loss, 0.05 Threshold\n",
            "559 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "560 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "561 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "562 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "563 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "564 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "565 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "566 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "567 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "568 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "569 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "570 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "571 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "572 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "573 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "574 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "575 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "576 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "577 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "578 episode , 200 step , 0.03 Loss, 0.05 Threshold\n",
            "579 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "580 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "581 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "582 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "583 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "584 episode , 200 step , 0.03 Loss, 0.05 Threshold\n",
            "585 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "586 episode , 200 step , 0.03 Loss, 0.05 Threshold\n",
            "587 episode , 200 step , 0.03 Loss, 0.05 Threshold\n",
            "588 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "589 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "590 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "591 episode , 200 step , 0.02 Loss, 0.05 Threshold\n",
            "592 episode , 200 step , 0.02 Loss, 0.05 Threshold\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}