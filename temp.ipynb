{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNvgt7rJPgSE37xQ02Tks4P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gomyk/NNStudy/blob/moonwon/temp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO9p_LliP05R",
        "colab_type": "text"
      },
      "source": [
        "#Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9duZfSLhJ8X",
        "colab_type": "code",
        "outputId": "8b869cae-315e-4ff3-f47d-82042f66cc00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!apt-get install x11-utils\n",
        "!pip install box2d-py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "x11-utils is already the newest version (7.7+3build1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n",
            "Requirement already satisfied: box2d-py in /usr/local/lib/python3.6/dist-packages (2.3.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DE8ejMqcTWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "import math\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "from PIL import Image\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import base64\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "from google.colab import output\n",
        "\n",
        "display = Display(visible=0, size=(400,600),)\n",
        "display.start()\n",
        "env = gym.make(\"BipedalWalker-v2\")\n",
        "env._max_episode_steps = 1000\n",
        "#env = gym.wrappers.Monitor(gym.make(\"CartPole-v1\"), \"video\", force=True, video_callable=lambda c:c%100 ==0)\n",
        "\n",
        "# GPU를 사용할 경우\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3exp-qAP7jv",
        "colab_type": "text"
      },
      "source": [
        "##Replay Memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmc6Jfr2d8_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReplayMemory:\n",
        "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
        "\n",
        "    def __init__(self, action_dim:int , obs_dim: int, size: int, batch_size: int):\n",
        "        \"\"\"Initializate.\"\"\"\n",
        "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.acts_buf = np.zeros([size, action_dim], dtype=np.float32)\n",
        "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.done_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.max_size, self.batch_size = size, batch_size\n",
        "        self.ptr, self.size, = 0, 0\n",
        "\n",
        "    def store(\n",
        "        self,\n",
        "        obs: np.ndarray,\n",
        "        act: np.ndarray, \n",
        "        rew: float, \n",
        "        next_obs: np.ndarray, \n",
        "        done: bool,\n",
        "    ):\n",
        "        \"\"\"Store the transition in buffer.\"\"\"\n",
        "        self.obs_buf[self.ptr] = obs\n",
        "        self.next_obs_buf[self.ptr] = next_obs\n",
        "        self.acts_buf[self.ptr] = act\n",
        "        self.rews_buf[self.ptr] = rew\n",
        "        self.done_buf[self.ptr] = done\n",
        "        self.ptr = (self.ptr + 1) % self.max_size\n",
        "        self.size = min(self.size + 1, self.max_size)\n",
        "\n",
        "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
        "        return dict(obs=self.obs_buf[idxs],\n",
        "                    next_obs=self.next_obs_buf[idxs],\n",
        "                    acts=self.acts_buf[idxs],\n",
        "                    rews=self.rews_buf[idxs],\n",
        "                    done=self.done_buf[idxs])\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwrDEGlnQAeH",
        "colab_type": "text"
      },
      "source": [
        "##Define Noise Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j021icUCet_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OUNoise:\n",
        "    \"\"\"Ornstein-Uhlenbeck process.\n",
        "    Taken from Udacity deep-reinforcement-learning github repository:\n",
        "    https://github.com/udacity/deep-reinforcement-learning/blob/master/\n",
        "    ddpg-pendulum/ddpg_agent.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        size: int, \n",
        "        mu: float = 0.0, \n",
        "        theta: float = 0.15, \n",
        "        sigma: float = 0.2,\n",
        "    ):\n",
        "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
        "        self.state = np.float64(0.0)\n",
        "        self.mu = mu * np.ones(size)\n",
        "        self.theta = theta\n",
        "        self.sigma = sigma\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
        "        self.state = copy.copy(self.mu)\n",
        "\n",
        "    def sample(self) -> np.ndarray:\n",
        "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
        "        x = self.state\n",
        "        dx = self.theta * (self.mu - x) + self.sigma * np.array(\n",
        "            [random.random() for _ in range(len(x))]\n",
        "        )\n",
        "        self.state = x + dx\n",
        "        return self.state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYAZSWC2QGDx",
        "colab_type": "text"
      },
      "source": [
        "##Actor Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1hagvrqKTpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HIDDEN_SIZE = 256\n",
        "class Actor(nn.Module):\n",
        "\n",
        "    def __init__(self, obs_size, outputs, init_w: float = 3e-3,):\n",
        "        super(Actor, self).__init__()\n",
        "        self.linear = nn.Linear(obs_size, HIDDEN_SIZE)\n",
        "        self.linear2 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.linear3 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.head = nn.Linear(HIDDEN_SIZE, outputs)\n",
        "\n",
        "        self.head.weight.data.uniform_(-init_w, init_w)\n",
        "        self.head.bias.data.uniform_(-init_w, init_w)\n",
        "\n",
        "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
        "        x = F.relu(self.linear(state))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = F.relu(self.linear3(x))\n",
        "        return self.head(x).tanh()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy5GwnzbQJ4o",
        "colab_type": "text"
      },
      "source": [
        "##Critic Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_lqf372OXYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Critic(nn.Module):\n",
        "\n",
        "    def __init__(self, obs_size, action_size, init_w: float = 3e-3,):\n",
        "        super(Critic, self).__init__()\n",
        "        self.linear = nn.Linear(obs_size + action_size, HIDDEN_SIZE)\n",
        "        self.linear2 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.linear3 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.head = nn.Linear(HIDDEN_SIZE, 1)\n",
        "\n",
        "        self.head.weight.data.uniform_(-init_w, init_w)\n",
        "        self.head.bias.data.uniform_(-init_w, init_w)\n",
        "\n",
        "    def forward(self, state: torch.Tensor, action: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward method implementation.\"\"\"\n",
        "        x = torch.cat((state, action), dim=-1)\n",
        "        x = F.relu(self.linear(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = F.relu(self.linear3(x))\n",
        "        return self.head(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtxzbD_-QPWZ",
        "colab_type": "text"
      },
      "source": [
        "###Environment Snapshot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVgLn9rKgS79",
        "colab_type": "code",
        "outputId": "5ed74464-334e-4075-d33a-fd7e4bac84f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "env.reset()\n",
        "plt.figure()\n",
        "plt.imshow(env.render(mode='rgb_array'))\n",
        "plt.title('Example extracted screen')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM8uMg9vMLDMObjOzzPx/gfFNOqPHxdQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_0DaDLxQVkZ",
        "colab_type": "text"
      },
      "source": [
        "##Prepare to learning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y5GkgVljenU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.999\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 1000\n",
        "TARGET_UPDATE = 10\n",
        "ACTOR_LR = 0.001\n",
        "CRITIC_LR = 0.002\n",
        "MEMORY_SIZE = 10000\n",
        "EPISODE_SIZE = 1000\n",
        "TAU = 0.001\n",
        "ou_noise_theta = 0.15\n",
        "ou_noise_sigma = 0.1\n",
        "\n",
        "RECORD_INTERVAL = 50\n",
        "\n",
        "# gym 행동 공간에서 행동의 숫자를 얻습니다.\n",
        "#n_actions = env.action_space.n\n",
        "n_actions = 4\n",
        "n_obvs = 24\n",
        "\n",
        "actor = Actor(n_obvs, n_actions).to(device)\n",
        "actor.eval()\n",
        "actor_target = Actor(n_obvs, n_actions).to(device)\n",
        "actor_target.load_state_dict(actor.state_dict())\n",
        "actor_target.eval()\n",
        "\n",
        "critic = Critic(n_obvs, n_actions).to(device)\n",
        "critic.eval()\n",
        "critic_target = Critic(n_obvs, n_actions).to(device)\n",
        "critic_target.load_state_dict(critic.state_dict())\n",
        "critic_target.eval()\n",
        "\n",
        "actor_optimizer = optim.Adam(actor.parameters(), lr=ACTOR_LR)\n",
        "critic_optimizer = optim.Adam(critic.parameters(), lr=CRITIC_LR)\n",
        "memory = ReplayMemory(n_actions,n_obvs,MEMORY_SIZE,BATCH_SIZE)\n",
        "\n",
        "noise = OUNoise(\n",
        "            n_actions,\n",
        "            theta=ou_noise_theta,\n",
        "            sigma=ou_noise_sigma,\n",
        "        )\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    steps_done += 1\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    if sample < eps_threshold:\n",
        "            #selected_action = [np.random.uniform(0,1),np.random.uniform(0,1),np.random.uniform(0,1)]\n",
        "            selected_action = np.random.uniform(-1,1,n_actions)\n",
        "    else:\n",
        "        selected_action = actor(\n",
        "             torch.FloatTensor(state).to(device)\n",
        "         ).detach().cpu().numpy()\n",
        "    _noise = noise.sample()\n",
        "    for action in selected_action:\n",
        "      action = np.clip(action + _noise, -1.0, 1.0)\n",
        "    return selected_action\n",
        "episode_durations = []\n",
        "\n",
        "\n",
        "def plot_durations():\n",
        "    plt.figure(2)\n",
        "    plt.clf()\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # 100개의 에피소드 평균을 가져 와서 도표 그리기\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB_xKtOnUR4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def target_soft_update():\n",
        "        #Soft-update: target = tau*local + (1-tau)*target\n",
        "        tau = TAU\n",
        "        \n",
        "        for t_param, l_param in zip(\n",
        "            actor_target.parameters(), actor.parameters()\n",
        "        ):\n",
        "            t_param.data.copy_(tau * l_param.data + (1.0 - tau) * t_param.data)\n",
        "            \n",
        "        for t_param, l_param in zip(\n",
        "            critic_target.parameters(), critic.parameters()\n",
        "        ):\n",
        "            t_param.data.copy_(tau * l_param.data + (1.0 - tau) * t_param.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW7qP2ZuQf-s",
        "colab_type": "text"
      },
      "source": [
        "##Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1Vbb4tzjnjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return -1 , -1\n",
        "    samples = memory.sample_batch()\n",
        "    state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
        "    next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
        "    action = torch.FloatTensor(samples[\"acts\"]).to(device)\n",
        "    reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
        "    done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
        "    \n",
        "    masks = 1 - done\n",
        "    next_action = actor_target(next_state)\n",
        "    next_value = critic_target(next_state, next_action)\n",
        "    curr_return = reward + GAMMA * next_value * masks\n",
        "\n",
        "    # train critic\n",
        "    values = critic(state, action)\n",
        "    critic_loss = F.smooth_l1_loss(values, curr_return)\n",
        "    critic_optimizer.zero_grad()\n",
        "    critic_loss.backward()\n",
        "    critic_optimizer.step()     \n",
        "    # train actor\n",
        "    loss = critic(state, actor(state))\n",
        "    actor_loss = -loss.mean()\n",
        "        \n",
        "    actor_optimizer.zero_grad()\n",
        "    actor_loss.backward()\n",
        "    actor_optimizer.step()\n",
        "        \n",
        "    # target update\n",
        "    target_soft_update()\n",
        "\n",
        "    return actor_loss.data, critic_loss.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4UN3NpFQiLJ",
        "colab_type": "text"
      },
      "source": [
        "##Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-2dnWNDjp7y",
        "colab_type": "code",
        "outputId": "917ee6c0-3772-423e-ee14-31ea83088345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "frames = []\n",
        "for i_episode in range(EPISODE_SIZE):\n",
        "    # 환경과 상태 초기화\n",
        "    obv = env.reset()\n",
        "    total_actor_loss = 0\n",
        "    total_critic_loss = 0\n",
        "    total_reward = 0\n",
        "    global steps_done\n",
        "    top_reward = -1\n",
        "    total_action_count = [0,0,0]\n",
        "    for t in count():\n",
        "        if i_episode % RECORD_INTERVAL == 0:\n",
        "          frames.append(env.render(mode=\"rgb_array\"))\n",
        "        # 행동 선택과 수행\n",
        "        action = select_action(obv)\n",
        "        next_obv, reward, done, _ = env.step(action)\n",
        "        if reward > top_reward:\n",
        "          top_reward = reward\n",
        "        total_reward += reward\n",
        "        # 메모리에 변이 저장\n",
        "        assert obv is not None\n",
        "        memory.store(obv, action, reward, next_obv, done)\n",
        "\n",
        "        # 다음 상태로 이동\n",
        "        obv = next_obv\n",
        "\n",
        "        # 최적화 한단계 수행(목표 네트워크에서)\n",
        "        actor_loss, critic_loss = optimize_model()\n",
        "        total_actor_loss += actor_loss\n",
        "        total_critic_loss += critic_loss\n",
        "        if done:\n",
        "            E = eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "            math.exp(-1. * steps_done / EPS_DECAY)\n",
        "            episode_durations.append(t + 1)\n",
        "            print('%d episode , %d step , %.2f Actor Loss, %.2f Critic Loss,  %.2f Threshold , %.2f Top reward, %.2f Avg reward'\\\n",
        "                  %(i_episode,t+1,total_actor_loss/(t+1), total_critic_loss/(t+1) ,E, top_reward, total_reward/(t+1)))\n",
        "            print(total_action_count)\n",
        "            plot_durations()\n",
        "            total_actor_loss = 0\n",
        "            total_critic_loss = 0\n",
        "            top_reward = 0\n",
        "            total_reward = 0\n",
        "            total_action_count = [0,0,0]\n",
        "            break\n",
        "    #목표 네트워크 업데이트, 모든 웨이트와 바이어스 복사\n",
        "    if i_episode % TARGET_UPDATE == 0:\n",
        "        actor_target.load_state_dict(actor.state_dict())\n",
        "        critic_target.load_state_dict(critic.state_dict())\n",
        "print('Complete')\n",
        "env.render()\n",
        "env.close()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 episode , 81 step , -1.00 Actor Loss, -1.00 Critic Loss,  0.83 Threshold , 0.25 Top reward, -1.23 Avg reward\n",
            "[0, 0, 0]\n",
            "1 episode , 1000 step , -0.04 Actor Loss, 0.01 Critic Loss,  0.34 Threshold , 0.18 Top reward, -0.04 Avg reward\n",
            "[0, 0, 0]\n",
            "2 episode , 1000 step , 0.00 Actor Loss, 0.01 Critic Loss,  0.16 Threshold , 0.24 Top reward, -0.03 Avg reward\n",
            "[0, 0, 0]\n",
            "3 episode , 1000 step , -0.02 Actor Loss, 0.01 Critic Loss,  0.09 Threshold , 0.36 Top reward, -0.02 Avg reward\n",
            "[0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pWWG7HcMD3j",
        "colab_type": "text"
      },
      "source": [
        "## Rendering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHCq9xymdUgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install JSAnimation\n",
        "from matplotlib import animation, rc\n",
        "from JSAnimation.IPython_display import display_animation\n",
        "from IPython.display import display\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2NMRr68tmra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_video():\n",
        "  mp4list = glob.glob('./*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    print(mp4list)\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jaeim4ulL0y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports specifically so we can render outputs in Colab.\n",
        "fig = plt.figure()\n",
        "def display_frames_as_gif(frame):\n",
        "    \"\"\"Displays a list of frames as a gif, with controls.\"\"\"\n",
        "    patch = plt.imshow(frame[0].astype(int))\n",
        "    def animate(i):\n",
        "        patch.set_data(frame[i].astype(int))\n",
        "\n",
        "    anim = animation.FuncAnimation(\n",
        "        fig, animate, frames=len(frames), interval=30, blit=False\n",
        "    )\n",
        "    #display(display_animation(anim, default_mode='loop'))\n",
        "    # Set up formatting for the movie files\n",
        "    display(HTML(data=anim.to_html5_video()))\n",
        "    #FFwriter = animation.FFMpegWriter()\n",
        "    #anim.save('basic_animation.mp4', writer = FFwriter)\n",
        "    #show_video()\n",
        "# display \n",
        "display_frames_as_gif(frames)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}